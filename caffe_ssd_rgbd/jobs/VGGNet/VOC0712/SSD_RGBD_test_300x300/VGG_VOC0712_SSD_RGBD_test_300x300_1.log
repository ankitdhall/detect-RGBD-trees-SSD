I0209 22:43:49.129778  6526 caffe.cpp:217] Using GPUs 1, 2, 0
I0209 22:43:51.317512  6526 caffe.cpp:222] GPU 1: GeForce GTX TITAN X
I0209 22:43:51.318229  6526 caffe.cpp:222] GPU 2: GeForce GTX TITAN X
I0209 22:43:51.318928  6526 caffe.cpp:222] GPU 0: GeForce GTX TITAN X
I0209 22:43:51.594000  6526 solver.cpp:63] Initializing solver from parameters: 
train_net: "models/VGGNet/VOC0712/SSD_RGBD_test_300x300/train.prototxt"
test_net: "models/VGGNet/VOC0712/SSD_RGBD_test_300x300/test.prototxt"
test_iter: 317
test_interval: 10000
base_lr: 2.5e-05
display: 10
max_iter: 120000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 10000
snapshot_prefix: "models/VGGNet/VOC0712/SSD_RGBD_test_300x300/VGG_VOC0712_SSD_RGBD_test_300x300"
solver_mode: GPU
device_id: 1
debug_info: false
train_state {
  level: 0
  stage: ""
}
snapshot_after_train: true
test_initialization: false
average_loss: 10
stepvalue: 80000
stepvalue: 100000
stepvalue: 120000
iter_size: 1
type: "SGD"
eval_type: "detection"
ap_version: "11point"
show_per_class_result: true
I0209 22:43:51.594246  6526 solver.cpp:96] Creating training net from train_net file: models/VGGNet/VOC0712/SSD_RGBD_test_300x300/train.prototxt
I0209 22:43:51.600046  6526 net.cpp:58] Initializing net from parameters: 
name: "VGG_VOC0712_SSD_RGBD_test_300x300_train"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 126
    mean_value: 100
    mean_value: 108
    mean_value: 113
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 300
      width: 300
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 2
      saturation_prob: 0.5
      saturation_lower: 0
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 1
      max_expand_ratio: 4
    }
  }
  data_param {
    source: "examples/VOC0712/VOC0712_trainval_lmdb"
    batch_size: 40
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "data/VOC0712/labelmap_voc.prototxt"
  }
}
layer {
  name: "conv1_1_rgbd"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_rgbd"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_rgbd"
  top: "conv1_1_rgbd"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_rgbd"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 6
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "fc7"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv8_1"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv8_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_1_relu"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_relu"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv9_1"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv9_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_1_relu"
  type: "ReLU"
  bottom: "conv9_1"
  top: "conv9_1"
}
layer {
  name: "conv9_2"
  type: "Convolution"
  bottom: "conv9_1"
  top: "conv9_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_relu"
  type: "ReLU"
  bottom: "conv9_2"
  top: "conv9_2"
}
layer {
  name: "conv4_3_norm"
  type: "Normalize"
  bottom: "conv4_3"
  top: "conv4_3_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20
    }
    channel_shared: false
  }
}
layer {
  name: "conv4_3_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_loc"
  top: "conv4_3_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_loc_perm"
  top: "conv4_3_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 88
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_conf"
  top: "conv4_3_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_conf_perm"
  top: "conv4_3_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv4_3_norm"
  bottom: "data"
  top: "conv4_3_norm_mbox_priorbox"
  prior_box_param {
    min_size: 30
    max_size: 60
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 8
    offset: 0.5
  }
}
layer {
  name: "fc7_mbox_loc"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_loc_perm"
  type: "Permute"
  bottom: "fc7_mbox_loc"
  top: "fc7_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_loc_flat"
  type: "Flatten"
  bottom: "fc7_mbox_loc_perm"
  top: "fc7_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_conf"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 132
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_conf_perm"
  type: "Permute"
  bottom: "fc7_mbox_conf"
  top: "fc7_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_conf_flat"
  type: "Flatten"
  bottom: "fc7_mbox_conf_perm"
  top: "fc7_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_priorbox"
  type: "PriorBox"
  bottom: "fc7"
  bottom: "data"
  top: "fc7_mbox_priorbox"
  prior_box_param {
    min_size: 60
    max_size: 111
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 16
    offset: 0.5
  }
}
layer {
  name: "conv6_2_mbox_loc"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_loc"
  top: "conv6_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_loc_perm"
  top: "conv6_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_conf"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 132
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_conf"
  top: "conv6_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_conf_perm"
  top: "conv6_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv6_2"
  bottom: "data"
  top: "conv6_2_mbox_priorbox"
  prior_box_param {
    min_size: 111
    max_size: 162
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 32
    offset: 0.5
  }
}
layer {
  name: "conv7_2_mbox_loc"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_loc"
  top: "conv7_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_loc_perm"
  top: "conv7_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_conf"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 132
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_conf"
  top: "conv7_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_conf_perm"
  top: "conv7_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv7_2"
  bottom: "data"
  top: "conv7_2_mbox_priorbox"
  prior_box_param {
    min_size: 162
    max_size: 213
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 64
    offset: 0.5
  }
}
layer {
  name: "conv8_2_mbox_loc"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_loc"
  top: "conv8_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_loc_perm"
  top: "conv8_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_conf"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 88
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_conf"
  top: "conv8_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_conf_perm"
  top: "conv8_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv8_2"
  bottom: "data"
  top: "conv8_2_mbox_priorbox"
  prior_box_param {
    min_size: 213
    max_size: 264
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 100
    offset: 0.5
  }
}
layer {
  name: "conv9_2_mbox_loc"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_loc"
  top: "conv9_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_loc_perm"
  top: "conv9_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_conf"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 88
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_conf"
  top: "conv9_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_conf_perm"
  top: "conv9_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv9_2"
  bottom: "data"
  top: "conv9_2_mbox_priorbox"
  prior_box_param {
    min_size: 264
    max_size: 315
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 300
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_flat"
  bottom: "fc7_mbox_loc_flat"
  bottom: "conv6_2_mbox_loc_flat"
  bottom: "conv7_2_mbox_loc_flat"
  bottom: "conv8_2_mbox_loc_flat"
  bottom: "conv9_2_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_flat"
  bottom: "fc7_mbox_conf_flat"
  bottom: "conv6_2_mbox_conf_flat"
  bottom: "conv7_2_mbox_conf_flat"
  bottom: "conv8_2_mbox_conf_flat"
  bottom: "conv9_2_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_priorbox"
  bottom: "fc7_mbox_priorbox"
  bottom: "conv6_2_mbox_priorbox"
  bottom: "conv7_2_mbox_priorbox"
  bottom: "conv8_2_mbox_priorbox"
  bottom: "conv9_2_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_loss"
  type: "MultiBoxLoss"
  bottom: "mbox_loc"
  bottom: "mbox_conf"
  bottom: "mbox_priorbox"
  bottom: "label"
  top: "mbox_loss"
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: true
  propagate_down: false
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  multibox_loss_param {
    loc_loss_type: SMOOTH_L1
    conf_loss_type: SOFTMAX
    loc_weight: 1
    num_classes: 22
    share_location: true
    match_type: PER_PREDICTION
    overlap_threshold: 0.5
    use_prior_for_matching: true
    background_label_id: 0
    use_difficult_gt: true
    neg_pos_ratio: 3
    neg_overlap: 0.5
    code_type: CENTER_SIZE
    ignore_cross_boundary_bbox: false
    mining_type: MAX_NEGATIVE
  }
}
I0209 22:43:51.600986  6526 layer_factory.hpp:77] Creating layer data
I0209 22:43:51.601784  6526 net.cpp:100] Creating Layer data
I0209 22:43:51.601843  6526 net.cpp:408] data -> data
I0209 22:43:51.601902  6526 net.cpp:408] data -> label
I0209 22:43:51.603042  6545 db_lmdb.cpp:35] Opened lmdb examples/VOC0712/VOC0712_trainval_lmdb
I0209 22:43:51.638038  6526 annotated_data_layer.cpp:62] output data size: 40,4,300,300
I0209 22:43:51.742213  6526 net.cpp:150] Setting up data
I0209 22:43:51.742282  6526 net.cpp:157] Top shape: 40 4 300 300 (14400000)
I0209 22:43:51.742293  6526 net.cpp:157] Top shape: 1 1 2 8 (16)
I0209 22:43:51.742298  6526 net.cpp:165] Memory required for data: 57600064
I0209 22:43:51.742311  6526 layer_factory.hpp:77] Creating layer data_data_0_split
I0209 22:43:51.742331  6526 net.cpp:100] Creating Layer data_data_0_split
I0209 22:43:51.742341  6526 net.cpp:434] data_data_0_split <- data
I0209 22:43:51.742367  6526 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0209 22:43:51.742384  6526 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0209 22:43:51.742394  6526 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0209 22:43:51.742403  6526 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0209 22:43:51.742410  6526 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0209 22:43:51.742421  6526 net.cpp:408] data_data_0_split -> data_data_0_split_5
I0209 22:43:51.742429  6526 net.cpp:408] data_data_0_split -> data_data_0_split_6
I0209 22:43:51.742558  6526 net.cpp:150] Setting up data_data_0_split
I0209 22:43:51.742570  6526 net.cpp:157] Top shape: 40 4 300 300 (14400000)
I0209 22:43:51.742576  6526 net.cpp:157] Top shape: 40 4 300 300 (14400000)
I0209 22:43:51.742581  6526 net.cpp:157] Top shape: 40 4 300 300 (14400000)
I0209 22:43:51.742586  6526 net.cpp:157] Top shape: 40 4 300 300 (14400000)
I0209 22:43:51.742591  6526 net.cpp:157] Top shape: 40 4 300 300 (14400000)
I0209 22:43:51.742596  6526 net.cpp:157] Top shape: 40 4 300 300 (14400000)
I0209 22:43:51.742602  6526 net.cpp:157] Top shape: 40 4 300 300 (14400000)
I0209 22:43:51.742606  6526 net.cpp:165] Memory required for data: 460800064
I0209 22:43:51.742610  6526 layer_factory.hpp:77] Creating layer conv1_1_rgbd
I0209 22:43:51.742631  6526 net.cpp:100] Creating Layer conv1_1_rgbd
I0209 22:43:51.742637  6526 net.cpp:434] conv1_1_rgbd <- data_data_0_split_0
I0209 22:43:51.742646  6526 net.cpp:408] conv1_1_rgbd -> conv1_1_rgbd
I0209 22:43:51.915196  6526 net.cpp:150] Setting up conv1_1_rgbd
I0209 22:43:51.915231  6526 net.cpp:157] Top shape: 40 64 300 300 (230400000)
I0209 22:43:51.915236  6526 net.cpp:165] Memory required for data: 1382400064
I0209 22:43:51.915256  6526 layer_factory.hpp:77] Creating layer relu1_1
I0209 22:43:51.915269  6526 net.cpp:100] Creating Layer relu1_1
I0209 22:43:51.915276  6526 net.cpp:434] relu1_1 <- conv1_1_rgbd
I0209 22:43:51.915282  6526 net.cpp:395] relu1_1 -> conv1_1_rgbd (in-place)
I0209 22:43:51.915596  6526 net.cpp:150] Setting up relu1_1
I0209 22:43:51.915611  6526 net.cpp:157] Top shape: 40 64 300 300 (230400000)
I0209 22:43:51.915616  6526 net.cpp:165] Memory required for data: 2304000064
I0209 22:43:51.915619  6526 layer_factory.hpp:77] Creating layer conv1_2
I0209 22:43:51.915634  6526 net.cpp:100] Creating Layer conv1_2
I0209 22:43:51.915638  6526 net.cpp:434] conv1_2 <- conv1_1_rgbd
I0209 22:43:51.915645  6526 net.cpp:408] conv1_2 -> conv1_2
I0209 22:43:51.917340  6526 net.cpp:150] Setting up conv1_2
I0209 22:43:51.917356  6526 net.cpp:157] Top shape: 40 64 300 300 (230400000)
I0209 22:43:51.917361  6526 net.cpp:165] Memory required for data: 3225600064
I0209 22:43:51.917371  6526 layer_factory.hpp:77] Creating layer relu1_2
I0209 22:43:51.917377  6526 net.cpp:100] Creating Layer relu1_2
I0209 22:43:51.917382  6526 net.cpp:434] relu1_2 <- conv1_2
I0209 22:43:51.917387  6526 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0209 22:43:51.917667  6526 net.cpp:150] Setting up relu1_2
I0209 22:43:51.917681  6526 net.cpp:157] Top shape: 40 64 300 300 (230400000)
I0209 22:43:51.917685  6526 net.cpp:165] Memory required for data: 4147200064
I0209 22:43:51.917690  6526 layer_factory.hpp:77] Creating layer pool1
I0209 22:43:51.917698  6526 net.cpp:100] Creating Layer pool1
I0209 22:43:51.917702  6526 net.cpp:434] pool1 <- conv1_2
I0209 22:43:51.917708  6526 net.cpp:408] pool1 -> pool1
I0209 22:43:51.917758  6526 net.cpp:150] Setting up pool1
I0209 22:43:51.917770  6526 net.cpp:157] Top shape: 40 64 150 150 (57600000)
I0209 22:43:51.917790  6526 net.cpp:165] Memory required for data: 4377600064
I0209 22:43:51.917794  6526 layer_factory.hpp:77] Creating layer conv2_1
I0209 22:43:51.917804  6526 net.cpp:100] Creating Layer conv2_1
I0209 22:43:51.917809  6526 net.cpp:434] conv2_1 <- pool1
I0209 22:43:51.917814  6526 net.cpp:408] conv2_1 -> conv2_1
I0209 22:43:51.919412  6526 net.cpp:150] Setting up conv2_1
I0209 22:43:51.919428  6526 net.cpp:157] Top shape: 40 128 150 150 (115200000)
I0209 22:43:51.919432  6526 net.cpp:165] Memory required for data: 4838400064
I0209 22:43:51.919442  6526 layer_factory.hpp:77] Creating layer relu2_1
I0209 22:43:51.919450  6526 net.cpp:100] Creating Layer relu2_1
I0209 22:43:51.919455  6526 net.cpp:434] relu2_1 <- conv2_1
I0209 22:43:51.919461  6526 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0209 22:43:51.919622  6526 net.cpp:150] Setting up relu2_1
I0209 22:43:51.919633  6526 net.cpp:157] Top shape: 40 128 150 150 (115200000)
I0209 22:43:51.919637  6526 net.cpp:165] Memory required for data: 5299200064
I0209 22:43:51.919641  6526 layer_factory.hpp:77] Creating layer conv2_2
I0209 22:43:51.919651  6526 net.cpp:100] Creating Layer conv2_2
I0209 22:43:51.919656  6526 net.cpp:434] conv2_2 <- conv2_1
I0209 22:43:51.919661  6526 net.cpp:408] conv2_2 -> conv2_2
I0209 22:43:51.922113  6526 net.cpp:150] Setting up conv2_2
I0209 22:43:51.922129  6526 net.cpp:157] Top shape: 40 128 150 150 (115200000)
I0209 22:43:51.922133  6526 net.cpp:165] Memory required for data: 5760000064
I0209 22:43:51.922140  6526 layer_factory.hpp:77] Creating layer relu2_2
I0209 22:43:51.922147  6526 net.cpp:100] Creating Layer relu2_2
I0209 22:43:51.922152  6526 net.cpp:434] relu2_2 <- conv2_2
I0209 22:43:51.922158  6526 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0209 22:43:51.922454  6526 net.cpp:150] Setting up relu2_2
I0209 22:43:51.922468  6526 net.cpp:157] Top shape: 40 128 150 150 (115200000)
I0209 22:43:51.922472  6526 net.cpp:165] Memory required for data: 6220800064
I0209 22:43:51.922477  6526 layer_factory.hpp:77] Creating layer pool2
I0209 22:43:51.922483  6526 net.cpp:100] Creating Layer pool2
I0209 22:43:51.922487  6526 net.cpp:434] pool2 <- conv2_2
I0209 22:43:51.922493  6526 net.cpp:408] pool2 -> pool2
I0209 22:43:51.922536  6526 net.cpp:150] Setting up pool2
I0209 22:43:51.922543  6526 net.cpp:157] Top shape: 40 128 75 75 (28800000)
I0209 22:43:51.922545  6526 net.cpp:165] Memory required for data: 6336000064
I0209 22:43:51.922549  6526 layer_factory.hpp:77] Creating layer conv3_1
I0209 22:43:51.922559  6526 net.cpp:100] Creating Layer conv3_1
I0209 22:43:51.922562  6526 net.cpp:434] conv3_1 <- pool2
I0209 22:43:51.922569  6526 net.cpp:408] conv3_1 -> conv3_1
I0209 22:43:51.926512  6526 net.cpp:150] Setting up conv3_1
I0209 22:43:51.926529  6526 net.cpp:157] Top shape: 40 256 75 75 (57600000)
I0209 22:43:51.926533  6526 net.cpp:165] Memory required for data: 6566400064
I0209 22:43:51.926544  6526 layer_factory.hpp:77] Creating layer relu3_1
I0209 22:43:51.926551  6526 net.cpp:100] Creating Layer relu3_1
I0209 22:43:51.926555  6526 net.cpp:434] relu3_1 <- conv3_1
I0209 22:43:51.926560  6526 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0209 22:43:51.926844  6526 net.cpp:150] Setting up relu3_1
I0209 22:43:51.926858  6526 net.cpp:157] Top shape: 40 256 75 75 (57600000)
I0209 22:43:51.926862  6526 net.cpp:165] Memory required for data: 6796800064
I0209 22:43:51.926867  6526 layer_factory.hpp:77] Creating layer conv3_2
I0209 22:43:51.926877  6526 net.cpp:100] Creating Layer conv3_2
I0209 22:43:51.926882  6526 net.cpp:434] conv3_2 <- conv3_1
I0209 22:43:51.926887  6526 net.cpp:408] conv3_2 -> conv3_2
I0209 22:43:51.932842  6526 net.cpp:150] Setting up conv3_2
I0209 22:43:51.932858  6526 net.cpp:157] Top shape: 40 256 75 75 (57600000)
I0209 22:43:51.932863  6526 net.cpp:165] Memory required for data: 7027200064
I0209 22:43:51.932870  6526 layer_factory.hpp:77] Creating layer relu3_2
I0209 22:43:51.932878  6526 net.cpp:100] Creating Layer relu3_2
I0209 22:43:51.932883  6526 net.cpp:434] relu3_2 <- conv3_2
I0209 22:43:51.932900  6526 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0209 22:43:51.933064  6526 net.cpp:150] Setting up relu3_2
I0209 22:43:51.933075  6526 net.cpp:157] Top shape: 40 256 75 75 (57600000)
I0209 22:43:51.933079  6526 net.cpp:165] Memory required for data: 7257600064
I0209 22:43:51.933084  6526 layer_factory.hpp:77] Creating layer conv3_3
I0209 22:43:51.933094  6526 net.cpp:100] Creating Layer conv3_3
I0209 22:43:51.933099  6526 net.cpp:434] conv3_3 <- conv3_2
I0209 22:43:51.933104  6526 net.cpp:408] conv3_3 -> conv3_3
I0209 22:43:51.939064  6526 net.cpp:150] Setting up conv3_3
I0209 22:43:51.939081  6526 net.cpp:157] Top shape: 40 256 75 75 (57600000)
I0209 22:43:51.939085  6526 net.cpp:165] Memory required for data: 7488000064
I0209 22:43:51.939092  6526 layer_factory.hpp:77] Creating layer relu3_3
I0209 22:43:51.939100  6526 net.cpp:100] Creating Layer relu3_3
I0209 22:43:51.939105  6526 net.cpp:434] relu3_3 <- conv3_3
I0209 22:43:51.939110  6526 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0209 22:43:51.939401  6526 net.cpp:150] Setting up relu3_3
I0209 22:43:51.939415  6526 net.cpp:157] Top shape: 40 256 75 75 (57600000)
I0209 22:43:51.939419  6526 net.cpp:165] Memory required for data: 7718400064
I0209 22:43:51.939424  6526 layer_factory.hpp:77] Creating layer pool3
I0209 22:43:51.939430  6526 net.cpp:100] Creating Layer pool3
I0209 22:43:51.939435  6526 net.cpp:434] pool3 <- conv3_3
I0209 22:43:51.939440  6526 net.cpp:408] pool3 -> pool3
I0209 22:43:51.939483  6526 net.cpp:150] Setting up pool3
I0209 22:43:51.939489  6526 net.cpp:157] Top shape: 40 256 38 38 (14786560)
I0209 22:43:51.939492  6526 net.cpp:165] Memory required for data: 7777546304
I0209 22:43:51.939496  6526 layer_factory.hpp:77] Creating layer conv4_1
I0209 22:43:51.939505  6526 net.cpp:100] Creating Layer conv4_1
I0209 22:43:51.939509  6526 net.cpp:434] conv4_1 <- pool3
I0209 22:43:51.939515  6526 net.cpp:408] conv4_1 -> conv4_1
I0209 22:43:51.950738  6526 net.cpp:150] Setting up conv4_1
I0209 22:43:51.950760  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:51.950765  6526 net.cpp:165] Memory required for data: 7895838784
I0209 22:43:51.950773  6526 layer_factory.hpp:77] Creating layer relu4_1
I0209 22:43:51.950780  6526 net.cpp:100] Creating Layer relu4_1
I0209 22:43:51.950785  6526 net.cpp:434] relu4_1 <- conv4_1
I0209 22:43:51.950791  6526 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0209 22:43:51.951086  6526 net.cpp:150] Setting up relu4_1
I0209 22:43:51.951100  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:51.951104  6526 net.cpp:165] Memory required for data: 8014131264
I0209 22:43:51.951108  6526 layer_factory.hpp:77] Creating layer conv4_2
I0209 22:43:51.951119  6526 net.cpp:100] Creating Layer conv4_2
I0209 22:43:51.951123  6526 net.cpp:434] conv4_2 <- conv4_1
I0209 22:43:51.951130  6526 net.cpp:408] conv4_2 -> conv4_2
I0209 22:43:51.971910  6526 net.cpp:150] Setting up conv4_2
I0209 22:43:51.971947  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:51.971952  6526 net.cpp:165] Memory required for data: 8132423744
I0209 22:43:51.971967  6526 layer_factory.hpp:77] Creating layer relu4_2
I0209 22:43:51.971978  6526 net.cpp:100] Creating Layer relu4_2
I0209 22:43:51.971984  6526 net.cpp:434] relu4_2 <- conv4_2
I0209 22:43:51.971992  6526 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0209 22:43:51.972163  6526 net.cpp:150] Setting up relu4_2
I0209 22:43:51.972174  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:51.972178  6526 net.cpp:165] Memory required for data: 8250716224
I0209 22:43:51.972182  6526 layer_factory.hpp:77] Creating layer conv4_3
I0209 22:43:51.972199  6526 net.cpp:100] Creating Layer conv4_3
I0209 22:43:51.972203  6526 net.cpp:434] conv4_3 <- conv4_2
I0209 22:43:51.972209  6526 net.cpp:408] conv4_3 -> conv4_3
I0209 22:43:51.992910  6526 net.cpp:150] Setting up conv4_3
I0209 22:43:51.992940  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:51.992945  6526 net.cpp:165] Memory required for data: 8369008704
I0209 22:43:51.992974  6526 layer_factory.hpp:77] Creating layer relu4_3
I0209 22:43:51.992985  6526 net.cpp:100] Creating Layer relu4_3
I0209 22:43:51.992990  6526 net.cpp:434] relu4_3 <- conv4_3
I0209 22:43:51.992996  6526 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0209 22:43:51.993316  6526 net.cpp:150] Setting up relu4_3
I0209 22:43:51.993330  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:51.993335  6526 net.cpp:165] Memory required for data: 8487301184
I0209 22:43:51.993338  6526 layer_factory.hpp:77] Creating layer conv4_3_relu4_3_0_split
I0209 22:43:51.993345  6526 net.cpp:100] Creating Layer conv4_3_relu4_3_0_split
I0209 22:43:51.993350  6526 net.cpp:434] conv4_3_relu4_3_0_split <- conv4_3
I0209 22:43:51.993357  6526 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_0
I0209 22:43:51.993366  6526 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_1
I0209 22:43:51.993410  6526 net.cpp:150] Setting up conv4_3_relu4_3_0_split
I0209 22:43:51.993417  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:51.993420  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:51.993424  6526 net.cpp:165] Memory required for data: 8723886144
I0209 22:43:51.993427  6526 layer_factory.hpp:77] Creating layer pool4
I0209 22:43:51.993437  6526 net.cpp:100] Creating Layer pool4
I0209 22:43:51.993440  6526 net.cpp:434] pool4 <- conv4_3_relu4_3_0_split_0
I0209 22:43:51.993446  6526 net.cpp:408] pool4 -> pool4
I0209 22:43:51.993484  6526 net.cpp:150] Setting up pool4
I0209 22:43:51.993490  6526 net.cpp:157] Top shape: 40 512 19 19 (7393280)
I0209 22:43:51.993494  6526 net.cpp:165] Memory required for data: 8753459264
I0209 22:43:51.993497  6526 layer_factory.hpp:77] Creating layer conv5_1
I0209 22:43:51.993510  6526 net.cpp:100] Creating Layer conv5_1
I0209 22:43:51.993515  6526 net.cpp:434] conv5_1 <- pool4
I0209 22:43:51.993520  6526 net.cpp:408] conv5_1 -> conv5_1
I0209 22:43:52.014194  6526 net.cpp:150] Setting up conv5_1
I0209 22:43:52.014223  6526 net.cpp:157] Top shape: 40 512 19 19 (7393280)
I0209 22:43:52.014228  6526 net.cpp:165] Memory required for data: 8783032384
I0209 22:43:52.014237  6526 layer_factory.hpp:77] Creating layer relu5_1
I0209 22:43:52.014248  6526 net.cpp:100] Creating Layer relu5_1
I0209 22:43:52.014253  6526 net.cpp:434] relu5_1 <- conv5_1
I0209 22:43:52.014261  6526 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0209 22:43:52.014565  6526 net.cpp:150] Setting up relu5_1
I0209 22:43:52.014580  6526 net.cpp:157] Top shape: 40 512 19 19 (7393280)
I0209 22:43:52.014583  6526 net.cpp:165] Memory required for data: 8812605504
I0209 22:43:52.014587  6526 layer_factory.hpp:77] Creating layer conv5_2
I0209 22:43:52.014601  6526 net.cpp:100] Creating Layer conv5_2
I0209 22:43:52.014606  6526 net.cpp:434] conv5_2 <- conv5_1
I0209 22:43:52.014613  6526 net.cpp:408] conv5_2 -> conv5_2
I0209 22:43:52.035370  6526 net.cpp:150] Setting up conv5_2
I0209 22:43:52.035406  6526 net.cpp:157] Top shape: 40 512 19 19 (7393280)
I0209 22:43:52.035410  6526 net.cpp:165] Memory required for data: 8842178624
I0209 22:43:52.035420  6526 layer_factory.hpp:77] Creating layer relu5_2
I0209 22:43:52.035430  6526 net.cpp:100] Creating Layer relu5_2
I0209 22:43:52.035435  6526 net.cpp:434] relu5_2 <- conv5_2
I0209 22:43:52.035442  6526 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0209 22:43:52.035617  6526 net.cpp:150] Setting up relu5_2
I0209 22:43:52.035634  6526 net.cpp:157] Top shape: 40 512 19 19 (7393280)
I0209 22:43:52.035637  6526 net.cpp:165] Memory required for data: 8871751744
I0209 22:43:52.035641  6526 layer_factory.hpp:77] Creating layer conv5_3
I0209 22:43:52.035655  6526 net.cpp:100] Creating Layer conv5_3
I0209 22:43:52.035658  6526 net.cpp:434] conv5_3 <- conv5_2
I0209 22:43:52.035666  6526 net.cpp:408] conv5_3 -> conv5_3
I0209 22:43:52.056407  6526 net.cpp:150] Setting up conv5_3
I0209 22:43:52.056438  6526 net.cpp:157] Top shape: 40 512 19 19 (7393280)
I0209 22:43:52.056443  6526 net.cpp:165] Memory required for data: 8901324864
I0209 22:43:52.056452  6526 layer_factory.hpp:77] Creating layer relu5_3
I0209 22:43:52.056488  6526 net.cpp:100] Creating Layer relu5_3
I0209 22:43:52.056494  6526 net.cpp:434] relu5_3 <- conv5_3
I0209 22:43:52.056501  6526 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0209 22:43:52.056815  6526 net.cpp:150] Setting up relu5_3
I0209 22:43:52.056830  6526 net.cpp:157] Top shape: 40 512 19 19 (7393280)
I0209 22:43:52.056834  6526 net.cpp:165] Memory required for data: 8930897984
I0209 22:43:52.056838  6526 layer_factory.hpp:77] Creating layer pool5
I0209 22:43:52.056845  6526 net.cpp:100] Creating Layer pool5
I0209 22:43:52.056849  6526 net.cpp:434] pool5 <- conv5_3
I0209 22:43:52.056857  6526 net.cpp:408] pool5 -> pool5
I0209 22:43:52.056906  6526 net.cpp:150] Setting up pool5
I0209 22:43:52.056913  6526 net.cpp:157] Top shape: 40 512 19 19 (7393280)
I0209 22:43:52.056916  6526 net.cpp:165] Memory required for data: 8960471104
I0209 22:43:52.056921  6526 layer_factory.hpp:77] Creating layer fc6
I0209 22:43:52.056932  6526 net.cpp:100] Creating Layer fc6
I0209 22:43:52.056936  6526 net.cpp:434] fc6 <- pool5
I0209 22:43:52.056942  6526 net.cpp:408] fc6 -> fc6
I0209 22:43:52.096995  6526 net.cpp:150] Setting up fc6
I0209 22:43:52.097031  6526 net.cpp:157] Top shape: 40 1024 19 19 (14786560)
I0209 22:43:52.097035  6526 net.cpp:165] Memory required for data: 9019617344
I0209 22:43:52.097045  6526 layer_factory.hpp:77] Creating layer relu6
I0209 22:43:52.097059  6526 net.cpp:100] Creating Layer relu6
I0209 22:43:52.097065  6526 net.cpp:434] relu6 <- fc6
I0209 22:43:52.097074  6526 net.cpp:395] relu6 -> fc6 (in-place)
I0209 22:43:52.097316  6526 net.cpp:150] Setting up relu6
I0209 22:43:52.097328  6526 net.cpp:157] Top shape: 40 1024 19 19 (14786560)
I0209 22:43:52.097332  6526 net.cpp:165] Memory required for data: 9078763584
I0209 22:43:52.097337  6526 layer_factory.hpp:77] Creating layer fc7
I0209 22:43:52.097348  6526 net.cpp:100] Creating Layer fc7
I0209 22:43:52.097352  6526 net.cpp:434] fc7 <- fc6
I0209 22:43:52.097360  6526 net.cpp:408] fc7 -> fc7
I0209 22:43:52.107266  6526 net.cpp:150] Setting up fc7
I0209 22:43:52.107283  6526 net.cpp:157] Top shape: 40 1024 19 19 (14786560)
I0209 22:43:52.107287  6526 net.cpp:165] Memory required for data: 9137909824
I0209 22:43:52.107295  6526 layer_factory.hpp:77] Creating layer relu7
I0209 22:43:52.107301  6526 net.cpp:100] Creating Layer relu7
I0209 22:43:52.107306  6526 net.cpp:434] relu7 <- fc7
I0209 22:43:52.107312  6526 net.cpp:395] relu7 -> fc7 (in-place)
I0209 22:43:52.107620  6526 net.cpp:150] Setting up relu7
I0209 22:43:52.107635  6526 net.cpp:157] Top shape: 40 1024 19 19 (14786560)
I0209 22:43:52.107637  6526 net.cpp:165] Memory required for data: 9197056064
I0209 22:43:52.107641  6526 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0209 22:43:52.107651  6526 net.cpp:100] Creating Layer fc7_relu7_0_split
I0209 22:43:52.107656  6526 net.cpp:434] fc7_relu7_0_split <- fc7
I0209 22:43:52.107661  6526 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0209 22:43:52.107669  6526 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0209 22:43:52.107681  6526 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0209 22:43:52.107687  6526 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_3
I0209 22:43:52.107760  6526 net.cpp:150] Setting up fc7_relu7_0_split
I0209 22:43:52.107769  6526 net.cpp:157] Top shape: 40 1024 19 19 (14786560)
I0209 22:43:52.107774  6526 net.cpp:157] Top shape: 40 1024 19 19 (14786560)
I0209 22:43:52.107777  6526 net.cpp:157] Top shape: 40 1024 19 19 (14786560)
I0209 22:43:52.107781  6526 net.cpp:157] Top shape: 40 1024 19 19 (14786560)
I0209 22:43:52.107785  6526 net.cpp:165] Memory required for data: 9433641024
I0209 22:43:52.107789  6526 layer_factory.hpp:77] Creating layer conv6_1
I0209 22:43:52.107800  6526 net.cpp:100] Creating Layer conv6_1
I0209 22:43:52.107805  6526 net.cpp:434] conv6_1 <- fc7_relu7_0_split_0
I0209 22:43:52.107811  6526 net.cpp:408] conv6_1 -> conv6_1
I0209 22:43:52.112165  6526 net.cpp:150] Setting up conv6_1
I0209 22:43:52.112186  6526 net.cpp:157] Top shape: 40 256 19 19 (3696640)
I0209 22:43:52.112207  6526 net.cpp:165] Memory required for data: 9448427584
I0209 22:43:52.112215  6526 layer_factory.hpp:77] Creating layer conv6_1_relu
I0209 22:43:52.112223  6526 net.cpp:100] Creating Layer conv6_1_relu
I0209 22:43:52.112227  6526 net.cpp:434] conv6_1_relu <- conv6_1
I0209 22:43:52.112233  6526 net.cpp:395] conv6_1_relu -> conv6_1 (in-place)
I0209 22:43:52.112560  6526 net.cpp:150] Setting up conv6_1_relu
I0209 22:43:52.112574  6526 net.cpp:157] Top shape: 40 256 19 19 (3696640)
I0209 22:43:52.112578  6526 net.cpp:165] Memory required for data: 9463214144
I0209 22:43:52.112583  6526 layer_factory.hpp:77] Creating layer conv6_2
I0209 22:43:52.112594  6526 net.cpp:100] Creating Layer conv6_2
I0209 22:43:52.112599  6526 net.cpp:434] conv6_2 <- conv6_1
I0209 22:43:52.112607  6526 net.cpp:408] conv6_2 -> conv6_2
I0209 22:43:52.114398  6546 blocking_queue.cpp:50] Waiting for data
I0209 22:43:52.123522  6526 net.cpp:150] Setting up conv6_2
I0209 22:43:52.123538  6526 net.cpp:157] Top shape: 40 512 10 10 (2048000)
I0209 22:43:52.123543  6526 net.cpp:165] Memory required for data: 9471406144
I0209 22:43:52.123556  6526 layer_factory.hpp:77] Creating layer conv6_2_relu
I0209 22:43:52.123569  6526 net.cpp:100] Creating Layer conv6_2_relu
I0209 22:43:52.123574  6526 net.cpp:434] conv6_2_relu <- conv6_2
I0209 22:43:52.123579  6526 net.cpp:395] conv6_2_relu -> conv6_2 (in-place)
I0209 22:43:52.123755  6526 net.cpp:150] Setting up conv6_2_relu
I0209 22:43:52.123766  6526 net.cpp:157] Top shape: 40 512 10 10 (2048000)
I0209 22:43:52.123770  6526 net.cpp:165] Memory required for data: 9479598144
I0209 22:43:52.123775  6526 layer_factory.hpp:77] Creating layer conv6_2_conv6_2_relu_0_split
I0209 22:43:52.123780  6526 net.cpp:100] Creating Layer conv6_2_conv6_2_relu_0_split
I0209 22:43:52.123785  6526 net.cpp:434] conv6_2_conv6_2_relu_0_split <- conv6_2
I0209 22:43:52.123791  6526 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_0
I0209 22:43:52.123800  6526 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_1
I0209 22:43:52.123806  6526 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_2
I0209 22:43:52.123812  6526 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_3
I0209 22:43:52.123884  6526 net.cpp:150] Setting up conv6_2_conv6_2_relu_0_split
I0209 22:43:52.123893  6526 net.cpp:157] Top shape: 40 512 10 10 (2048000)
I0209 22:43:52.123896  6526 net.cpp:157] Top shape: 40 512 10 10 (2048000)
I0209 22:43:52.123900  6526 net.cpp:157] Top shape: 40 512 10 10 (2048000)
I0209 22:43:52.123904  6526 net.cpp:157] Top shape: 40 512 10 10 (2048000)
I0209 22:43:52.123908  6526 net.cpp:165] Memory required for data: 9512366144
I0209 22:43:52.123911  6526 layer_factory.hpp:77] Creating layer conv7_1
I0209 22:43:52.123924  6526 net.cpp:100] Creating Layer conv7_1
I0209 22:43:52.123927  6526 net.cpp:434] conv7_1 <- conv6_2_conv6_2_relu_0_split_0
I0209 22:43:52.123934  6526 net.cpp:408] conv7_1 -> conv7_1
I0209 22:43:52.125491  6526 net.cpp:150] Setting up conv7_1
I0209 22:43:52.125506  6526 net.cpp:157] Top shape: 40 128 10 10 (512000)
I0209 22:43:52.125511  6526 net.cpp:165] Memory required for data: 9514414144
I0209 22:43:52.125517  6526 layer_factory.hpp:77] Creating layer conv7_1_relu
I0209 22:43:52.125526  6526 net.cpp:100] Creating Layer conv7_1_relu
I0209 22:43:52.125531  6526 net.cpp:434] conv7_1_relu <- conv7_1
I0209 22:43:52.125536  6526 net.cpp:395] conv7_1_relu -> conv7_1 (in-place)
I0209 22:43:52.125846  6526 net.cpp:150] Setting up conv7_1_relu
I0209 22:43:52.125860  6526 net.cpp:157] Top shape: 40 128 10 10 (512000)
I0209 22:43:52.125864  6526 net.cpp:165] Memory required for data: 9516462144
I0209 22:43:52.125869  6526 layer_factory.hpp:77] Creating layer conv7_2
I0209 22:43:52.125879  6526 net.cpp:100] Creating Layer conv7_2
I0209 22:43:52.125883  6526 net.cpp:434] conv7_2 <- conv7_1
I0209 22:43:52.125891  6526 net.cpp:408] conv7_2 -> conv7_2
I0209 22:43:52.129421  6526 net.cpp:150] Setting up conv7_2
I0209 22:43:52.129448  6526 net.cpp:157] Top shape: 40 256 5 5 (256000)
I0209 22:43:52.129453  6526 net.cpp:165] Memory required for data: 9517486144
I0209 22:43:52.129461  6526 layer_factory.hpp:77] Creating layer conv7_2_relu
I0209 22:43:52.129467  6526 net.cpp:100] Creating Layer conv7_2_relu
I0209 22:43:52.129472  6526 net.cpp:434] conv7_2_relu <- conv7_2
I0209 22:43:52.129479  6526 net.cpp:395] conv7_2_relu -> conv7_2 (in-place)
I0209 22:43:52.129803  6526 net.cpp:150] Setting up conv7_2_relu
I0209 22:43:52.129817  6526 net.cpp:157] Top shape: 40 256 5 5 (256000)
I0209 22:43:52.129822  6526 net.cpp:165] Memory required for data: 9518510144
I0209 22:43:52.129825  6526 layer_factory.hpp:77] Creating layer conv7_2_conv7_2_relu_0_split
I0209 22:43:52.129832  6526 net.cpp:100] Creating Layer conv7_2_conv7_2_relu_0_split
I0209 22:43:52.129837  6526 net.cpp:434] conv7_2_conv7_2_relu_0_split <- conv7_2
I0209 22:43:52.129843  6526 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_0
I0209 22:43:52.129851  6526 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_1
I0209 22:43:52.129858  6526 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_2
I0209 22:43:52.129864  6526 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_3
I0209 22:43:52.129938  6526 net.cpp:150] Setting up conv7_2_conv7_2_relu_0_split
I0209 22:43:52.129951  6526 net.cpp:157] Top shape: 40 256 5 5 (256000)
I0209 22:43:52.129956  6526 net.cpp:157] Top shape: 40 256 5 5 (256000)
I0209 22:43:52.129959  6526 net.cpp:157] Top shape: 40 256 5 5 (256000)
I0209 22:43:52.129963  6526 net.cpp:157] Top shape: 40 256 5 5 (256000)
I0209 22:43:52.129966  6526 net.cpp:165] Memory required for data: 9522606144
I0209 22:43:52.129969  6526 layer_factory.hpp:77] Creating layer conv8_1
I0209 22:43:52.129979  6526 net.cpp:100] Creating Layer conv8_1
I0209 22:43:52.129984  6526 net.cpp:434] conv8_1 <- conv7_2_conv7_2_relu_0_split_0
I0209 22:43:52.129992  6526 net.cpp:408] conv8_1 -> conv8_1
I0209 22:43:52.131304  6526 net.cpp:150] Setting up conv8_1
I0209 22:43:52.131321  6526 net.cpp:157] Top shape: 40 128 5 5 (128000)
I0209 22:43:52.131325  6526 net.cpp:165] Memory required for data: 9523118144
I0209 22:43:52.131332  6526 layer_factory.hpp:77] Creating layer conv8_1_relu
I0209 22:43:52.131340  6526 net.cpp:100] Creating Layer conv8_1_relu
I0209 22:43:52.131343  6526 net.cpp:434] conv8_1_relu <- conv8_1
I0209 22:43:52.131350  6526 net.cpp:395] conv8_1_relu -> conv8_1 (in-place)
I0209 22:43:52.131526  6526 net.cpp:150] Setting up conv8_1_relu
I0209 22:43:52.131537  6526 net.cpp:157] Top shape: 40 128 5 5 (128000)
I0209 22:43:52.131541  6526 net.cpp:165] Memory required for data: 9523630144
I0209 22:43:52.131546  6526 layer_factory.hpp:77] Creating layer conv8_2
I0209 22:43:52.131556  6526 net.cpp:100] Creating Layer conv8_2
I0209 22:43:52.131561  6526 net.cpp:434] conv8_2 <- conv8_1
I0209 22:43:52.131568  6526 net.cpp:408] conv8_2 -> conv8_2
I0209 22:43:52.135222  6526 net.cpp:150] Setting up conv8_2
I0209 22:43:52.135238  6526 net.cpp:157] Top shape: 40 256 3 3 (92160)
I0209 22:43:52.135242  6526 net.cpp:165] Memory required for data: 9523998784
I0209 22:43:52.135249  6526 layer_factory.hpp:77] Creating layer conv8_2_relu
I0209 22:43:52.135257  6526 net.cpp:100] Creating Layer conv8_2_relu
I0209 22:43:52.135262  6526 net.cpp:434] conv8_2_relu <- conv8_2
I0209 22:43:52.135268  6526 net.cpp:395] conv8_2_relu -> conv8_2 (in-place)
I0209 22:43:52.135586  6526 net.cpp:150] Setting up conv8_2_relu
I0209 22:43:52.135601  6526 net.cpp:157] Top shape: 40 256 3 3 (92160)
I0209 22:43:52.135604  6526 net.cpp:165] Memory required for data: 9524367424
I0209 22:43:52.135608  6526 layer_factory.hpp:77] Creating layer conv8_2_conv8_2_relu_0_split
I0209 22:43:52.135615  6526 net.cpp:100] Creating Layer conv8_2_conv8_2_relu_0_split
I0209 22:43:52.135619  6526 net.cpp:434] conv8_2_conv8_2_relu_0_split <- conv8_2
I0209 22:43:52.135627  6526 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_0
I0209 22:43:52.135646  6526 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_1
I0209 22:43:52.135653  6526 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_2
I0209 22:43:52.135661  6526 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_3
I0209 22:43:52.135736  6526 net.cpp:150] Setting up conv8_2_conv8_2_relu_0_split
I0209 22:43:52.135746  6526 net.cpp:157] Top shape: 40 256 3 3 (92160)
I0209 22:43:52.135751  6526 net.cpp:157] Top shape: 40 256 3 3 (92160)
I0209 22:43:52.135754  6526 net.cpp:157] Top shape: 40 256 3 3 (92160)
I0209 22:43:52.135758  6526 net.cpp:157] Top shape: 40 256 3 3 (92160)
I0209 22:43:52.135761  6526 net.cpp:165] Memory required for data: 9525841984
I0209 22:43:52.135764  6526 layer_factory.hpp:77] Creating layer conv9_1
I0209 22:43:52.135776  6526 net.cpp:100] Creating Layer conv9_1
I0209 22:43:52.135779  6526 net.cpp:434] conv9_1 <- conv8_2_conv8_2_relu_0_split_0
I0209 22:43:52.135788  6526 net.cpp:408] conv9_1 -> conv9_1
I0209 22:43:52.136971  6526 net.cpp:150] Setting up conv9_1
I0209 22:43:52.136986  6526 net.cpp:157] Top shape: 40 128 3 3 (46080)
I0209 22:43:52.136991  6526 net.cpp:165] Memory required for data: 9526026304
I0209 22:43:52.136997  6526 layer_factory.hpp:77] Creating layer conv9_1_relu
I0209 22:43:52.137003  6526 net.cpp:100] Creating Layer conv9_1_relu
I0209 22:43:52.137009  6526 net.cpp:434] conv9_1_relu <- conv9_1
I0209 22:43:52.137015  6526 net.cpp:395] conv9_1_relu -> conv9_1 (in-place)
I0209 22:43:52.137336  6526 net.cpp:150] Setting up conv9_1_relu
I0209 22:43:52.137349  6526 net.cpp:157] Top shape: 40 128 3 3 (46080)
I0209 22:43:52.137353  6526 net.cpp:165] Memory required for data: 9526210624
I0209 22:43:52.137357  6526 layer_factory.hpp:77] Creating layer conv9_2
I0209 22:43:52.137368  6526 net.cpp:100] Creating Layer conv9_2
I0209 22:43:52.137372  6526 net.cpp:434] conv9_2 <- conv9_1
I0209 22:43:52.137382  6526 net.cpp:408] conv9_2 -> conv9_2
I0209 22:43:52.141046  6526 net.cpp:150] Setting up conv9_2
I0209 22:43:52.141062  6526 net.cpp:157] Top shape: 40 256 1 1 (10240)
I0209 22:43:52.141065  6526 net.cpp:165] Memory required for data: 9526251584
I0209 22:43:52.141072  6526 layer_factory.hpp:77] Creating layer conv9_2_relu
I0209 22:43:52.141079  6526 net.cpp:100] Creating Layer conv9_2_relu
I0209 22:43:52.141084  6526 net.cpp:434] conv9_2_relu <- conv9_2
I0209 22:43:52.141091  6526 net.cpp:395] conv9_2_relu -> conv9_2 (in-place)
I0209 22:43:52.141270  6526 net.cpp:150] Setting up conv9_2_relu
I0209 22:43:52.141288  6526 net.cpp:157] Top shape: 40 256 1 1 (10240)
I0209 22:43:52.141291  6526 net.cpp:165] Memory required for data: 9526292544
I0209 22:43:52.141295  6526 layer_factory.hpp:77] Creating layer conv9_2_conv9_2_relu_0_split
I0209 22:43:52.141301  6526 net.cpp:100] Creating Layer conv9_2_conv9_2_relu_0_split
I0209 22:43:52.141305  6526 net.cpp:434] conv9_2_conv9_2_relu_0_split <- conv9_2
I0209 22:43:52.141311  6526 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_0
I0209 22:43:52.141320  6526 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_1
I0209 22:43:52.141327  6526 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_2
I0209 22:43:52.141386  6526 net.cpp:150] Setting up conv9_2_conv9_2_relu_0_split
I0209 22:43:52.141396  6526 net.cpp:157] Top shape: 40 256 1 1 (10240)
I0209 22:43:52.141399  6526 net.cpp:157] Top shape: 40 256 1 1 (10240)
I0209 22:43:52.141403  6526 net.cpp:157] Top shape: 40 256 1 1 (10240)
I0209 22:43:52.141407  6526 net.cpp:165] Memory required for data: 9526415424
I0209 22:43:52.141410  6526 layer_factory.hpp:77] Creating layer conv4_3_norm
I0209 22:43:52.141418  6526 net.cpp:100] Creating Layer conv4_3_norm
I0209 22:43:52.141423  6526 net.cpp:434] conv4_3_norm <- conv4_3_relu4_3_0_split_1
I0209 22:43:52.141429  6526 net.cpp:408] conv4_3_norm -> conv4_3_norm
I0209 22:43:52.141595  6526 net.cpp:150] Setting up conv4_3_norm
I0209 22:43:52.141604  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:52.141618  6526 net.cpp:165] Memory required for data: 9644707904
I0209 22:43:52.141625  6526 layer_factory.hpp:77] Creating layer conv4_3_norm_conv4_3_norm_0_split
I0209 22:43:52.141630  6526 net.cpp:100] Creating Layer conv4_3_norm_conv4_3_norm_0_split
I0209 22:43:52.141634  6526 net.cpp:434] conv4_3_norm_conv4_3_norm_0_split <- conv4_3_norm
I0209 22:43:52.141640  6526 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_0
I0209 22:43:52.141646  6526 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_1
I0209 22:43:52.141654  6526 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_2
I0209 22:43:52.141707  6526 net.cpp:150] Setting up conv4_3_norm_conv4_3_norm_0_split
I0209 22:43:52.141716  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:52.141719  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:52.141723  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:52.141726  6526 net.cpp:165] Memory required for data: 9999585344
I0209 22:43:52.141731  6526 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc
I0209 22:43:52.141739  6526 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc
I0209 22:43:52.141743  6526 net.cpp:434] conv4_3_norm_mbox_loc <- conv4_3_norm_conv4_3_norm_0_split_0
I0209 22:43:52.141751  6526 net.cpp:408] conv4_3_norm_mbox_loc -> conv4_3_norm_mbox_loc
I0209 22:43:52.143513  6526 net.cpp:150] Setting up conv4_3_norm_mbox_loc
I0209 22:43:52.143530  6526 net.cpp:157] Top shape: 40 16 38 38 (924160)
I0209 22:43:52.143534  6526 net.cpp:165] Memory required for data: 10003281984
I0209 22:43:52.143542  6526 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_perm
I0209 22:43:52.143556  6526 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_perm
I0209 22:43:52.143561  6526 net.cpp:434] conv4_3_norm_mbox_loc_perm <- conv4_3_norm_mbox_loc
I0209 22:43:52.143568  6526 net.cpp:408] conv4_3_norm_mbox_loc_perm -> conv4_3_norm_mbox_loc_perm
I0209 22:43:52.143689  6526 net.cpp:150] Setting up conv4_3_norm_mbox_loc_perm
I0209 22:43:52.143700  6526 net.cpp:157] Top shape: 40 38 38 16 (924160)
I0209 22:43:52.143704  6526 net.cpp:165] Memory required for data: 10006978624
I0209 22:43:52.143707  6526 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_flat
I0209 22:43:52.143714  6526 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_flat
I0209 22:43:52.143718  6526 net.cpp:434] conv4_3_norm_mbox_loc_flat <- conv4_3_norm_mbox_loc_perm
I0209 22:43:52.143723  6526 net.cpp:408] conv4_3_norm_mbox_loc_flat -> conv4_3_norm_mbox_loc_flat
I0209 22:43:52.143760  6526 net.cpp:150] Setting up conv4_3_norm_mbox_loc_flat
I0209 22:43:52.143769  6526 net.cpp:157] Top shape: 40 23104 (924160)
I0209 22:43:52.143774  6526 net.cpp:165] Memory required for data: 10010675264
I0209 22:43:52.143776  6526 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf
I0209 22:43:52.143793  6526 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf
I0209 22:43:52.143798  6526 net.cpp:434] conv4_3_norm_mbox_conf <- conv4_3_norm_conv4_3_norm_0_split_1
I0209 22:43:52.143805  6526 net.cpp:408] conv4_3_norm_mbox_conf -> conv4_3_norm_mbox_conf
I0209 22:43:52.148367  6526 net.cpp:150] Setting up conv4_3_norm_mbox_conf
I0209 22:43:52.148383  6526 net.cpp:157] Top shape: 40 88 38 38 (5082880)
I0209 22:43:52.148388  6526 net.cpp:165] Memory required for data: 10031006784
I0209 22:43:52.148396  6526 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_perm
I0209 22:43:52.148406  6526 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_perm
I0209 22:43:52.148411  6526 net.cpp:434] conv4_3_norm_mbox_conf_perm <- conv4_3_norm_mbox_conf
I0209 22:43:52.148416  6526 net.cpp:408] conv4_3_norm_mbox_conf_perm -> conv4_3_norm_mbox_conf_perm
I0209 22:43:52.148535  6526 net.cpp:150] Setting up conv4_3_norm_mbox_conf_perm
I0209 22:43:52.148545  6526 net.cpp:157] Top shape: 40 38 38 88 (5082880)
I0209 22:43:52.148547  6526 net.cpp:165] Memory required for data: 10051338304
I0209 22:43:52.148562  6526 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_flat
I0209 22:43:52.148571  6526 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_flat
I0209 22:43:52.148576  6526 net.cpp:434] conv4_3_norm_mbox_conf_flat <- conv4_3_norm_mbox_conf_perm
I0209 22:43:52.148581  6526 net.cpp:408] conv4_3_norm_mbox_conf_flat -> conv4_3_norm_mbox_conf_flat
I0209 22:43:52.148612  6526 net.cpp:150] Setting up conv4_3_norm_mbox_conf_flat
I0209 22:43:52.148618  6526 net.cpp:157] Top shape: 40 127072 (5082880)
I0209 22:43:52.148622  6526 net.cpp:165] Memory required for data: 10071669824
I0209 22:43:52.148625  6526 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_priorbox
I0209 22:43:52.148636  6526 net.cpp:100] Creating Layer conv4_3_norm_mbox_priorbox
I0209 22:43:52.148640  6526 net.cpp:434] conv4_3_norm_mbox_priorbox <- conv4_3_norm_conv4_3_norm_0_split_2
I0209 22:43:52.148646  6526 net.cpp:434] conv4_3_norm_mbox_priorbox <- data_data_0_split_1
I0209 22:43:52.148654  6526 net.cpp:408] conv4_3_norm_mbox_priorbox -> conv4_3_norm_mbox_priorbox
I0209 22:43:52.148686  6526 net.cpp:150] Setting up conv4_3_norm_mbox_priorbox
I0209 22:43:52.148694  6526 net.cpp:157] Top shape: 1 2 23104 (46208)
I0209 22:43:52.148697  6526 net.cpp:165] Memory required for data: 10071854656
I0209 22:43:52.148701  6526 layer_factory.hpp:77] Creating layer fc7_mbox_loc
I0209 22:43:52.148713  6526 net.cpp:100] Creating Layer fc7_mbox_loc
I0209 22:43:52.148717  6526 net.cpp:434] fc7_mbox_loc <- fc7_relu7_0_split_1
I0209 22:43:52.148725  6526 net.cpp:408] fc7_mbox_loc -> fc7_mbox_loc
I0209 22:43:52.151841  6526 net.cpp:150] Setting up fc7_mbox_loc
I0209 22:43:52.151857  6526 net.cpp:157] Top shape: 40 24 19 19 (346560)
I0209 22:43:52.151861  6526 net.cpp:165] Memory required for data: 10073240896
I0209 22:43:52.151868  6526 layer_factory.hpp:77] Creating layer fc7_mbox_loc_perm
I0209 22:43:52.151877  6526 net.cpp:100] Creating Layer fc7_mbox_loc_perm
I0209 22:43:52.151882  6526 net.cpp:434] fc7_mbox_loc_perm <- fc7_mbox_loc
I0209 22:43:52.151888  6526 net.cpp:408] fc7_mbox_loc_perm -> fc7_mbox_loc_perm
I0209 22:43:52.152007  6526 net.cpp:150] Setting up fc7_mbox_loc_perm
I0209 22:43:52.152016  6526 net.cpp:157] Top shape: 40 19 19 24 (346560)
I0209 22:43:52.152020  6526 net.cpp:165] Memory required for data: 10074627136
I0209 22:43:52.152024  6526 layer_factory.hpp:77] Creating layer fc7_mbox_loc_flat
I0209 22:43:52.152029  6526 net.cpp:100] Creating Layer fc7_mbox_loc_flat
I0209 22:43:52.152034  6526 net.cpp:434] fc7_mbox_loc_flat <- fc7_mbox_loc_perm
I0209 22:43:52.152040  6526 net.cpp:408] fc7_mbox_loc_flat -> fc7_mbox_loc_flat
I0209 22:43:52.152066  6526 net.cpp:150] Setting up fc7_mbox_loc_flat
I0209 22:43:52.152073  6526 net.cpp:157] Top shape: 40 8664 (346560)
I0209 22:43:52.152076  6526 net.cpp:165] Memory required for data: 10076013376
I0209 22:43:52.152081  6526 layer_factory.hpp:77] Creating layer fc7_mbox_conf
I0209 22:43:52.152092  6526 net.cpp:100] Creating Layer fc7_mbox_conf
I0209 22:43:52.152096  6526 net.cpp:434] fc7_mbox_conf <- fc7_relu7_0_split_2
I0209 22:43:52.152103  6526 net.cpp:408] fc7_mbox_conf -> fc7_mbox_conf
I0209 22:43:52.163193  6526 net.cpp:150] Setting up fc7_mbox_conf
I0209 22:43:52.163211  6526 net.cpp:157] Top shape: 40 132 19 19 (1906080)
I0209 22:43:52.163215  6526 net.cpp:165] Memory required for data: 10083637696
I0209 22:43:52.163223  6526 layer_factory.hpp:77] Creating layer fc7_mbox_conf_perm
I0209 22:43:52.163229  6526 net.cpp:100] Creating Layer fc7_mbox_conf_perm
I0209 22:43:52.163234  6526 net.cpp:434] fc7_mbox_conf_perm <- fc7_mbox_conf
I0209 22:43:52.163244  6526 net.cpp:408] fc7_mbox_conf_perm -> fc7_mbox_conf_perm
I0209 22:43:52.163362  6526 net.cpp:150] Setting up fc7_mbox_conf_perm
I0209 22:43:52.163372  6526 net.cpp:157] Top shape: 40 19 19 132 (1906080)
I0209 22:43:52.163375  6526 net.cpp:165] Memory required for data: 10091262016
I0209 22:43:52.163378  6526 layer_factory.hpp:77] Creating layer fc7_mbox_conf_flat
I0209 22:43:52.163386  6526 net.cpp:100] Creating Layer fc7_mbox_conf_flat
I0209 22:43:52.163401  6526 net.cpp:434] fc7_mbox_conf_flat <- fc7_mbox_conf_perm
I0209 22:43:52.163414  6526 net.cpp:408] fc7_mbox_conf_flat -> fc7_mbox_conf_flat
I0209 22:43:52.163444  6526 net.cpp:150] Setting up fc7_mbox_conf_flat
I0209 22:43:52.163452  6526 net.cpp:157] Top shape: 40 47652 (1906080)
I0209 22:43:52.163455  6526 net.cpp:165] Memory required for data: 10098886336
I0209 22:43:52.163460  6526 layer_factory.hpp:77] Creating layer fc7_mbox_priorbox
I0209 22:43:52.163467  6526 net.cpp:100] Creating Layer fc7_mbox_priorbox
I0209 22:43:52.163471  6526 net.cpp:434] fc7_mbox_priorbox <- fc7_relu7_0_split_3
I0209 22:43:52.163476  6526 net.cpp:434] fc7_mbox_priorbox <- data_data_0_split_2
I0209 22:43:52.163482  6526 net.cpp:408] fc7_mbox_priorbox -> fc7_mbox_priorbox
I0209 22:43:52.163512  6526 net.cpp:150] Setting up fc7_mbox_priorbox
I0209 22:43:52.163518  6526 net.cpp:157] Top shape: 1 2 8664 (17328)
I0209 22:43:52.163522  6526 net.cpp:165] Memory required for data: 10098955648
I0209 22:43:52.163525  6526 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc
I0209 22:43:52.163537  6526 net.cpp:100] Creating Layer conv6_2_mbox_loc
I0209 22:43:52.163542  6526 net.cpp:434] conv6_2_mbox_loc <- conv6_2_conv6_2_relu_0_split_1
I0209 22:43:52.163548  6526 net.cpp:408] conv6_2_mbox_loc -> conv6_2_mbox_loc
I0209 22:43:52.165863  6526 net.cpp:150] Setting up conv6_2_mbox_loc
I0209 22:43:52.165879  6526 net.cpp:157] Top shape: 40 24 10 10 (96000)
I0209 22:43:52.165884  6526 net.cpp:165] Memory required for data: 10099339648
I0209 22:43:52.165890  6526 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_perm
I0209 22:43:52.165900  6526 net.cpp:100] Creating Layer conv6_2_mbox_loc_perm
I0209 22:43:52.165905  6526 net.cpp:434] conv6_2_mbox_loc_perm <- conv6_2_mbox_loc
I0209 22:43:52.165911  6526 net.cpp:408] conv6_2_mbox_loc_perm -> conv6_2_mbox_loc_perm
I0209 22:43:52.166031  6526 net.cpp:150] Setting up conv6_2_mbox_loc_perm
I0209 22:43:52.166040  6526 net.cpp:157] Top shape: 40 10 10 24 (96000)
I0209 22:43:52.166050  6526 net.cpp:165] Memory required for data: 10099723648
I0209 22:43:52.166054  6526 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_flat
I0209 22:43:52.166060  6526 net.cpp:100] Creating Layer conv6_2_mbox_loc_flat
I0209 22:43:52.166064  6526 net.cpp:434] conv6_2_mbox_loc_flat <- conv6_2_mbox_loc_perm
I0209 22:43:52.166071  6526 net.cpp:408] conv6_2_mbox_loc_flat -> conv6_2_mbox_loc_flat
I0209 22:43:52.166097  6526 net.cpp:150] Setting up conv6_2_mbox_loc_flat
I0209 22:43:52.166103  6526 net.cpp:157] Top shape: 40 2400 (96000)
I0209 22:43:52.166106  6526 net.cpp:165] Memory required for data: 10100107648
I0209 22:43:52.166110  6526 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf
I0209 22:43:52.166122  6526 net.cpp:100] Creating Layer conv6_2_mbox_conf
I0209 22:43:52.166126  6526 net.cpp:434] conv6_2_mbox_conf <- conv6_2_conv6_2_relu_0_split_2
I0209 22:43:52.166133  6526 net.cpp:408] conv6_2_mbox_conf -> conv6_2_mbox_conf
I0209 22:43:52.172387  6526 net.cpp:150] Setting up conv6_2_mbox_conf
I0209 22:43:52.172405  6526 net.cpp:157] Top shape: 40 132 10 10 (528000)
I0209 22:43:52.172408  6526 net.cpp:165] Memory required for data: 10102219648
I0209 22:43:52.172415  6526 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_perm
I0209 22:43:52.172422  6526 net.cpp:100] Creating Layer conv6_2_mbox_conf_perm
I0209 22:43:52.172426  6526 net.cpp:434] conv6_2_mbox_conf_perm <- conv6_2_mbox_conf
I0209 22:43:52.172436  6526 net.cpp:408] conv6_2_mbox_conf_perm -> conv6_2_mbox_conf_perm
I0209 22:43:52.172557  6526 net.cpp:150] Setting up conv6_2_mbox_conf_perm
I0209 22:43:52.172566  6526 net.cpp:157] Top shape: 40 10 10 132 (528000)
I0209 22:43:52.172569  6526 net.cpp:165] Memory required for data: 10104331648
I0209 22:43:52.172574  6526 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_flat
I0209 22:43:52.172580  6526 net.cpp:100] Creating Layer conv6_2_mbox_conf_flat
I0209 22:43:52.172583  6526 net.cpp:434] conv6_2_mbox_conf_flat <- conv6_2_mbox_conf_perm
I0209 22:43:52.172590  6526 net.cpp:408] conv6_2_mbox_conf_flat -> conv6_2_mbox_conf_flat
I0209 22:43:52.172631  6526 net.cpp:150] Setting up conv6_2_mbox_conf_flat
I0209 22:43:52.172637  6526 net.cpp:157] Top shape: 40 13200 (528000)
I0209 22:43:52.172641  6526 net.cpp:165] Memory required for data: 10106443648
I0209 22:43:52.172644  6526 layer_factory.hpp:77] Creating layer conv6_2_mbox_priorbox
I0209 22:43:52.172652  6526 net.cpp:100] Creating Layer conv6_2_mbox_priorbox
I0209 22:43:52.172657  6526 net.cpp:434] conv6_2_mbox_priorbox <- conv6_2_conv6_2_relu_0_split_3
I0209 22:43:52.172662  6526 net.cpp:434] conv6_2_mbox_priorbox <- data_data_0_split_3
I0209 22:43:52.172669  6526 net.cpp:408] conv6_2_mbox_priorbox -> conv6_2_mbox_priorbox
I0209 22:43:52.172698  6526 net.cpp:150] Setting up conv6_2_mbox_priorbox
I0209 22:43:52.172704  6526 net.cpp:157] Top shape: 1 2 2400 (4800)
I0209 22:43:52.172708  6526 net.cpp:165] Memory required for data: 10106462848
I0209 22:43:52.172711  6526 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc
I0209 22:43:52.172722  6526 net.cpp:100] Creating Layer conv7_2_mbox_loc
I0209 22:43:52.172727  6526 net.cpp:434] conv7_2_mbox_loc <- conv7_2_conv7_2_relu_0_split_1
I0209 22:43:52.172734  6526 net.cpp:408] conv7_2_mbox_loc -> conv7_2_mbox_loc
I0209 22:43:52.174676  6526 net.cpp:150] Setting up conv7_2_mbox_loc
I0209 22:43:52.174692  6526 net.cpp:157] Top shape: 40 24 5 5 (24000)
I0209 22:43:52.174696  6526 net.cpp:165] Memory required for data: 10106558848
I0209 22:43:52.174703  6526 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_perm
I0209 22:43:52.174712  6526 net.cpp:100] Creating Layer conv7_2_mbox_loc_perm
I0209 22:43:52.174717  6526 net.cpp:434] conv7_2_mbox_loc_perm <- conv7_2_mbox_loc
I0209 22:43:52.174723  6526 net.cpp:408] conv7_2_mbox_loc_perm -> conv7_2_mbox_loc_perm
I0209 22:43:52.174842  6526 net.cpp:150] Setting up conv7_2_mbox_loc_perm
I0209 22:43:52.174851  6526 net.cpp:157] Top shape: 40 5 5 24 (24000)
I0209 22:43:52.174855  6526 net.cpp:165] Memory required for data: 10106654848
I0209 22:43:52.174859  6526 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_flat
I0209 22:43:52.174865  6526 net.cpp:100] Creating Layer conv7_2_mbox_loc_flat
I0209 22:43:52.174870  6526 net.cpp:434] conv7_2_mbox_loc_flat <- conv7_2_mbox_loc_perm
I0209 22:43:52.174875  6526 net.cpp:408] conv7_2_mbox_loc_flat -> conv7_2_mbox_loc_flat
I0209 22:43:52.174903  6526 net.cpp:150] Setting up conv7_2_mbox_loc_flat
I0209 22:43:52.174911  6526 net.cpp:157] Top shape: 40 600 (24000)
I0209 22:43:52.174914  6526 net.cpp:165] Memory required for data: 10106750848
I0209 22:43:52.174918  6526 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf
I0209 22:43:52.174928  6526 net.cpp:100] Creating Layer conv7_2_mbox_conf
I0209 22:43:52.174932  6526 net.cpp:434] conv7_2_mbox_conf <- conv7_2_conv7_2_relu_0_split_2
I0209 22:43:52.174940  6526 net.cpp:408] conv7_2_mbox_conf -> conv7_2_mbox_conf
I0209 22:43:52.178738  6526 net.cpp:150] Setting up conv7_2_mbox_conf
I0209 22:43:52.178755  6526 net.cpp:157] Top shape: 40 132 5 5 (132000)
I0209 22:43:52.178760  6526 net.cpp:165] Memory required for data: 10107278848
I0209 22:43:52.178766  6526 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_perm
I0209 22:43:52.178774  6526 net.cpp:100] Creating Layer conv7_2_mbox_conf_perm
I0209 22:43:52.178779  6526 net.cpp:434] conv7_2_mbox_conf_perm <- conv7_2_mbox_conf
I0209 22:43:52.178786  6526 net.cpp:408] conv7_2_mbox_conf_perm -> conv7_2_mbox_conf_perm
I0209 22:43:52.178910  6526 net.cpp:150] Setting up conv7_2_mbox_conf_perm
I0209 22:43:52.178918  6526 net.cpp:157] Top shape: 40 5 5 132 (132000)
I0209 22:43:52.178922  6526 net.cpp:165] Memory required for data: 10107806848
I0209 22:43:52.178925  6526 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_flat
I0209 22:43:52.178931  6526 net.cpp:100] Creating Layer conv7_2_mbox_conf_flat
I0209 22:43:52.178936  6526 net.cpp:434] conv7_2_mbox_conf_flat <- conv7_2_mbox_conf_perm
I0209 22:43:52.178942  6526 net.cpp:408] conv7_2_mbox_conf_flat -> conv7_2_mbox_conf_flat
I0209 22:43:52.178970  6526 net.cpp:150] Setting up conv7_2_mbox_conf_flat
I0209 22:43:52.178987  6526 net.cpp:157] Top shape: 40 3300 (132000)
I0209 22:43:52.178992  6526 net.cpp:165] Memory required for data: 10108334848
I0209 22:43:52.178994  6526 layer_factory.hpp:77] Creating layer conv7_2_mbox_priorbox
I0209 22:43:52.179004  6526 net.cpp:100] Creating Layer conv7_2_mbox_priorbox
I0209 22:43:52.179008  6526 net.cpp:434] conv7_2_mbox_priorbox <- conv7_2_conv7_2_relu_0_split_3
I0209 22:43:52.179013  6526 net.cpp:434] conv7_2_mbox_priorbox <- data_data_0_split_4
I0209 22:43:52.179021  6526 net.cpp:408] conv7_2_mbox_priorbox -> conv7_2_mbox_priorbox
I0209 22:43:52.179052  6526 net.cpp:150] Setting up conv7_2_mbox_priorbox
I0209 22:43:52.179064  6526 net.cpp:157] Top shape: 1 2 600 (1200)
I0209 22:43:52.179067  6526 net.cpp:165] Memory required for data: 10108339648
I0209 22:43:52.179070  6526 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc
I0209 22:43:52.179081  6526 net.cpp:100] Creating Layer conv8_2_mbox_loc
I0209 22:43:52.179086  6526 net.cpp:434] conv8_2_mbox_loc <- conv8_2_conv8_2_relu_0_split_1
I0209 22:43:52.179093  6526 net.cpp:408] conv8_2_mbox_loc -> conv8_2_mbox_loc
I0209 22:43:52.180389  6526 net.cpp:150] Setting up conv8_2_mbox_loc
I0209 22:43:52.180407  6526 net.cpp:157] Top shape: 40 16 3 3 (5760)
I0209 22:43:52.180410  6526 net.cpp:165] Memory required for data: 10108362688
I0209 22:43:52.180429  6526 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_perm
I0209 22:43:52.180438  6526 net.cpp:100] Creating Layer conv8_2_mbox_loc_perm
I0209 22:43:52.180441  6526 net.cpp:434] conv8_2_mbox_loc_perm <- conv8_2_mbox_loc
I0209 22:43:52.180447  6526 net.cpp:408] conv8_2_mbox_loc_perm -> conv8_2_mbox_loc_perm
I0209 22:43:52.180570  6526 net.cpp:150] Setting up conv8_2_mbox_loc_perm
I0209 22:43:52.180582  6526 net.cpp:157] Top shape: 40 3 3 16 (5760)
I0209 22:43:52.180584  6526 net.cpp:165] Memory required for data: 10108385728
I0209 22:43:52.180588  6526 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_flat
I0209 22:43:52.180594  6526 net.cpp:100] Creating Layer conv8_2_mbox_loc_flat
I0209 22:43:52.180598  6526 net.cpp:434] conv8_2_mbox_loc_flat <- conv8_2_mbox_loc_perm
I0209 22:43:52.180604  6526 net.cpp:408] conv8_2_mbox_loc_flat -> conv8_2_mbox_loc_flat
I0209 22:43:52.180634  6526 net.cpp:150] Setting up conv8_2_mbox_loc_flat
I0209 22:43:52.180639  6526 net.cpp:157] Top shape: 40 144 (5760)
I0209 22:43:52.180642  6526 net.cpp:165] Memory required for data: 10108408768
I0209 22:43:52.180646  6526 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf
I0209 22:43:52.180656  6526 net.cpp:100] Creating Layer conv8_2_mbox_conf
I0209 22:43:52.180660  6526 net.cpp:434] conv8_2_mbox_conf <- conv8_2_conv8_2_relu_0_split_2
I0209 22:43:52.180670  6526 net.cpp:408] conv8_2_mbox_conf -> conv8_2_mbox_conf
I0209 22:43:52.183686  6526 net.cpp:150] Setting up conv8_2_mbox_conf
I0209 22:43:52.183702  6526 net.cpp:157] Top shape: 40 88 3 3 (31680)
I0209 22:43:52.183706  6526 net.cpp:165] Memory required for data: 10108535488
I0209 22:43:52.183713  6526 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_perm
I0209 22:43:52.183722  6526 net.cpp:100] Creating Layer conv8_2_mbox_conf_perm
I0209 22:43:52.183734  6526 net.cpp:434] conv8_2_mbox_conf_perm <- conv8_2_mbox_conf
I0209 22:43:52.183740  6526 net.cpp:408] conv8_2_mbox_conf_perm -> conv8_2_mbox_conf_perm
I0209 22:43:52.183864  6526 net.cpp:150] Setting up conv8_2_mbox_conf_perm
I0209 22:43:52.183873  6526 net.cpp:157] Top shape: 40 3 3 88 (31680)
I0209 22:43:52.183877  6526 net.cpp:165] Memory required for data: 10108662208
I0209 22:43:52.183881  6526 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_flat
I0209 22:43:52.183887  6526 net.cpp:100] Creating Layer conv8_2_mbox_conf_flat
I0209 22:43:52.183892  6526 net.cpp:434] conv8_2_mbox_conf_flat <- conv8_2_mbox_conf_perm
I0209 22:43:52.183898  6526 net.cpp:408] conv8_2_mbox_conf_flat -> conv8_2_mbox_conf_flat
I0209 22:43:52.183926  6526 net.cpp:150] Setting up conv8_2_mbox_conf_flat
I0209 22:43:52.183933  6526 net.cpp:157] Top shape: 40 792 (31680)
I0209 22:43:52.183948  6526 net.cpp:165] Memory required for data: 10108788928
I0209 22:43:52.183951  6526 layer_factory.hpp:77] Creating layer conv8_2_mbox_priorbox
I0209 22:43:52.183959  6526 net.cpp:100] Creating Layer conv8_2_mbox_priorbox
I0209 22:43:52.183962  6526 net.cpp:434] conv8_2_mbox_priorbox <- conv8_2_conv8_2_relu_0_split_3
I0209 22:43:52.183967  6526 net.cpp:434] conv8_2_mbox_priorbox <- data_data_0_split_5
I0209 22:43:52.183975  6526 net.cpp:408] conv8_2_mbox_priorbox -> conv8_2_mbox_priorbox
I0209 22:43:52.184007  6526 net.cpp:150] Setting up conv8_2_mbox_priorbox
I0209 22:43:52.184021  6526 net.cpp:157] Top shape: 1 2 144 (288)
I0209 22:43:52.184025  6526 net.cpp:165] Memory required for data: 10108790080
I0209 22:43:52.184028  6526 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc
I0209 22:43:52.184039  6526 net.cpp:100] Creating Layer conv9_2_mbox_loc
I0209 22:43:52.184044  6526 net.cpp:434] conv9_2_mbox_loc <- conv9_2_conv9_2_relu_0_split_0
I0209 22:43:52.184051  6526 net.cpp:408] conv9_2_mbox_loc -> conv9_2_mbox_loc
I0209 22:43:52.185561  6526 net.cpp:150] Setting up conv9_2_mbox_loc
I0209 22:43:52.185577  6526 net.cpp:157] Top shape: 40 16 1 1 (640)
I0209 22:43:52.185581  6526 net.cpp:165] Memory required for data: 10108792640
I0209 22:43:52.185588  6526 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_perm
I0209 22:43:52.185597  6526 net.cpp:100] Creating Layer conv9_2_mbox_loc_perm
I0209 22:43:52.185602  6526 net.cpp:434] conv9_2_mbox_loc_perm <- conv9_2_mbox_loc
I0209 22:43:52.185609  6526 net.cpp:408] conv9_2_mbox_loc_perm -> conv9_2_mbox_loc_perm
I0209 22:43:52.185732  6526 net.cpp:150] Setting up conv9_2_mbox_loc_perm
I0209 22:43:52.185742  6526 net.cpp:157] Top shape: 40 1 1 16 (640)
I0209 22:43:52.185746  6526 net.cpp:165] Memory required for data: 10108795200
I0209 22:43:52.185750  6526 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_flat
I0209 22:43:52.185756  6526 net.cpp:100] Creating Layer conv9_2_mbox_loc_flat
I0209 22:43:52.185760  6526 net.cpp:434] conv9_2_mbox_loc_flat <- conv9_2_mbox_loc_perm
I0209 22:43:52.185765  6526 net.cpp:408] conv9_2_mbox_loc_flat -> conv9_2_mbox_loc_flat
I0209 22:43:52.185796  6526 net.cpp:150] Setting up conv9_2_mbox_loc_flat
I0209 22:43:52.185804  6526 net.cpp:157] Top shape: 40 16 (640)
I0209 22:43:52.185807  6526 net.cpp:165] Memory required for data: 10108797760
I0209 22:43:52.185811  6526 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf
I0209 22:43:52.185822  6526 net.cpp:100] Creating Layer conv9_2_mbox_conf
I0209 22:43:52.185827  6526 net.cpp:434] conv9_2_mbox_conf <- conv9_2_conv9_2_relu_0_split_1
I0209 22:43:52.185835  6526 net.cpp:408] conv9_2_mbox_conf -> conv9_2_mbox_conf
I0209 22:43:52.188843  6526 net.cpp:150] Setting up conv9_2_mbox_conf
I0209 22:43:52.188860  6526 net.cpp:157] Top shape: 40 88 1 1 (3520)
I0209 22:43:52.188864  6526 net.cpp:165] Memory required for data: 10108811840
I0209 22:43:52.188871  6526 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_perm
I0209 22:43:52.188879  6526 net.cpp:100] Creating Layer conv9_2_mbox_conf_perm
I0209 22:43:52.188885  6526 net.cpp:434] conv9_2_mbox_conf_perm <- conv9_2_mbox_conf
I0209 22:43:52.188892  6526 net.cpp:408] conv9_2_mbox_conf_perm -> conv9_2_mbox_conf_perm
I0209 22:43:52.189021  6526 net.cpp:150] Setting up conv9_2_mbox_conf_perm
I0209 22:43:52.189030  6526 net.cpp:157] Top shape: 40 1 1 88 (3520)
I0209 22:43:52.189034  6526 net.cpp:165] Memory required for data: 10108825920
I0209 22:43:52.189038  6526 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_flat
I0209 22:43:52.189043  6526 net.cpp:100] Creating Layer conv9_2_mbox_conf_flat
I0209 22:43:52.189048  6526 net.cpp:434] conv9_2_mbox_conf_flat <- conv9_2_mbox_conf_perm
I0209 22:43:52.189054  6526 net.cpp:408] conv9_2_mbox_conf_flat -> conv9_2_mbox_conf_flat
I0209 22:43:52.189082  6526 net.cpp:150] Setting up conv9_2_mbox_conf_flat
I0209 22:43:52.189090  6526 net.cpp:157] Top shape: 40 88 (3520)
I0209 22:43:52.189093  6526 net.cpp:165] Memory required for data: 10108840000
I0209 22:43:52.189096  6526 layer_factory.hpp:77] Creating layer conv9_2_mbox_priorbox
I0209 22:43:52.189113  6526 net.cpp:100] Creating Layer conv9_2_mbox_priorbox
I0209 22:43:52.189118  6526 net.cpp:434] conv9_2_mbox_priorbox <- conv9_2_conv9_2_relu_0_split_2
I0209 22:43:52.189123  6526 net.cpp:434] conv9_2_mbox_priorbox <- data_data_0_split_6
I0209 22:43:52.189131  6526 net.cpp:408] conv9_2_mbox_priorbox -> conv9_2_mbox_priorbox
I0209 22:43:52.189163  6526 net.cpp:150] Setting up conv9_2_mbox_priorbox
I0209 22:43:52.189179  6526 net.cpp:157] Top shape: 1 2 16 (32)
I0209 22:43:52.189183  6526 net.cpp:165] Memory required for data: 10108840128
I0209 22:43:52.189187  6526 layer_factory.hpp:77] Creating layer mbox_loc
I0209 22:43:52.189200  6526 net.cpp:100] Creating Layer mbox_loc
I0209 22:43:52.189205  6526 net.cpp:434] mbox_loc <- conv4_3_norm_mbox_loc_flat
I0209 22:43:52.189210  6526 net.cpp:434] mbox_loc <- fc7_mbox_loc_flat
I0209 22:43:52.189215  6526 net.cpp:434] mbox_loc <- conv6_2_mbox_loc_flat
I0209 22:43:52.189220  6526 net.cpp:434] mbox_loc <- conv7_2_mbox_loc_flat
I0209 22:43:52.189224  6526 net.cpp:434] mbox_loc <- conv8_2_mbox_loc_flat
I0209 22:43:52.189229  6526 net.cpp:434] mbox_loc <- conv9_2_mbox_loc_flat
I0209 22:43:52.189234  6526 net.cpp:408] mbox_loc -> mbox_loc
I0209 22:43:52.189270  6526 net.cpp:150] Setting up mbox_loc
I0209 22:43:52.189276  6526 net.cpp:157] Top shape: 40 34928 (1397120)
I0209 22:43:52.189280  6526 net.cpp:165] Memory required for data: 10114428608
I0209 22:43:52.189282  6526 layer_factory.hpp:77] Creating layer mbox_conf
I0209 22:43:52.189291  6526 net.cpp:100] Creating Layer mbox_conf
I0209 22:43:52.189296  6526 net.cpp:434] mbox_conf <- conv4_3_norm_mbox_conf_flat
I0209 22:43:52.189301  6526 net.cpp:434] mbox_conf <- fc7_mbox_conf_flat
I0209 22:43:52.189306  6526 net.cpp:434] mbox_conf <- conv6_2_mbox_conf_flat
I0209 22:43:52.189309  6526 net.cpp:434] mbox_conf <- conv7_2_mbox_conf_flat
I0209 22:43:52.189313  6526 net.cpp:434] mbox_conf <- conv8_2_mbox_conf_flat
I0209 22:43:52.189318  6526 net.cpp:434] mbox_conf <- conv9_2_mbox_conf_flat
I0209 22:43:52.189323  6526 net.cpp:408] mbox_conf -> mbox_conf
I0209 22:43:52.189353  6526 net.cpp:150] Setting up mbox_conf
I0209 22:43:52.189359  6526 net.cpp:157] Top shape: 40 192104 (7684160)
I0209 22:43:52.189363  6526 net.cpp:165] Memory required for data: 10145165248
I0209 22:43:52.189366  6526 layer_factory.hpp:77] Creating layer mbox_priorbox
I0209 22:43:52.189373  6526 net.cpp:100] Creating Layer mbox_priorbox
I0209 22:43:52.189376  6526 net.cpp:434] mbox_priorbox <- conv4_3_norm_mbox_priorbox
I0209 22:43:52.189381  6526 net.cpp:434] mbox_priorbox <- fc7_mbox_priorbox
I0209 22:43:52.189385  6526 net.cpp:434] mbox_priorbox <- conv6_2_mbox_priorbox
I0209 22:43:52.189389  6526 net.cpp:434] mbox_priorbox <- conv7_2_mbox_priorbox
I0209 22:43:52.189393  6526 net.cpp:434] mbox_priorbox <- conv8_2_mbox_priorbox
I0209 22:43:52.189398  6526 net.cpp:434] mbox_priorbox <- conv9_2_mbox_priorbox
I0209 22:43:52.189402  6526 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0209 22:43:52.189429  6526 net.cpp:150] Setting up mbox_priorbox
I0209 22:43:52.189435  6526 net.cpp:157] Top shape: 1 2 34928 (69856)
I0209 22:43:52.189437  6526 net.cpp:165] Memory required for data: 10145444672
I0209 22:43:52.189441  6526 layer_factory.hpp:77] Creating layer mbox_loss
I0209 22:43:52.189453  6526 net.cpp:100] Creating Layer mbox_loss
I0209 22:43:52.189457  6526 net.cpp:434] mbox_loss <- mbox_loc
I0209 22:43:52.189461  6526 net.cpp:434] mbox_loss <- mbox_conf
I0209 22:43:52.189465  6526 net.cpp:434] mbox_loss <- mbox_priorbox
I0209 22:43:52.189469  6526 net.cpp:434] mbox_loss <- label
I0209 22:43:52.189477  6526 net.cpp:408] mbox_loss -> mbox_loss
I0209 22:43:52.189545  6526 layer_factory.hpp:77] Creating layer mbox_loss_smooth_L1_loc
I0209 22:43:52.189659  6526 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0209 22:43:52.189672  6526 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0209 22:43:52.189995  6526 net.cpp:150] Setting up mbox_loss
I0209 22:43:52.190016  6526 net.cpp:157] Top shape: (1)
I0209 22:43:52.190021  6526 net.cpp:160]     with loss weight 1
I0209 22:43:52.190037  6526 net.cpp:165] Memory required for data: 10145444676
I0209 22:43:52.190042  6526 net.cpp:226] mbox_loss needs backward computation.
I0209 22:43:52.190048  6526 net.cpp:228] mbox_priorbox does not need backward computation.
I0209 22:43:52.190055  6526 net.cpp:226] mbox_conf needs backward computation.
I0209 22:43:52.190060  6526 net.cpp:226] mbox_loc needs backward computation.
I0209 22:43:52.190065  6526 net.cpp:228] conv9_2_mbox_priorbox does not need backward computation.
I0209 22:43:52.190069  6526 net.cpp:226] conv9_2_mbox_conf_flat needs backward computation.
I0209 22:43:52.190073  6526 net.cpp:226] conv9_2_mbox_conf_perm needs backward computation.
I0209 22:43:52.190076  6526 net.cpp:226] conv9_2_mbox_conf needs backward computation.
I0209 22:43:52.190080  6526 net.cpp:226] conv9_2_mbox_loc_flat needs backward computation.
I0209 22:43:52.190084  6526 net.cpp:226] conv9_2_mbox_loc_perm needs backward computation.
I0209 22:43:52.190088  6526 net.cpp:226] conv9_2_mbox_loc needs backward computation.
I0209 22:43:52.190093  6526 net.cpp:228] conv8_2_mbox_priorbox does not need backward computation.
I0209 22:43:52.190098  6526 net.cpp:226] conv8_2_mbox_conf_flat needs backward computation.
I0209 22:43:52.190101  6526 net.cpp:226] conv8_2_mbox_conf_perm needs backward computation.
I0209 22:43:52.190104  6526 net.cpp:226] conv8_2_mbox_conf needs backward computation.
I0209 22:43:52.190109  6526 net.cpp:226] conv8_2_mbox_loc_flat needs backward computation.
I0209 22:43:52.190111  6526 net.cpp:226] conv8_2_mbox_loc_perm needs backward computation.
I0209 22:43:52.190115  6526 net.cpp:226] conv8_2_mbox_loc needs backward computation.
I0209 22:43:52.190119  6526 net.cpp:228] conv7_2_mbox_priorbox does not need backward computation.
I0209 22:43:52.190124  6526 net.cpp:226] conv7_2_mbox_conf_flat needs backward computation.
I0209 22:43:52.190126  6526 net.cpp:226] conv7_2_mbox_conf_perm needs backward computation.
I0209 22:43:52.190130  6526 net.cpp:226] conv7_2_mbox_conf needs backward computation.
I0209 22:43:52.190134  6526 net.cpp:226] conv7_2_mbox_loc_flat needs backward computation.
I0209 22:43:52.190137  6526 net.cpp:226] conv7_2_mbox_loc_perm needs backward computation.
I0209 22:43:52.190140  6526 net.cpp:226] conv7_2_mbox_loc needs backward computation.
I0209 22:43:52.190145  6526 net.cpp:228] conv6_2_mbox_priorbox does not need backward computation.
I0209 22:43:52.190148  6526 net.cpp:226] conv6_2_mbox_conf_flat needs backward computation.
I0209 22:43:52.190152  6526 net.cpp:226] conv6_2_mbox_conf_perm needs backward computation.
I0209 22:43:52.190155  6526 net.cpp:226] conv6_2_mbox_conf needs backward computation.
I0209 22:43:52.190160  6526 net.cpp:226] conv6_2_mbox_loc_flat needs backward computation.
I0209 22:43:52.190162  6526 net.cpp:226] conv6_2_mbox_loc_perm needs backward computation.
I0209 22:43:52.190166  6526 net.cpp:226] conv6_2_mbox_loc needs backward computation.
I0209 22:43:52.190170  6526 net.cpp:228] fc7_mbox_priorbox does not need backward computation.
I0209 22:43:52.190174  6526 net.cpp:226] fc7_mbox_conf_flat needs backward computation.
I0209 22:43:52.190177  6526 net.cpp:226] fc7_mbox_conf_perm needs backward computation.
I0209 22:43:52.190181  6526 net.cpp:226] fc7_mbox_conf needs backward computation.
I0209 22:43:52.190186  6526 net.cpp:226] fc7_mbox_loc_flat needs backward computation.
I0209 22:43:52.190189  6526 net.cpp:226] fc7_mbox_loc_perm needs backward computation.
I0209 22:43:52.190193  6526 net.cpp:226] fc7_mbox_loc needs backward computation.
I0209 22:43:52.190198  6526 net.cpp:228] conv4_3_norm_mbox_priorbox does not need backward computation.
I0209 22:43:52.190202  6526 net.cpp:226] conv4_3_norm_mbox_conf_flat needs backward computation.
I0209 22:43:52.190207  6526 net.cpp:226] conv4_3_norm_mbox_conf_perm needs backward computation.
I0209 22:43:52.190210  6526 net.cpp:226] conv4_3_norm_mbox_conf needs backward computation.
I0209 22:43:52.190214  6526 net.cpp:226] conv4_3_norm_mbox_loc_flat needs backward computation.
I0209 22:43:52.190224  6526 net.cpp:226] conv4_3_norm_mbox_loc_perm needs backward computation.
I0209 22:43:52.190228  6526 net.cpp:226] conv4_3_norm_mbox_loc needs backward computation.
I0209 22:43:52.190234  6526 net.cpp:226] conv4_3_norm_conv4_3_norm_0_split needs backward computation.
I0209 22:43:52.190239  6526 net.cpp:226] conv4_3_norm needs backward computation.
I0209 22:43:52.190243  6526 net.cpp:226] conv9_2_conv9_2_relu_0_split needs backward computation.
I0209 22:43:52.190248  6526 net.cpp:226] conv9_2_relu needs backward computation.
I0209 22:43:52.190250  6526 net.cpp:226] conv9_2 needs backward computation.
I0209 22:43:52.190254  6526 net.cpp:226] conv9_1_relu needs backward computation.
I0209 22:43:52.190258  6526 net.cpp:226] conv9_1 needs backward computation.
I0209 22:43:52.190263  6526 net.cpp:226] conv8_2_conv8_2_relu_0_split needs backward computation.
I0209 22:43:52.190266  6526 net.cpp:226] conv8_2_relu needs backward computation.
I0209 22:43:52.190269  6526 net.cpp:226] conv8_2 needs backward computation.
I0209 22:43:52.190274  6526 net.cpp:226] conv8_1_relu needs backward computation.
I0209 22:43:52.190276  6526 net.cpp:226] conv8_1 needs backward computation.
I0209 22:43:52.190280  6526 net.cpp:226] conv7_2_conv7_2_relu_0_split needs backward computation.
I0209 22:43:52.190284  6526 net.cpp:226] conv7_2_relu needs backward computation.
I0209 22:43:52.190287  6526 net.cpp:226] conv7_2 needs backward computation.
I0209 22:43:52.190291  6526 net.cpp:226] conv7_1_relu needs backward computation.
I0209 22:43:52.190294  6526 net.cpp:226] conv7_1 needs backward computation.
I0209 22:43:52.190299  6526 net.cpp:226] conv6_2_conv6_2_relu_0_split needs backward computation.
I0209 22:43:52.190302  6526 net.cpp:226] conv6_2_relu needs backward computation.
I0209 22:43:52.190305  6526 net.cpp:226] conv6_2 needs backward computation.
I0209 22:43:52.190310  6526 net.cpp:226] conv6_1_relu needs backward computation.
I0209 22:43:52.190313  6526 net.cpp:226] conv6_1 needs backward computation.
I0209 22:43:52.190317  6526 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0209 22:43:52.190321  6526 net.cpp:226] relu7 needs backward computation.
I0209 22:43:52.190325  6526 net.cpp:226] fc7 needs backward computation.
I0209 22:43:52.190328  6526 net.cpp:226] relu6 needs backward computation.
I0209 22:43:52.190331  6526 net.cpp:226] fc6 needs backward computation.
I0209 22:43:52.190335  6526 net.cpp:226] pool5 needs backward computation.
I0209 22:43:52.190340  6526 net.cpp:226] relu5_3 needs backward computation.
I0209 22:43:52.190343  6526 net.cpp:226] conv5_3 needs backward computation.
I0209 22:43:52.190351  6526 net.cpp:226] relu5_2 needs backward computation.
I0209 22:43:52.190356  6526 net.cpp:226] conv5_2 needs backward computation.
I0209 22:43:52.190358  6526 net.cpp:226] relu5_1 needs backward computation.
I0209 22:43:52.190362  6526 net.cpp:226] conv5_1 needs backward computation.
I0209 22:43:52.190366  6526 net.cpp:226] pool4 needs backward computation.
I0209 22:43:52.190371  6526 net.cpp:226] conv4_3_relu4_3_0_split needs backward computation.
I0209 22:43:52.190374  6526 net.cpp:226] relu4_3 needs backward computation.
I0209 22:43:52.190377  6526 net.cpp:226] conv4_3 needs backward computation.
I0209 22:43:52.190382  6526 net.cpp:226] relu4_2 needs backward computation.
I0209 22:43:52.190384  6526 net.cpp:226] conv4_2 needs backward computation.
I0209 22:43:52.190387  6526 net.cpp:226] relu4_1 needs backward computation.
I0209 22:43:52.190392  6526 net.cpp:226] conv4_1 needs backward computation.
I0209 22:43:52.190395  6526 net.cpp:226] pool3 needs backward computation.
I0209 22:43:52.190398  6526 net.cpp:226] relu3_3 needs backward computation.
I0209 22:43:52.190402  6526 net.cpp:226] conv3_3 needs backward computation.
I0209 22:43:52.190407  6526 net.cpp:226] relu3_2 needs backward computation.
I0209 22:43:52.190409  6526 net.cpp:226] conv3_2 needs backward computation.
I0209 22:43:52.190413  6526 net.cpp:226] relu3_1 needs backward computation.
I0209 22:43:52.190423  6526 net.cpp:226] conv3_1 needs backward computation.
I0209 22:43:52.190428  6526 net.cpp:226] pool2 needs backward computation.
I0209 22:43:52.190431  6526 net.cpp:226] relu2_2 needs backward computation.
I0209 22:43:52.190434  6526 net.cpp:226] conv2_2 needs backward computation.
I0209 22:43:52.190438  6526 net.cpp:226] relu2_1 needs backward computation.
I0209 22:43:52.190441  6526 net.cpp:226] conv2_1 needs backward computation.
I0209 22:43:52.190445  6526 net.cpp:226] pool1 needs backward computation.
I0209 22:43:52.190449  6526 net.cpp:226] relu1_2 needs backward computation.
I0209 22:43:52.190454  6526 net.cpp:226] conv1_2 needs backward computation.
I0209 22:43:52.190459  6526 net.cpp:226] relu1_1 needs backward computation.
I0209 22:43:52.190461  6526 net.cpp:226] conv1_1_rgbd needs backward computation.
I0209 22:43:52.190467  6526 net.cpp:228] data_data_0_split does not need backward computation.
I0209 22:43:52.190472  6526 net.cpp:228] data does not need backward computation.
I0209 22:43:52.190475  6526 net.cpp:270] This network produces output mbox_loss
I0209 22:43:52.190557  6526 net.cpp:283] Network initialization done.
I0209 22:43:52.192929  6526 solver.cpp:196] Creating test net (#0) specified by test_net file: models/VGGNet/VOC0712/SSD_RGBD_test_300x300/test.prototxt
I0209 22:43:52.193738  6526 net.cpp:58] Initializing net from parameters: 
name: "VGG_VOC0712_SSD_RGBD_test_300x300_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: 126
    mean_value: 100
    mean_value: 108
    mean_value: 113
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 300
      width: 300
      interp_mode: LINEAR
    }
  }
  data_param {
    source: "examples/VOC0712/VOC0712_test_lmdb"
    batch_size: 40
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "data/VOC0712/labelmap_voc.prototxt"
  }
}
layer {
  name: "conv1_1_rgbd"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_rgbd"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_rgbd"
  top: "conv1_1_rgbd"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_rgbd"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 6
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "fc7"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv8_1"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv8_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_1_relu"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_relu"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv9_1"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv9_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_1_relu"
  type: "ReLU"
  bottom: "conv9_1"
  top: "conv9_1"
}
layer {
  name: "conv9_2"
  type: "Convolution"
  bottom: "conv9_1"
  top: "conv9_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_relu"
  type: "ReLU"
  bottom: "conv9_2"
  top: "conv9_2"
}
layer {
  name: "conv4_3_norm"
  type: "Normalize"
  bottom: "conv4_3"
  top: "conv4_3_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20
    }
    channel_shared: false
  }
}
layer {
  name: "conv4_3_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_loc"
  top: "conv4_3_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_loc_perm"
  top: "conv4_3_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 88
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_conf"
  top: "conv4_3_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_conf_perm"
  top: "conv4_3_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv4_3_norm"
  bottom: "data"
  top: "conv4_3_norm_mbox_priorbox"
  prior_box_param {
    min_size: 30
    max_size: 60
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 8
    offset: 0.5
  }
}
layer {
  name: "fc7_mbox_loc"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_loc_perm"
  type: "Permute"
  bottom: "fc7_mbox_loc"
  top: "fc7_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_loc_flat"
  type: "Flatten"
  bottom: "fc7_mbox_loc_perm"
  top: "fc7_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_conf"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 132
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_conf_perm"
  type: "Permute"
  bottom: "fc7_mbox_conf"
  top: "fc7_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_conf_flat"
  type: "Flatten"
  bottom: "fc7_mbox_conf_perm"
  top: "fc7_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_priorbox"
  type: "PriorBox"
  bottom: "fc7"
  bottom: "data"
  top: "fc7_mbox_priorbox"
  prior_box_param {
    min_size: 60
    max_size: 111
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 16
    offset: 0.5
  }
}
layer {
  name: "conv6_2_mbox_loc"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_loc"
  top: "conv6_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_loc_perm"
  top: "conv6_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_conf"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 132
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_conf"
  top: "conv6_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_conf_perm"
  top: "conv6_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv6_2"
  bottom: "data"
  top: "conv6_2_mbox_priorbox"
  prior_box_param {
    min_size: 111
    max_size: 162
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 32
    offset: 0.5
  }
}
layer {
  name: "conv7_2_mbox_loc"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_loc"
  top: "conv7_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_loc_perm"
  top: "conv7_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_conf"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 132
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_conf"
  top: "conv7_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_conf_perm"
  top: "conv7_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv7_2"
  bottom: "data"
  top: "conv7_2_mbox_priorbox"
  prior_box_param {
    min_size: 162
    max_size: 213
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 64
    offset: 0.5
  }
}
layer {
  name: "conv8_2_mbox_loc"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_loc"
  top: "conv8_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_loc_perm"
  top: "conv8_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_conf"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 88
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_conf"
  top: "conv8_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_conf_perm"
  top: "conv8_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv8_2"
  bottom: "data"
  top: "conv8_2_mbox_priorbox"
  prior_box_param {
    min_size: 213
    max_size: 264
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 100
    offset: 0.5
  }
}
layer {
  name: "conv9_2_mbox_loc"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_loc"
  top: "conv9_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_loc_perm"
  top: "conv9_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_conf"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 88
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_conf"
  top: "conv9_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_conf_perm"
  top: "conv9_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv9_2"
  bottom: "data"
  top: "conv9_2_mbox_priorbox"
  prior_box_param {
    min_size: 264
    max_size: 315
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 300
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_flat"
  bottom: "fc7_mbox_loc_flat"
  bottom: "conv6_2_mbox_loc_flat"
  bottom: "conv7_2_mbox_loc_flat"
  bottom: "conv8_2_mbox_loc_flat"
  bottom: "conv9_2_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_flat"
  bottom: "fc7_mbox_conf_flat"
  bottom: "conv6_2_mbox_conf_flat"
  bottom: "conv7_2_mbox_conf_flat"
  bottom: "conv8_2_mbox_conf_flat"
  bottom: "conv9_2_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_priorbox"
  bottom: "fc7_mbox_priorbox"
  bottom: "conv6_2_mbox_priorbox"
  bottom: "conv7_2_mbox_priorbox"
  bottom: "conv8_2_mbox_priorbox"
  bottom: "conv9_2_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_reshape"
  type: "Reshape"
  bottom: "mbox_conf"
  top: "mbox_conf_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: -1
      dim: 22
    }
  }
}
layer {
  name: "mbox_conf_softmax"
  type: "Softmax"
  bottom: "mbox_conf_reshape"
  top: "mbox_conf_softmax"
  softmax_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_flatten"
  type: "Flatten"
  bottom: "mbox_conf_softmax"
  top: "mbox_conf_flatten"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "detection_out"
  type: "DetectionOutput"
  bottom: "mbox_loc"
  bottom: "mbox_conf_flatten"
  bottom: "mbox_priorbox"
  top: "detection_out"
  include {
    phase: TEST
  }
  detection_output_param {
    num_classes: 22
    share_location: true
    background_label_id: 0
    nms_param {
      nms_threshold: 0.45
      top_k: 400
    }
    save_output_param {
      output_directory: "/home/dhall/data/VOCdevkit/results/VOC2007/SSD_RGBD_test_300x300/Main"
      output_name_prefix: "comp4_det_test_"
      output_format: "VOC"
      label_map_file: "data/VOC0712/labelmap_voc.prototxt"
      name_size_file: "data/VOC0712/test_name_size.txt"
      num_test_image: 2
    }
    code_type: CENTER_SIZE
    keep_top_k: 200
    confidence_threshold: 0.01
  }
}
layer {
  name: "detection_eval"
  type: "DetectionEvaluate"
  bottom: "detection_out"
  bottom: "label"
  top: "detection_eval"
  include {
    phase: TEST
  }
  detection_evaluate_param {
    num_classes: 22
    background_label_id: 0
    overlap_threshold: 0.5
    evaluate_difficult_gt: false
    name_size_file: "data/VOC0712/test_name_size.txt"
  }
}
I0209 22:43:52.194185  6526 layer_factory.hpp:77] Creating layer data
I0209 22:43:52.194268  6526 net.cpp:100] Creating Layer data
I0209 22:43:52.194278  6526 net.cpp:408] data -> data
I0209 22:43:52.194290  6526 net.cpp:408] data -> label
I0209 22:43:52.196172  6547 db_lmdb.cpp:35] Opened lmdb examples/VOC0712/VOC0712_test_lmdb
I0209 22:43:52.208945  6526 annotated_data_layer.cpp:62] output data size: 40,4,300,300
I0209 22:43:52.287010  6526 net.cpp:150] Setting up data
I0209 22:43:52.287050  6526 net.cpp:157] Top shape: 40 4 300 300 (14400000)
I0209 22:43:52.287057  6526 net.cpp:157] Top shape: 1 1 6 8 (48)
I0209 22:43:52.287060  6526 net.cpp:165] Memory required for data: 57600192
I0209 22:43:52.287067  6526 layer_factory.hpp:77] Creating layer data_data_0_split
I0209 22:43:52.287081  6526 net.cpp:100] Creating Layer data_data_0_split
I0209 22:43:52.287086  6526 net.cpp:434] data_data_0_split <- data
I0209 22:43:52.287094  6526 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0209 22:43:52.287106  6526 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0209 22:43:52.287113  6526 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0209 22:43:52.287120  6526 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0209 22:43:52.287127  6526 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0209 22:43:52.287132  6526 net.cpp:408] data_data_0_split -> data_data_0_split_5
I0209 22:43:52.287137  6526 net.cpp:408] data_data_0_split -> data_data_0_split_6
I0209 22:43:52.287327  6526 net.cpp:150] Setting up data_data_0_split
I0209 22:43:52.287336  6526 net.cpp:157] Top shape: 40 4 300 300 (14400000)
I0209 22:43:52.287341  6526 net.cpp:157] Top shape: 40 4 300 300 (14400000)
I0209 22:43:52.287345  6526 net.cpp:157] Top shape: 40 4 300 300 (14400000)
I0209 22:43:52.287349  6526 net.cpp:157] Top shape: 40 4 300 300 (14400000)
I0209 22:43:52.287353  6526 net.cpp:157] Top shape: 40 4 300 300 (14400000)
I0209 22:43:52.287358  6526 net.cpp:157] Top shape: 40 4 300 300 (14400000)
I0209 22:43:52.287362  6526 net.cpp:157] Top shape: 40 4 300 300 (14400000)
I0209 22:43:52.287365  6526 net.cpp:165] Memory required for data: 460800192
I0209 22:43:52.287369  6526 layer_factory.hpp:77] Creating layer conv1_1_rgbd
I0209 22:43:52.287382  6526 net.cpp:100] Creating Layer conv1_1_rgbd
I0209 22:43:52.287386  6526 net.cpp:434] conv1_1_rgbd <- data_data_0_split_0
I0209 22:43:52.287394  6526 net.cpp:408] conv1_1_rgbd -> conv1_1_rgbd
I0209 22:43:52.289091  6526 net.cpp:150] Setting up conv1_1_rgbd
I0209 22:43:52.289108  6526 net.cpp:157] Top shape: 40 64 300 300 (230400000)
I0209 22:43:52.289113  6526 net.cpp:165] Memory required for data: 1382400192
I0209 22:43:52.289124  6526 layer_factory.hpp:77] Creating layer relu1_1
I0209 22:43:52.289132  6526 net.cpp:100] Creating Layer relu1_1
I0209 22:43:52.289136  6526 net.cpp:434] relu1_1 <- conv1_1_rgbd
I0209 22:43:52.289141  6526 net.cpp:395] relu1_1 -> conv1_1_rgbd (in-place)
I0209 22:43:52.289559  6526 net.cpp:150] Setting up relu1_1
I0209 22:43:52.289573  6526 net.cpp:157] Top shape: 40 64 300 300 (230400000)
I0209 22:43:52.289577  6526 net.cpp:165] Memory required for data: 2304000192
I0209 22:43:52.289582  6526 layer_factory.hpp:77] Creating layer conv1_2
I0209 22:43:52.289592  6526 net.cpp:100] Creating Layer conv1_2
I0209 22:43:52.289597  6526 net.cpp:434] conv1_2 <- conv1_1_rgbd
I0209 22:43:52.289603  6526 net.cpp:408] conv1_2 -> conv1_2
I0209 22:43:52.291631  6526 net.cpp:150] Setting up conv1_2
I0209 22:43:52.291648  6526 net.cpp:157] Top shape: 40 64 300 300 (230400000)
I0209 22:43:52.291653  6526 net.cpp:165] Memory required for data: 3225600192
I0209 22:43:52.291663  6526 layer_factory.hpp:77] Creating layer relu1_2
I0209 22:43:52.291671  6526 net.cpp:100] Creating Layer relu1_2
I0209 22:43:52.291676  6526 net.cpp:434] relu1_2 <- conv1_2
I0209 22:43:52.291682  6526 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0209 22:43:52.291873  6526 net.cpp:150] Setting up relu1_2
I0209 22:43:52.291884  6526 net.cpp:157] Top shape: 40 64 300 300 (230400000)
I0209 22:43:52.291888  6526 net.cpp:165] Memory required for data: 4147200192
I0209 22:43:52.291893  6526 layer_factory.hpp:77] Creating layer pool1
I0209 22:43:52.291899  6526 net.cpp:100] Creating Layer pool1
I0209 22:43:52.291903  6526 net.cpp:434] pool1 <- conv1_2
I0209 22:43:52.291908  6526 net.cpp:408] pool1 -> pool1
I0209 22:43:52.291965  6526 net.cpp:150] Setting up pool1
I0209 22:43:52.291972  6526 net.cpp:157] Top shape: 40 64 150 150 (57600000)
I0209 22:43:52.291976  6526 net.cpp:165] Memory required for data: 4377600192
I0209 22:43:52.291980  6526 layer_factory.hpp:77] Creating layer conv2_1
I0209 22:43:52.291992  6526 net.cpp:100] Creating Layer conv2_1
I0209 22:43:52.291996  6526 net.cpp:434] conv2_1 <- pool1
I0209 22:43:52.292002  6526 net.cpp:408] conv2_1 -> conv2_1
I0209 22:43:52.293787  6526 net.cpp:150] Setting up conv2_1
I0209 22:43:52.293803  6526 net.cpp:157] Top shape: 40 128 150 150 (115200000)
I0209 22:43:52.293807  6526 net.cpp:165] Memory required for data: 4838400192
I0209 22:43:52.293818  6526 layer_factory.hpp:77] Creating layer relu2_1
I0209 22:43:52.293828  6526 net.cpp:100] Creating Layer relu2_1
I0209 22:43:52.293831  6526 net.cpp:434] relu2_1 <- conv2_1
I0209 22:43:52.293836  6526 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0209 22:43:52.294024  6526 net.cpp:150] Setting up relu2_1
I0209 22:43:52.294035  6526 net.cpp:157] Top shape: 40 128 150 150 (115200000)
I0209 22:43:52.294039  6526 net.cpp:165] Memory required for data: 5299200192
I0209 22:43:52.294044  6526 layer_factory.hpp:77] Creating layer conv2_2
I0209 22:43:52.294075  6526 net.cpp:100] Creating Layer conv2_2
I0209 22:43:52.294080  6526 net.cpp:434] conv2_2 <- conv2_1
I0209 22:43:52.294086  6526 net.cpp:408] conv2_2 -> conv2_2
I0209 22:43:52.296936  6526 net.cpp:150] Setting up conv2_2
I0209 22:43:52.296954  6526 net.cpp:157] Top shape: 40 128 150 150 (115200000)
I0209 22:43:52.296959  6526 net.cpp:165] Memory required for data: 5760000192
I0209 22:43:52.296967  6526 layer_factory.hpp:77] Creating layer relu2_2
I0209 22:43:52.296974  6526 net.cpp:100] Creating Layer relu2_2
I0209 22:43:52.296978  6526 net.cpp:434] relu2_2 <- conv2_2
I0209 22:43:52.296984  6526 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0209 22:43:52.297303  6526 net.cpp:150] Setting up relu2_2
I0209 22:43:52.297317  6526 net.cpp:157] Top shape: 40 128 150 150 (115200000)
I0209 22:43:52.297322  6526 net.cpp:165] Memory required for data: 6220800192
I0209 22:43:52.297325  6526 layer_factory.hpp:77] Creating layer pool2
I0209 22:43:52.297333  6526 net.cpp:100] Creating Layer pool2
I0209 22:43:52.297338  6526 net.cpp:434] pool2 <- conv2_2
I0209 22:43:52.297343  6526 net.cpp:408] pool2 -> pool2
I0209 22:43:52.297400  6526 net.cpp:150] Setting up pool2
I0209 22:43:52.297408  6526 net.cpp:157] Top shape: 40 128 75 75 (28800000)
I0209 22:43:52.297412  6526 net.cpp:165] Memory required for data: 6336000192
I0209 22:43:52.297415  6526 layer_factory.hpp:77] Creating layer conv3_1
I0209 22:43:52.297425  6526 net.cpp:100] Creating Layer conv3_1
I0209 22:43:52.297430  6526 net.cpp:434] conv3_1 <- pool2
I0209 22:43:52.297435  6526 net.cpp:408] conv3_1 -> conv3_1
I0209 22:43:52.301214  6526 net.cpp:150] Setting up conv3_1
I0209 22:43:52.301237  6526 net.cpp:157] Top shape: 40 256 75 75 (57600000)
I0209 22:43:52.301241  6526 net.cpp:165] Memory required for data: 6566400192
I0209 22:43:52.301254  6526 layer_factory.hpp:77] Creating layer relu3_1
I0209 22:43:52.301262  6526 net.cpp:100] Creating Layer relu3_1
I0209 22:43:52.301266  6526 net.cpp:434] relu3_1 <- conv3_1
I0209 22:43:52.301271  6526 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0209 22:43:52.301451  6526 net.cpp:150] Setting up relu3_1
I0209 22:43:52.301462  6526 net.cpp:157] Top shape: 40 256 75 75 (57600000)
I0209 22:43:52.301465  6526 net.cpp:165] Memory required for data: 6796800192
I0209 22:43:52.301470  6526 layer_factory.hpp:77] Creating layer conv3_2
I0209 22:43:52.301479  6526 net.cpp:100] Creating Layer conv3_2
I0209 22:43:52.301483  6526 net.cpp:434] conv3_2 <- conv3_1
I0209 22:43:52.301489  6526 net.cpp:408] conv3_2 -> conv3_2
I0209 22:43:52.307875  6526 net.cpp:150] Setting up conv3_2
I0209 22:43:52.307909  6526 net.cpp:157] Top shape: 40 256 75 75 (57600000)
I0209 22:43:52.307914  6526 net.cpp:165] Memory required for data: 7027200192
I0209 22:43:52.307922  6526 layer_factory.hpp:77] Creating layer relu3_2
I0209 22:43:52.307931  6526 net.cpp:100] Creating Layer relu3_2
I0209 22:43:52.307937  6526 net.cpp:434] relu3_2 <- conv3_2
I0209 22:43:52.307943  6526 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0209 22:43:52.308118  6526 net.cpp:150] Setting up relu3_2
I0209 22:43:52.308130  6526 net.cpp:157] Top shape: 40 256 75 75 (57600000)
I0209 22:43:52.308133  6526 net.cpp:165] Memory required for data: 7257600192
I0209 22:43:52.308137  6526 layer_factory.hpp:77] Creating layer conv3_3
I0209 22:43:52.308151  6526 net.cpp:100] Creating Layer conv3_3
I0209 22:43:52.308156  6526 net.cpp:434] conv3_3 <- conv3_2
I0209 22:43:52.308162  6526 net.cpp:408] conv3_3 -> conv3_3
I0209 22:43:52.319398  6526 net.cpp:150] Setting up conv3_3
I0209 22:43:52.319429  6526 net.cpp:157] Top shape: 40 256 75 75 (57600000)
I0209 22:43:52.319433  6526 net.cpp:165] Memory required for data: 7488000192
I0209 22:43:52.319442  6526 layer_factory.hpp:77] Creating layer relu3_3
I0209 22:43:52.319453  6526 net.cpp:100] Creating Layer relu3_3
I0209 22:43:52.319459  6526 net.cpp:434] relu3_3 <- conv3_3
I0209 22:43:52.319466  6526 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0209 22:43:52.319828  6526 net.cpp:150] Setting up relu3_3
I0209 22:43:52.319841  6526 net.cpp:157] Top shape: 40 256 75 75 (57600000)
I0209 22:43:52.319862  6526 net.cpp:165] Memory required for data: 7718400192
I0209 22:43:52.319867  6526 layer_factory.hpp:77] Creating layer pool3
I0209 22:43:52.319875  6526 net.cpp:100] Creating Layer pool3
I0209 22:43:52.319880  6526 net.cpp:434] pool3 <- conv3_3
I0209 22:43:52.319885  6526 net.cpp:408] pool3 -> pool3
I0209 22:43:52.319946  6526 net.cpp:150] Setting up pool3
I0209 22:43:52.319954  6526 net.cpp:157] Top shape: 40 256 38 38 (14786560)
I0209 22:43:52.319958  6526 net.cpp:165] Memory required for data: 7777546432
I0209 22:43:52.319962  6526 layer_factory.hpp:77] Creating layer conv4_1
I0209 22:43:52.319972  6526 net.cpp:100] Creating Layer conv4_1
I0209 22:43:52.319977  6526 net.cpp:434] conv4_1 <- pool3
I0209 22:43:52.319983  6526 net.cpp:408] conv4_1 -> conv4_1
I0209 22:43:52.330956  6526 net.cpp:150] Setting up conv4_1
I0209 22:43:52.330973  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:52.330977  6526 net.cpp:165] Memory required for data: 7895838912
I0209 22:43:52.330984  6526 layer_factory.hpp:77] Creating layer relu4_1
I0209 22:43:52.330992  6526 net.cpp:100] Creating Layer relu4_1
I0209 22:43:52.330996  6526 net.cpp:434] relu4_1 <- conv4_1
I0209 22:43:52.331002  6526 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0209 22:43:52.331184  6526 net.cpp:150] Setting up relu4_1
I0209 22:43:52.331195  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:52.331199  6526 net.cpp:165] Memory required for data: 8014131392
I0209 22:43:52.331203  6526 layer_factory.hpp:77] Creating layer conv4_2
I0209 22:43:52.331212  6526 net.cpp:100] Creating Layer conv4_2
I0209 22:43:52.331215  6526 net.cpp:434] conv4_2 <- conv4_1
I0209 22:43:52.331223  6526 net.cpp:408] conv4_2 -> conv4_2
I0209 22:43:52.352015  6526 net.cpp:150] Setting up conv4_2
I0209 22:43:52.352043  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:52.352048  6526 net.cpp:165] Memory required for data: 8132423872
I0209 22:43:52.352061  6526 layer_factory.hpp:77] Creating layer relu4_2
I0209 22:43:52.352072  6526 net.cpp:100] Creating Layer relu4_2
I0209 22:43:52.352077  6526 net.cpp:434] relu4_2 <- conv4_2
I0209 22:43:52.352083  6526 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0209 22:43:52.352274  6526 net.cpp:150] Setting up relu4_2
I0209 22:43:52.352285  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:52.352289  6526 net.cpp:165] Memory required for data: 8250716352
I0209 22:43:52.352293  6526 layer_factory.hpp:77] Creating layer conv4_3
I0209 22:43:52.352304  6526 net.cpp:100] Creating Layer conv4_3
I0209 22:43:52.352308  6526 net.cpp:434] conv4_3 <- conv4_2
I0209 22:43:52.352315  6526 net.cpp:408] conv4_3 -> conv4_3
I0209 22:43:52.373164  6526 net.cpp:150] Setting up conv4_3
I0209 22:43:52.373194  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:52.373198  6526 net.cpp:165] Memory required for data: 8369008832
I0209 22:43:52.373208  6526 layer_factory.hpp:77] Creating layer relu4_3
I0209 22:43:52.373217  6526 net.cpp:100] Creating Layer relu4_3
I0209 22:43:52.373222  6526 net.cpp:434] relu4_3 <- conv4_3
I0209 22:43:52.373229  6526 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0209 22:43:52.373566  6526 net.cpp:150] Setting up relu4_3
I0209 22:43:52.373580  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:52.373584  6526 net.cpp:165] Memory required for data: 8487301312
I0209 22:43:52.373589  6526 layer_factory.hpp:77] Creating layer conv4_3_relu4_3_0_split
I0209 22:43:52.373595  6526 net.cpp:100] Creating Layer conv4_3_relu4_3_0_split
I0209 22:43:52.373600  6526 net.cpp:434] conv4_3_relu4_3_0_split <- conv4_3
I0209 22:43:52.373605  6526 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_0
I0209 22:43:52.373613  6526 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_1
I0209 22:43:52.373672  6526 net.cpp:150] Setting up conv4_3_relu4_3_0_split
I0209 22:43:52.373682  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:52.373687  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:52.373706  6526 net.cpp:165] Memory required for data: 8723886272
I0209 22:43:52.373710  6526 layer_factory.hpp:77] Creating layer pool4
I0209 22:43:52.373718  6526 net.cpp:100] Creating Layer pool4
I0209 22:43:52.373723  6526 net.cpp:434] pool4 <- conv4_3_relu4_3_0_split_0
I0209 22:43:52.373729  6526 net.cpp:408] pool4 -> pool4
I0209 22:43:52.373785  6526 net.cpp:150] Setting up pool4
I0209 22:43:52.373791  6526 net.cpp:157] Top shape: 40 512 19 19 (7393280)
I0209 22:43:52.373795  6526 net.cpp:165] Memory required for data: 8753459392
I0209 22:43:52.373798  6526 layer_factory.hpp:77] Creating layer conv5_1
I0209 22:43:52.373808  6526 net.cpp:100] Creating Layer conv5_1
I0209 22:43:52.373812  6526 net.cpp:434] conv5_1 <- pool4
I0209 22:43:52.373821  6526 net.cpp:408] conv5_1 -> conv5_1
I0209 22:43:52.394855  6526 net.cpp:150] Setting up conv5_1
I0209 22:43:52.394883  6526 net.cpp:157] Top shape: 40 512 19 19 (7393280)
I0209 22:43:52.394887  6526 net.cpp:165] Memory required for data: 8783032512
I0209 22:43:52.394896  6526 layer_factory.hpp:77] Creating layer relu5_1
I0209 22:43:52.394904  6526 net.cpp:100] Creating Layer relu5_1
I0209 22:43:52.394911  6526 net.cpp:434] relu5_1 <- conv5_1
I0209 22:43:52.394918  6526 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0209 22:43:52.395114  6526 net.cpp:150] Setting up relu5_1
I0209 22:43:52.395126  6526 net.cpp:157] Top shape: 40 512 19 19 (7393280)
I0209 22:43:52.395130  6526 net.cpp:165] Memory required for data: 8812605632
I0209 22:43:52.395133  6526 layer_factory.hpp:77] Creating layer conv5_2
I0209 22:43:52.395146  6526 net.cpp:100] Creating Layer conv5_2
I0209 22:43:52.395150  6526 net.cpp:434] conv5_2 <- conv5_1
I0209 22:43:52.395157  6526 net.cpp:408] conv5_2 -> conv5_2
I0209 22:43:52.416147  6526 net.cpp:150] Setting up conv5_2
I0209 22:43:52.416175  6526 net.cpp:157] Top shape: 40 512 19 19 (7393280)
I0209 22:43:52.416179  6526 net.cpp:165] Memory required for data: 8842178752
I0209 22:43:52.416188  6526 layer_factory.hpp:77] Creating layer relu5_2
I0209 22:43:52.416198  6526 net.cpp:100] Creating Layer relu5_2
I0209 22:43:52.416204  6526 net.cpp:434] relu5_2 <- conv5_2
I0209 22:43:52.416211  6526 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0209 22:43:52.416415  6526 net.cpp:150] Setting up relu5_2
I0209 22:43:52.416426  6526 net.cpp:157] Top shape: 40 512 19 19 (7393280)
I0209 22:43:52.416430  6526 net.cpp:165] Memory required for data: 8871751872
I0209 22:43:52.416435  6526 layer_factory.hpp:77] Creating layer conv5_3
I0209 22:43:52.416446  6526 net.cpp:100] Creating Layer conv5_3
I0209 22:43:52.416450  6526 net.cpp:434] conv5_3 <- conv5_2
I0209 22:43:52.416458  6526 net.cpp:408] conv5_3 -> conv5_3
I0209 22:43:52.437407  6526 net.cpp:150] Setting up conv5_3
I0209 22:43:52.437435  6526 net.cpp:157] Top shape: 40 512 19 19 (7393280)
I0209 22:43:52.437440  6526 net.cpp:165] Memory required for data: 8901324992
I0209 22:43:52.437449  6526 layer_factory.hpp:77] Creating layer relu5_3
I0209 22:43:52.437464  6526 net.cpp:100] Creating Layer relu5_3
I0209 22:43:52.437470  6526 net.cpp:434] relu5_3 <- conv5_3
I0209 22:43:52.437477  6526 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0209 22:43:52.437821  6526 net.cpp:150] Setting up relu5_3
I0209 22:43:52.437835  6526 net.cpp:157] Top shape: 40 512 19 19 (7393280)
I0209 22:43:52.437839  6526 net.cpp:165] Memory required for data: 8930898112
I0209 22:43:52.437844  6526 layer_factory.hpp:77] Creating layer pool5
I0209 22:43:52.437851  6526 net.cpp:100] Creating Layer pool5
I0209 22:43:52.437855  6526 net.cpp:434] pool5 <- conv5_3
I0209 22:43:52.437863  6526 net.cpp:408] pool5 -> pool5
I0209 22:43:52.437927  6526 net.cpp:150] Setting up pool5
I0209 22:43:52.437935  6526 net.cpp:157] Top shape: 40 512 19 19 (7393280)
I0209 22:43:52.437939  6526 net.cpp:165] Memory required for data: 8960471232
I0209 22:43:52.437942  6526 layer_factory.hpp:77] Creating layer fc6
I0209 22:43:52.437957  6526 net.cpp:100] Creating Layer fc6
I0209 22:43:52.437960  6526 net.cpp:434] fc6 <- pool5
I0209 22:43:52.437966  6526 net.cpp:408] fc6 -> fc6
I0209 22:43:52.478314  6526 net.cpp:150] Setting up fc6
I0209 22:43:52.478344  6526 net.cpp:157] Top shape: 40 1024 19 19 (14786560)
I0209 22:43:52.478353  6526 net.cpp:165] Memory required for data: 9019617472
I0209 22:43:52.478363  6526 layer_factory.hpp:77] Creating layer relu6
I0209 22:43:52.478374  6526 net.cpp:100] Creating Layer relu6
I0209 22:43:52.478380  6526 net.cpp:434] relu6 <- fc6
I0209 22:43:52.478387  6526 net.cpp:395] relu6 -> fc6 (in-place)
I0209 22:43:52.478648  6526 net.cpp:150] Setting up relu6
I0209 22:43:52.478660  6526 net.cpp:157] Top shape: 40 1024 19 19 (14786560)
I0209 22:43:52.478664  6526 net.cpp:165] Memory required for data: 9078763712
I0209 22:43:52.478668  6526 layer_factory.hpp:77] Creating layer fc7
I0209 22:43:52.478682  6526 net.cpp:100] Creating Layer fc7
I0209 22:43:52.478687  6526 net.cpp:434] fc7 <- fc6
I0209 22:43:52.478693  6526 net.cpp:408] fc7 -> fc7
I0209 22:43:52.488917  6526 net.cpp:150] Setting up fc7
I0209 22:43:52.488934  6526 net.cpp:157] Top shape: 40 1024 19 19 (14786560)
I0209 22:43:52.488939  6526 net.cpp:165] Memory required for data: 9137909952
I0209 22:43:52.488945  6526 layer_factory.hpp:77] Creating layer relu7
I0209 22:43:52.488955  6526 net.cpp:100] Creating Layer relu7
I0209 22:43:52.488958  6526 net.cpp:434] relu7 <- fc7
I0209 22:43:52.488965  6526 net.cpp:395] relu7 -> fc7 (in-place)
I0209 22:43:52.489306  6526 net.cpp:150] Setting up relu7
I0209 22:43:52.489321  6526 net.cpp:157] Top shape: 40 1024 19 19 (14786560)
I0209 22:43:52.489326  6526 net.cpp:165] Memory required for data: 9197056192
I0209 22:43:52.489329  6526 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0209 22:43:52.489336  6526 net.cpp:100] Creating Layer fc7_relu7_0_split
I0209 22:43:52.489341  6526 net.cpp:434] fc7_relu7_0_split <- fc7
I0209 22:43:52.489348  6526 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0209 22:43:52.489356  6526 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0209 22:43:52.489367  6526 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0209 22:43:52.489373  6526 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_3
I0209 22:43:52.489469  6526 net.cpp:150] Setting up fc7_relu7_0_split
I0209 22:43:52.489477  6526 net.cpp:157] Top shape: 40 1024 19 19 (14786560)
I0209 22:43:52.489482  6526 net.cpp:157] Top shape: 40 1024 19 19 (14786560)
I0209 22:43:52.489486  6526 net.cpp:157] Top shape: 40 1024 19 19 (14786560)
I0209 22:43:52.489490  6526 net.cpp:157] Top shape: 40 1024 19 19 (14786560)
I0209 22:43:52.489493  6526 net.cpp:165] Memory required for data: 9433641152
I0209 22:43:52.489497  6526 layer_factory.hpp:77] Creating layer conv6_1
I0209 22:43:52.489508  6526 net.cpp:100] Creating Layer conv6_1
I0209 22:43:52.489512  6526 net.cpp:434] conv6_1 <- fc7_relu7_0_split_0
I0209 22:43:52.489521  6526 net.cpp:408] conv6_1 -> conv6_1
I0209 22:43:52.492919  6526 net.cpp:150] Setting up conv6_1
I0209 22:43:52.492936  6526 net.cpp:157] Top shape: 40 256 19 19 (3696640)
I0209 22:43:52.492940  6526 net.cpp:165] Memory required for data: 9448427712
I0209 22:43:52.492947  6526 layer_factory.hpp:77] Creating layer conv6_1_relu
I0209 22:43:52.492955  6526 net.cpp:100] Creating Layer conv6_1_relu
I0209 22:43:52.492960  6526 net.cpp:434] conv6_1_relu <- conv6_1
I0209 22:43:52.492965  6526 net.cpp:395] conv6_1_relu -> conv6_1 (in-place)
I0209 22:43:52.493304  6526 net.cpp:150] Setting up conv6_1_relu
I0209 22:43:52.493319  6526 net.cpp:157] Top shape: 40 256 19 19 (3696640)
I0209 22:43:52.493322  6526 net.cpp:165] Memory required for data: 9463214272
I0209 22:43:52.493326  6526 layer_factory.hpp:77] Creating layer conv6_2
I0209 22:43:52.493338  6526 net.cpp:100] Creating Layer conv6_2
I0209 22:43:52.493343  6526 net.cpp:434] conv6_2 <- conv6_1
I0209 22:43:52.493350  6526 net.cpp:408] conv6_2 -> conv6_2
I0209 22:43:52.504415  6526 net.cpp:150] Setting up conv6_2
I0209 22:43:52.504433  6526 net.cpp:157] Top shape: 40 512 10 10 (2048000)
I0209 22:43:52.504438  6526 net.cpp:165] Memory required for data: 9471406272
I0209 22:43:52.504451  6526 layer_factory.hpp:77] Creating layer conv6_2_relu
I0209 22:43:52.504477  6526 net.cpp:100] Creating Layer conv6_2_relu
I0209 22:43:52.504482  6526 net.cpp:434] conv6_2_relu <- conv6_2
I0209 22:43:52.504488  6526 net.cpp:395] conv6_2_relu -> conv6_2 (in-place)
I0209 22:43:52.504686  6526 net.cpp:150] Setting up conv6_2_relu
I0209 22:43:52.504698  6526 net.cpp:157] Top shape: 40 512 10 10 (2048000)
I0209 22:43:52.504703  6526 net.cpp:165] Memory required for data: 9479598272
I0209 22:43:52.504706  6526 layer_factory.hpp:77] Creating layer conv6_2_conv6_2_relu_0_split
I0209 22:43:52.504714  6526 net.cpp:100] Creating Layer conv6_2_conv6_2_relu_0_split
I0209 22:43:52.504719  6526 net.cpp:434] conv6_2_conv6_2_relu_0_split <- conv6_2
I0209 22:43:52.504724  6526 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_0
I0209 22:43:52.504732  6526 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_1
I0209 22:43:52.504739  6526 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_2
I0209 22:43:52.504745  6526 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_3
I0209 22:43:52.504840  6526 net.cpp:150] Setting up conv6_2_conv6_2_relu_0_split
I0209 22:43:52.504849  6526 net.cpp:157] Top shape: 40 512 10 10 (2048000)
I0209 22:43:52.504854  6526 net.cpp:157] Top shape: 40 512 10 10 (2048000)
I0209 22:43:52.504858  6526 net.cpp:157] Top shape: 40 512 10 10 (2048000)
I0209 22:43:52.504861  6526 net.cpp:157] Top shape: 40 512 10 10 (2048000)
I0209 22:43:52.504865  6526 net.cpp:165] Memory required for data: 9512366272
I0209 22:43:52.504868  6526 layer_factory.hpp:77] Creating layer conv7_1
I0209 22:43:52.504879  6526 net.cpp:100] Creating Layer conv7_1
I0209 22:43:52.504884  6526 net.cpp:434] conv7_1 <- conv6_2_conv6_2_relu_0_split_0
I0209 22:43:52.504891  6526 net.cpp:408] conv7_1 -> conv7_1
I0209 22:43:52.507014  6526 net.cpp:150] Setting up conv7_1
I0209 22:43:52.507030  6526 net.cpp:157] Top shape: 40 128 10 10 (512000)
I0209 22:43:52.507035  6526 net.cpp:165] Memory required for data: 9514414272
I0209 22:43:52.507041  6526 layer_factory.hpp:77] Creating layer conv7_1_relu
I0209 22:43:52.507048  6526 net.cpp:100] Creating Layer conv7_1_relu
I0209 22:43:52.507052  6526 net.cpp:434] conv7_1_relu <- conv7_1
I0209 22:43:52.507061  6526 net.cpp:395] conv7_1_relu -> conv7_1 (in-place)
I0209 22:43:52.507400  6526 net.cpp:150] Setting up conv7_1_relu
I0209 22:43:52.507414  6526 net.cpp:157] Top shape: 40 128 10 10 (512000)
I0209 22:43:52.507418  6526 net.cpp:165] Memory required for data: 9516462272
I0209 22:43:52.507422  6526 layer_factory.hpp:77] Creating layer conv7_2
I0209 22:43:52.507433  6526 net.cpp:100] Creating Layer conv7_2
I0209 22:43:52.507438  6526 net.cpp:434] conv7_2 <- conv7_1
I0209 22:43:52.507446  6526 net.cpp:408] conv7_2 -> conv7_2
I0209 22:43:52.511162  6526 net.cpp:150] Setting up conv7_2
I0209 22:43:52.511178  6526 net.cpp:157] Top shape: 40 256 5 5 (256000)
I0209 22:43:52.511183  6526 net.cpp:165] Memory required for data: 9517486272
I0209 22:43:52.511191  6526 layer_factory.hpp:77] Creating layer conv7_2_relu
I0209 22:43:52.511200  6526 net.cpp:100] Creating Layer conv7_2_relu
I0209 22:43:52.511205  6526 net.cpp:434] conv7_2_relu <- conv7_2
I0209 22:43:52.511211  6526 net.cpp:395] conv7_2_relu -> conv7_2 (in-place)
I0209 22:43:52.511562  6526 net.cpp:150] Setting up conv7_2_relu
I0209 22:43:52.511579  6526 net.cpp:157] Top shape: 40 256 5 5 (256000)
I0209 22:43:52.511582  6526 net.cpp:165] Memory required for data: 9518510272
I0209 22:43:52.511586  6526 layer_factory.hpp:77] Creating layer conv7_2_conv7_2_relu_0_split
I0209 22:43:52.511592  6526 net.cpp:100] Creating Layer conv7_2_conv7_2_relu_0_split
I0209 22:43:52.511596  6526 net.cpp:434] conv7_2_conv7_2_relu_0_split <- conv7_2
I0209 22:43:52.511602  6526 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_0
I0209 22:43:52.511610  6526 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_1
I0209 22:43:52.511618  6526 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_2
I0209 22:43:52.511636  6526 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_3
I0209 22:43:52.511739  6526 net.cpp:150] Setting up conv7_2_conv7_2_relu_0_split
I0209 22:43:52.511747  6526 net.cpp:157] Top shape: 40 256 5 5 (256000)
I0209 22:43:52.511752  6526 net.cpp:157] Top shape: 40 256 5 5 (256000)
I0209 22:43:52.511756  6526 net.cpp:157] Top shape: 40 256 5 5 (256000)
I0209 22:43:52.511760  6526 net.cpp:157] Top shape: 40 256 5 5 (256000)
I0209 22:43:52.511764  6526 net.cpp:165] Memory required for data: 9522606272
I0209 22:43:52.511767  6526 layer_factory.hpp:77] Creating layer conv8_1
I0209 22:43:52.511780  6526 net.cpp:100] Creating Layer conv8_1
I0209 22:43:52.511783  6526 net.cpp:434] conv8_1 <- conv7_2_conv7_2_relu_0_split_0
I0209 22:43:52.511790  6526 net.cpp:408] conv8_1 -> conv8_1
I0209 22:43:52.513262  6526 net.cpp:150] Setting up conv8_1
I0209 22:43:52.513276  6526 net.cpp:157] Top shape: 40 128 5 5 (128000)
I0209 22:43:52.513280  6526 net.cpp:165] Memory required for data: 9523118272
I0209 22:43:52.513288  6526 layer_factory.hpp:77] Creating layer conv8_1_relu
I0209 22:43:52.513294  6526 net.cpp:100] Creating Layer conv8_1_relu
I0209 22:43:52.513298  6526 net.cpp:434] conv8_1_relu <- conv8_1
I0209 22:43:52.513306  6526 net.cpp:395] conv8_1_relu -> conv8_1 (in-place)
I0209 22:43:52.513500  6526 net.cpp:150] Setting up conv8_1_relu
I0209 22:43:52.513512  6526 net.cpp:157] Top shape: 40 128 5 5 (128000)
I0209 22:43:52.513516  6526 net.cpp:165] Memory required for data: 9523630272
I0209 22:43:52.513520  6526 layer_factory.hpp:77] Creating layer conv8_2
I0209 22:43:52.513531  6526 net.cpp:100] Creating Layer conv8_2
I0209 22:43:52.513536  6526 net.cpp:434] conv8_2 <- conv8_1
I0209 22:43:52.513543  6526 net.cpp:408] conv8_2 -> conv8_2
I0209 22:43:52.517371  6526 net.cpp:150] Setting up conv8_2
I0209 22:43:52.517387  6526 net.cpp:157] Top shape: 40 256 3 3 (92160)
I0209 22:43:52.517392  6526 net.cpp:165] Memory required for data: 9523998912
I0209 22:43:52.517400  6526 layer_factory.hpp:77] Creating layer conv8_2_relu
I0209 22:43:52.517408  6526 net.cpp:100] Creating Layer conv8_2_relu
I0209 22:43:52.517412  6526 net.cpp:434] conv8_2_relu <- conv8_2
I0209 22:43:52.517418  6526 net.cpp:395] conv8_2_relu -> conv8_2 (in-place)
I0209 22:43:52.517760  6526 net.cpp:150] Setting up conv8_2_relu
I0209 22:43:52.517776  6526 net.cpp:157] Top shape: 40 256 3 3 (92160)
I0209 22:43:52.517779  6526 net.cpp:165] Memory required for data: 9524367552
I0209 22:43:52.517784  6526 layer_factory.hpp:77] Creating layer conv8_2_conv8_2_relu_0_split
I0209 22:43:52.517791  6526 net.cpp:100] Creating Layer conv8_2_conv8_2_relu_0_split
I0209 22:43:52.517794  6526 net.cpp:434] conv8_2_conv8_2_relu_0_split <- conv8_2
I0209 22:43:52.517801  6526 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_0
I0209 22:43:52.517808  6526 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_1
I0209 22:43:52.517817  6526 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_2
I0209 22:43:52.517822  6526 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_3
I0209 22:43:52.517923  6526 net.cpp:150] Setting up conv8_2_conv8_2_relu_0_split
I0209 22:43:52.517932  6526 net.cpp:157] Top shape: 40 256 3 3 (92160)
I0209 22:43:52.517937  6526 net.cpp:157] Top shape: 40 256 3 3 (92160)
I0209 22:43:52.517941  6526 net.cpp:157] Top shape: 40 256 3 3 (92160)
I0209 22:43:52.517946  6526 net.cpp:157] Top shape: 40 256 3 3 (92160)
I0209 22:43:52.517948  6526 net.cpp:165] Memory required for data: 9525842112
I0209 22:43:52.517952  6526 layer_factory.hpp:77] Creating layer conv9_1
I0209 22:43:52.517963  6526 net.cpp:100] Creating Layer conv9_1
I0209 22:43:52.517968  6526 net.cpp:434] conv9_1 <- conv8_2_conv8_2_relu_0_split_0
I0209 22:43:52.517974  6526 net.cpp:408] conv9_1 -> conv9_1
I0209 22:43:52.519331  6526 net.cpp:150] Setting up conv9_1
I0209 22:43:52.519347  6526 net.cpp:157] Top shape: 40 128 3 3 (46080)
I0209 22:43:52.519362  6526 net.cpp:165] Memory required for data: 9526026432
I0209 22:43:52.519371  6526 layer_factory.hpp:77] Creating layer conv9_1_relu
I0209 22:43:52.519379  6526 net.cpp:100] Creating Layer conv9_1_relu
I0209 22:43:52.519383  6526 net.cpp:434] conv9_1_relu <- conv9_1
I0209 22:43:52.519389  6526 net.cpp:395] conv9_1_relu -> conv9_1 (in-place)
I0209 22:43:52.519737  6526 net.cpp:150] Setting up conv9_1_relu
I0209 22:43:52.519752  6526 net.cpp:157] Top shape: 40 128 3 3 (46080)
I0209 22:43:52.519755  6526 net.cpp:165] Memory required for data: 9526210752
I0209 22:43:52.519759  6526 layer_factory.hpp:77] Creating layer conv9_2
I0209 22:43:52.519771  6526 net.cpp:100] Creating Layer conv9_2
I0209 22:43:52.519776  6526 net.cpp:434] conv9_2 <- conv9_1
I0209 22:43:52.519783  6526 net.cpp:408] conv9_2 -> conv9_2
I0209 22:43:52.523768  6526 net.cpp:150] Setting up conv9_2
I0209 22:43:52.523784  6526 net.cpp:157] Top shape: 40 256 1 1 (10240)
I0209 22:43:52.523789  6526 net.cpp:165] Memory required for data: 9526251712
I0209 22:43:52.523795  6526 layer_factory.hpp:77] Creating layer conv9_2_relu
I0209 22:43:52.523803  6526 net.cpp:100] Creating Layer conv9_2_relu
I0209 22:43:52.523808  6526 net.cpp:434] conv9_2_relu <- conv9_2
I0209 22:43:52.523814  6526 net.cpp:395] conv9_2_relu -> conv9_2 (in-place)
I0209 22:43:52.524013  6526 net.cpp:150] Setting up conv9_2_relu
I0209 22:43:52.524024  6526 net.cpp:157] Top shape: 40 256 1 1 (10240)
I0209 22:43:52.524027  6526 net.cpp:165] Memory required for data: 9526292672
I0209 22:43:52.524031  6526 layer_factory.hpp:77] Creating layer conv9_2_conv9_2_relu_0_split
I0209 22:43:52.524037  6526 net.cpp:100] Creating Layer conv9_2_conv9_2_relu_0_split
I0209 22:43:52.524041  6526 net.cpp:434] conv9_2_conv9_2_relu_0_split <- conv9_2
I0209 22:43:52.524049  6526 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_0
I0209 22:43:52.524055  6526 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_1
I0209 22:43:52.524062  6526 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_2
I0209 22:43:52.524142  6526 net.cpp:150] Setting up conv9_2_conv9_2_relu_0_split
I0209 22:43:52.524152  6526 net.cpp:157] Top shape: 40 256 1 1 (10240)
I0209 22:43:52.524155  6526 net.cpp:157] Top shape: 40 256 1 1 (10240)
I0209 22:43:52.524159  6526 net.cpp:157] Top shape: 40 256 1 1 (10240)
I0209 22:43:52.524163  6526 net.cpp:165] Memory required for data: 9526415552
I0209 22:43:52.524168  6526 layer_factory.hpp:77] Creating layer conv4_3_norm
I0209 22:43:52.524174  6526 net.cpp:100] Creating Layer conv4_3_norm
I0209 22:43:52.524178  6526 net.cpp:434] conv4_3_norm <- conv4_3_relu4_3_0_split_1
I0209 22:43:52.524186  6526 net.cpp:408] conv4_3_norm -> conv4_3_norm
I0209 22:43:52.524412  6526 net.cpp:150] Setting up conv4_3_norm
I0209 22:43:52.524421  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:52.524425  6526 net.cpp:165] Memory required for data: 9644708032
I0209 22:43:52.524430  6526 layer_factory.hpp:77] Creating layer conv4_3_norm_conv4_3_norm_0_split
I0209 22:43:52.524436  6526 net.cpp:100] Creating Layer conv4_3_norm_conv4_3_norm_0_split
I0209 22:43:52.524441  6526 net.cpp:434] conv4_3_norm_conv4_3_norm_0_split <- conv4_3_norm
I0209 22:43:52.524446  6526 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_0
I0209 22:43:52.524453  6526 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_1
I0209 22:43:52.524459  6526 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_2
I0209 22:43:52.524526  6526 net.cpp:150] Setting up conv4_3_norm_conv4_3_norm_0_split
I0209 22:43:52.524534  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:52.524538  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:52.524543  6526 net.cpp:157] Top shape: 40 512 38 38 (29573120)
I0209 22:43:52.524545  6526 net.cpp:165] Memory required for data: 9999585472
I0209 22:43:52.524549  6526 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc
I0209 22:43:52.524569  6526 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc
I0209 22:43:52.524575  6526 net.cpp:434] conv4_3_norm_mbox_loc <- conv4_3_norm_conv4_3_norm_0_split_0
I0209 22:43:52.524581  6526 net.cpp:408] conv4_3_norm_mbox_loc -> conv4_3_norm_mbox_loc
I0209 22:43:52.526396  6526 net.cpp:150] Setting up conv4_3_norm_mbox_loc
I0209 22:43:52.526412  6526 net.cpp:157] Top shape: 40 16 38 38 (924160)
I0209 22:43:52.526415  6526 net.cpp:165] Memory required for data: 10003282112
I0209 22:43:52.526422  6526 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_perm
I0209 22:43:52.526430  6526 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_perm
I0209 22:43:52.526434  6526 net.cpp:434] conv4_3_norm_mbox_loc_perm <- conv4_3_norm_mbox_loc
I0209 22:43:52.526443  6526 net.cpp:408] conv4_3_norm_mbox_loc_perm -> conv4_3_norm_mbox_loc_perm
I0209 22:43:52.526597  6526 net.cpp:150] Setting up conv4_3_norm_mbox_loc_perm
I0209 22:43:52.526605  6526 net.cpp:157] Top shape: 40 38 38 16 (924160)
I0209 22:43:52.526608  6526 net.cpp:165] Memory required for data: 10006978752
I0209 22:43:52.526612  6526 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_flat
I0209 22:43:52.526620  6526 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_flat
I0209 22:43:52.526624  6526 net.cpp:434] conv4_3_norm_mbox_loc_flat <- conv4_3_norm_mbox_loc_perm
I0209 22:43:52.526631  6526 net.cpp:408] conv4_3_norm_mbox_loc_flat -> conv4_3_norm_mbox_loc_flat
I0209 22:43:52.526672  6526 net.cpp:150] Setting up conv4_3_norm_mbox_loc_flat
I0209 22:43:52.526681  6526 net.cpp:157] Top shape: 40 23104 (924160)
I0209 22:43:52.526684  6526 net.cpp:165] Memory required for data: 10010675392
I0209 22:43:52.526688  6526 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf
I0209 22:43:52.526705  6526 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf
I0209 22:43:52.526710  6526 net.cpp:434] conv4_3_norm_mbox_conf <- conv4_3_norm_conv4_3_norm_0_split_1
I0209 22:43:52.526715  6526 net.cpp:408] conv4_3_norm_mbox_conf -> conv4_3_norm_mbox_conf
I0209 22:43:52.531448  6526 net.cpp:150] Setting up conv4_3_norm_mbox_conf
I0209 22:43:52.531466  6526 net.cpp:157] Top shape: 40 88 38 38 (5082880)
I0209 22:43:52.531469  6526 net.cpp:165] Memory required for data: 10031006912
I0209 22:43:52.531477  6526 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_perm
I0209 22:43:52.531484  6526 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_perm
I0209 22:43:52.531489  6526 net.cpp:434] conv4_3_norm_mbox_conf_perm <- conv4_3_norm_mbox_conf
I0209 22:43:52.531497  6526 net.cpp:408] conv4_3_norm_mbox_conf_perm -> conv4_3_norm_mbox_conf_perm
I0209 22:43:52.531652  6526 net.cpp:150] Setting up conv4_3_norm_mbox_conf_perm
I0209 22:43:52.531661  6526 net.cpp:157] Top shape: 40 38 38 88 (5082880)
I0209 22:43:52.531666  6526 net.cpp:165] Memory required for data: 10051338432
I0209 22:43:52.531669  6526 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_flat
I0209 22:43:52.531677  6526 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_flat
I0209 22:43:52.531680  6526 net.cpp:434] conv4_3_norm_mbox_conf_flat <- conv4_3_norm_mbox_conf_perm
I0209 22:43:52.531687  6526 net.cpp:408] conv4_3_norm_mbox_conf_flat -> conv4_3_norm_mbox_conf_flat
I0209 22:43:52.531723  6526 net.cpp:150] Setting up conv4_3_norm_mbox_conf_flat
I0209 22:43:52.531729  6526 net.cpp:157] Top shape: 40 127072 (5082880)
I0209 22:43:52.531733  6526 net.cpp:165] Memory required for data: 10071669952
I0209 22:43:52.531735  6526 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_priorbox
I0209 22:43:52.531744  6526 net.cpp:100] Creating Layer conv4_3_norm_mbox_priorbox
I0209 22:43:52.531749  6526 net.cpp:434] conv4_3_norm_mbox_priorbox <- conv4_3_norm_conv4_3_norm_0_split_2
I0209 22:43:52.531754  6526 net.cpp:434] conv4_3_norm_mbox_priorbox <- data_data_0_split_1
I0209 22:43:52.531759  6526 net.cpp:408] conv4_3_norm_mbox_priorbox -> conv4_3_norm_mbox_priorbox
I0209 22:43:52.531798  6526 net.cpp:150] Setting up conv4_3_norm_mbox_priorbox
I0209 22:43:52.531805  6526 net.cpp:157] Top shape: 1 2 23104 (46208)
I0209 22:43:52.531819  6526 net.cpp:165] Memory required for data: 10071854784
I0209 22:43:52.531823  6526 layer_factory.hpp:77] Creating layer fc7_mbox_loc
I0209 22:43:52.531834  6526 net.cpp:100] Creating Layer fc7_mbox_loc
I0209 22:43:52.531839  6526 net.cpp:434] fc7_mbox_loc <- fc7_relu7_0_split_1
I0209 22:43:52.531847  6526 net.cpp:408] fc7_mbox_loc -> fc7_mbox_loc
I0209 22:43:52.535135  6526 net.cpp:150] Setting up fc7_mbox_loc
I0209 22:43:52.535151  6526 net.cpp:157] Top shape: 40 24 19 19 (346560)
I0209 22:43:52.535156  6526 net.cpp:165] Memory required for data: 10073241024
I0209 22:43:52.535163  6526 layer_factory.hpp:77] Creating layer fc7_mbox_loc_perm
I0209 22:43:52.535171  6526 net.cpp:100] Creating Layer fc7_mbox_loc_perm
I0209 22:43:52.535176  6526 net.cpp:434] fc7_mbox_loc_perm <- fc7_mbox_loc
I0209 22:43:52.535181  6526 net.cpp:408] fc7_mbox_loc_perm -> fc7_mbox_loc_perm
I0209 22:43:52.535334  6526 net.cpp:150] Setting up fc7_mbox_loc_perm
I0209 22:43:52.535343  6526 net.cpp:157] Top shape: 40 19 19 24 (346560)
I0209 22:43:52.535347  6526 net.cpp:165] Memory required for data: 10074627264
I0209 22:43:52.535351  6526 layer_factory.hpp:77] Creating layer fc7_mbox_loc_flat
I0209 22:43:52.535358  6526 net.cpp:100] Creating Layer fc7_mbox_loc_flat
I0209 22:43:52.535362  6526 net.cpp:434] fc7_mbox_loc_flat <- fc7_mbox_loc_perm
I0209 22:43:52.535367  6526 net.cpp:408] fc7_mbox_loc_flat -> fc7_mbox_loc_flat
I0209 22:43:52.535403  6526 net.cpp:150] Setting up fc7_mbox_loc_flat
I0209 22:43:52.535410  6526 net.cpp:157] Top shape: 40 8664 (346560)
I0209 22:43:52.535413  6526 net.cpp:165] Memory required for data: 10076013504
I0209 22:43:52.535416  6526 layer_factory.hpp:77] Creating layer fc7_mbox_conf
I0209 22:43:52.535426  6526 net.cpp:100] Creating Layer fc7_mbox_conf
I0209 22:43:52.535431  6526 net.cpp:434] fc7_mbox_conf <- fc7_relu7_0_split_2
I0209 22:43:52.535439  6526 net.cpp:408] fc7_mbox_conf -> fc7_mbox_conf
I0209 22:43:52.546777  6526 net.cpp:150] Setting up fc7_mbox_conf
I0209 22:43:52.546799  6526 net.cpp:157] Top shape: 40 132 19 19 (1906080)
I0209 22:43:52.546804  6526 net.cpp:165] Memory required for data: 10083637824
I0209 22:43:52.546811  6526 layer_factory.hpp:77] Creating layer fc7_mbox_conf_perm
I0209 22:43:52.546820  6526 net.cpp:100] Creating Layer fc7_mbox_conf_perm
I0209 22:43:52.546826  6526 net.cpp:434] fc7_mbox_conf_perm <- fc7_mbox_conf
I0209 22:43:52.546833  6526 net.cpp:408] fc7_mbox_conf_perm -> fc7_mbox_conf_perm
I0209 22:43:52.546991  6526 net.cpp:150] Setting up fc7_mbox_conf_perm
I0209 22:43:52.547000  6526 net.cpp:157] Top shape: 40 19 19 132 (1906080)
I0209 22:43:52.547004  6526 net.cpp:165] Memory required for data: 10091262144
I0209 22:43:52.547008  6526 layer_factory.hpp:77] Creating layer fc7_mbox_conf_flat
I0209 22:43:52.547014  6526 net.cpp:100] Creating Layer fc7_mbox_conf_flat
I0209 22:43:52.547019  6526 net.cpp:434] fc7_mbox_conf_flat <- fc7_mbox_conf_perm
I0209 22:43:52.547025  6526 net.cpp:408] fc7_mbox_conf_flat -> fc7_mbox_conf_flat
I0209 22:43:52.547062  6526 net.cpp:150] Setting up fc7_mbox_conf_flat
I0209 22:43:52.547068  6526 net.cpp:157] Top shape: 40 47652 (1906080)
I0209 22:43:52.547072  6526 net.cpp:165] Memory required for data: 10098886464
I0209 22:43:52.547075  6526 layer_factory.hpp:77] Creating layer fc7_mbox_priorbox
I0209 22:43:52.547082  6526 net.cpp:100] Creating Layer fc7_mbox_priorbox
I0209 22:43:52.547087  6526 net.cpp:434] fc7_mbox_priorbox <- fc7_relu7_0_split_3
I0209 22:43:52.547092  6526 net.cpp:434] fc7_mbox_priorbox <- data_data_0_split_2
I0209 22:43:52.547099  6526 net.cpp:408] fc7_mbox_priorbox -> fc7_mbox_priorbox
I0209 22:43:52.547138  6526 net.cpp:150] Setting up fc7_mbox_priorbox
I0209 22:43:52.547147  6526 net.cpp:157] Top shape: 1 2 8664 (17328)
I0209 22:43:52.547149  6526 net.cpp:165] Memory required for data: 10098955776
I0209 22:43:52.547153  6526 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc
I0209 22:43:52.547165  6526 net.cpp:100] Creating Layer conv6_2_mbox_loc
I0209 22:43:52.547170  6526 net.cpp:434] conv6_2_mbox_loc <- conv6_2_conv6_2_relu_0_split_1
I0209 22:43:52.547190  6526 net.cpp:408] conv6_2_mbox_loc -> conv6_2_mbox_loc
I0209 22:43:52.549696  6526 net.cpp:150] Setting up conv6_2_mbox_loc
I0209 22:43:52.549713  6526 net.cpp:157] Top shape: 40 24 10 10 (96000)
I0209 22:43:52.549718  6526 net.cpp:165] Memory required for data: 10099339776
I0209 22:43:52.549726  6526 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_perm
I0209 22:43:52.549732  6526 net.cpp:100] Creating Layer conv6_2_mbox_loc_perm
I0209 22:43:52.549736  6526 net.cpp:434] conv6_2_mbox_loc_perm <- conv6_2_mbox_loc
I0209 22:43:52.549743  6526 net.cpp:408] conv6_2_mbox_loc_perm -> conv6_2_mbox_loc_perm
I0209 22:43:52.549896  6526 net.cpp:150] Setting up conv6_2_mbox_loc_perm
I0209 22:43:52.549906  6526 net.cpp:157] Top shape: 40 10 10 24 (96000)
I0209 22:43:52.549908  6526 net.cpp:165] Memory required for data: 10099723776
I0209 22:43:52.549912  6526 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_flat
I0209 22:43:52.549919  6526 net.cpp:100] Creating Layer conv6_2_mbox_loc_flat
I0209 22:43:52.549924  6526 net.cpp:434] conv6_2_mbox_loc_flat <- conv6_2_mbox_loc_perm
I0209 22:43:52.549929  6526 net.cpp:408] conv6_2_mbox_loc_flat -> conv6_2_mbox_loc_flat
I0209 22:43:52.549965  6526 net.cpp:150] Setting up conv6_2_mbox_loc_flat
I0209 22:43:52.549973  6526 net.cpp:157] Top shape: 40 2400 (96000)
I0209 22:43:52.549975  6526 net.cpp:165] Memory required for data: 10100107776
I0209 22:43:52.549979  6526 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf
I0209 22:43:52.549989  6526 net.cpp:100] Creating Layer conv6_2_mbox_conf
I0209 22:43:52.549994  6526 net.cpp:434] conv6_2_mbox_conf <- conv6_2_conv6_2_relu_0_split_2
I0209 22:43:52.550001  6526 net.cpp:408] conv6_2_mbox_conf -> conv6_2_mbox_conf
I0209 22:43:52.556470  6526 net.cpp:150] Setting up conv6_2_mbox_conf
I0209 22:43:52.556488  6526 net.cpp:157] Top shape: 40 132 10 10 (528000)
I0209 22:43:52.556491  6526 net.cpp:165] Memory required for data: 10102219776
I0209 22:43:52.556499  6526 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_perm
I0209 22:43:52.556506  6526 net.cpp:100] Creating Layer conv6_2_mbox_conf_perm
I0209 22:43:52.556510  6526 net.cpp:434] conv6_2_mbox_conf_perm <- conv6_2_mbox_conf
I0209 22:43:52.556517  6526 net.cpp:408] conv6_2_mbox_conf_perm -> conv6_2_mbox_conf_perm
I0209 22:43:52.556675  6526 net.cpp:150] Setting up conv6_2_mbox_conf_perm
I0209 22:43:52.556685  6526 net.cpp:157] Top shape: 40 10 10 132 (528000)
I0209 22:43:52.556689  6526 net.cpp:165] Memory required for data: 10104331776
I0209 22:43:52.556692  6526 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_flat
I0209 22:43:52.556699  6526 net.cpp:100] Creating Layer conv6_2_mbox_conf_flat
I0209 22:43:52.556702  6526 net.cpp:434] conv6_2_mbox_conf_flat <- conv6_2_mbox_conf_perm
I0209 22:43:52.556710  6526 net.cpp:408] conv6_2_mbox_conf_flat -> conv6_2_mbox_conf_flat
I0209 22:43:52.556746  6526 net.cpp:150] Setting up conv6_2_mbox_conf_flat
I0209 22:43:52.556753  6526 net.cpp:157] Top shape: 40 13200 (528000)
I0209 22:43:52.556756  6526 net.cpp:165] Memory required for data: 10106443776
I0209 22:43:52.556761  6526 layer_factory.hpp:77] Creating layer conv6_2_mbox_priorbox
I0209 22:43:52.556766  6526 net.cpp:100] Creating Layer conv6_2_mbox_priorbox
I0209 22:43:52.556771  6526 net.cpp:434] conv6_2_mbox_priorbox <- conv6_2_conv6_2_relu_0_split_3
I0209 22:43:52.556776  6526 net.cpp:434] conv6_2_mbox_priorbox <- data_data_0_split_3
I0209 22:43:52.556783  6526 net.cpp:408] conv6_2_mbox_priorbox -> conv6_2_mbox_priorbox
I0209 22:43:52.556823  6526 net.cpp:150] Setting up conv6_2_mbox_priorbox
I0209 22:43:52.556829  6526 net.cpp:157] Top shape: 1 2 2400 (4800)
I0209 22:43:52.556833  6526 net.cpp:165] Memory required for data: 10106462976
I0209 22:43:52.556835  6526 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc
I0209 22:43:52.556846  6526 net.cpp:100] Creating Layer conv7_2_mbox_loc
I0209 22:43:52.556850  6526 net.cpp:434] conv7_2_mbox_loc <- conv7_2_conv7_2_relu_0_split_1
I0209 22:43:52.556870  6526 net.cpp:408] conv7_2_mbox_loc -> conv7_2_mbox_loc
I0209 22:43:52.558563  6526 net.cpp:150] Setting up conv7_2_mbox_loc
I0209 22:43:52.558579  6526 net.cpp:157] Top shape: 40 24 5 5 (24000)
I0209 22:43:52.558584  6526 net.cpp:165] Memory required for data: 10106558976
I0209 22:43:52.558591  6526 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_perm
I0209 22:43:52.558599  6526 net.cpp:100] Creating Layer conv7_2_mbox_loc_perm
I0209 22:43:52.558604  6526 net.cpp:434] conv7_2_mbox_loc_perm <- conv7_2_mbox_loc
I0209 22:43:52.558611  6526 net.cpp:408] conv7_2_mbox_loc_perm -> conv7_2_mbox_loc_perm
I0209 22:43:52.558768  6526 net.cpp:150] Setting up conv7_2_mbox_loc_perm
I0209 22:43:52.558779  6526 net.cpp:157] Top shape: 40 5 5 24 (24000)
I0209 22:43:52.558781  6526 net.cpp:165] Memory required for data: 10106654976
I0209 22:43:52.558785  6526 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_flat
I0209 22:43:52.558791  6526 net.cpp:100] Creating Layer conv7_2_mbox_loc_flat
I0209 22:43:52.558795  6526 net.cpp:434] conv7_2_mbox_loc_flat <- conv7_2_mbox_loc_perm
I0209 22:43:52.558800  6526 net.cpp:408] conv7_2_mbox_loc_flat -> conv7_2_mbox_loc_flat
I0209 22:43:52.558837  6526 net.cpp:150] Setting up conv7_2_mbox_loc_flat
I0209 22:43:52.558843  6526 net.cpp:157] Top shape: 40 600 (24000)
I0209 22:43:52.558847  6526 net.cpp:165] Memory required for data: 10106750976
I0209 22:43:52.558851  6526 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf
I0209 22:43:52.558862  6526 net.cpp:100] Creating Layer conv7_2_mbox_conf
I0209 22:43:52.558867  6526 net.cpp:434] conv7_2_mbox_conf <- conv7_2_conv7_2_relu_0_split_2
I0209 22:43:52.558874  6526 net.cpp:408] conv7_2_mbox_conf -> conv7_2_mbox_conf
I0209 22:43:52.562815  6526 net.cpp:150] Setting up conv7_2_mbox_conf
I0209 22:43:52.562832  6526 net.cpp:157] Top shape: 40 132 5 5 (132000)
I0209 22:43:52.562836  6526 net.cpp:165] Memory required for data: 10107278976
I0209 22:43:52.562844  6526 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_perm
I0209 22:43:52.562852  6526 net.cpp:100] Creating Layer conv7_2_mbox_conf_perm
I0209 22:43:52.562856  6526 net.cpp:434] conv7_2_mbox_conf_perm <- conv7_2_mbox_conf
I0209 22:43:52.562863  6526 net.cpp:408] conv7_2_mbox_conf_perm -> conv7_2_mbox_conf_perm
I0209 22:43:52.563019  6526 net.cpp:150] Setting up conv7_2_mbox_conf_perm
I0209 22:43:52.563030  6526 net.cpp:157] Top shape: 40 5 5 132 (132000)
I0209 22:43:52.563033  6526 net.cpp:165] Memory required for data: 10107806976
I0209 22:43:52.563036  6526 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_flat
I0209 22:43:52.563042  6526 net.cpp:100] Creating Layer conv7_2_mbox_conf_flat
I0209 22:43:52.563046  6526 net.cpp:434] conv7_2_mbox_conf_flat <- conv7_2_mbox_conf_perm
I0209 22:43:52.563053  6526 net.cpp:408] conv7_2_mbox_conf_flat -> conv7_2_mbox_conf_flat
I0209 22:43:52.563089  6526 net.cpp:150] Setting up conv7_2_mbox_conf_flat
I0209 22:43:52.563097  6526 net.cpp:157] Top shape: 40 3300 (132000)
I0209 22:43:52.563100  6526 net.cpp:165] Memory required for data: 10108334976
I0209 22:43:52.563103  6526 layer_factory.hpp:77] Creating layer conv7_2_mbox_priorbox
I0209 22:43:52.563110  6526 net.cpp:100] Creating Layer conv7_2_mbox_priorbox
I0209 22:43:52.563114  6526 net.cpp:434] conv7_2_mbox_priorbox <- conv7_2_conv7_2_relu_0_split_3
I0209 22:43:52.563119  6526 net.cpp:434] conv7_2_mbox_priorbox <- data_data_0_split_4
I0209 22:43:52.563127  6526 net.cpp:408] conv7_2_mbox_priorbox -> conv7_2_mbox_priorbox
I0209 22:43:52.563163  6526 net.cpp:150] Setting up conv7_2_mbox_priorbox
I0209 22:43:52.563171  6526 net.cpp:157] Top shape: 1 2 600 (1200)
I0209 22:43:52.563174  6526 net.cpp:165] Memory required for data: 10108339776
I0209 22:43:52.563179  6526 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc
I0209 22:43:52.563189  6526 net.cpp:100] Creating Layer conv8_2_mbox_loc
I0209 22:43:52.563194  6526 net.cpp:434] conv8_2_mbox_loc <- conv8_2_conv8_2_relu_0_split_1
I0209 22:43:52.563200  6526 net.cpp:408] conv8_2_mbox_loc -> conv8_2_mbox_loc
I0209 22:43:52.564757  6526 net.cpp:150] Setting up conv8_2_mbox_loc
I0209 22:43:52.564784  6526 net.cpp:157] Top shape: 40 16 3 3 (5760)
I0209 22:43:52.564788  6526 net.cpp:165] Memory required for data: 10108362816
I0209 22:43:52.564808  6526 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_perm
I0209 22:43:52.564815  6526 net.cpp:100] Creating Layer conv8_2_mbox_loc_perm
I0209 22:43:52.564821  6526 net.cpp:434] conv8_2_mbox_loc_perm <- conv8_2_mbox_loc
I0209 22:43:52.564828  6526 net.cpp:408] conv8_2_mbox_loc_perm -> conv8_2_mbox_loc_perm
I0209 22:43:52.564990  6526 net.cpp:150] Setting up conv8_2_mbox_loc_perm
I0209 22:43:52.565001  6526 net.cpp:157] Top shape: 40 3 3 16 (5760)
I0209 22:43:52.565004  6526 net.cpp:165] Memory required for data: 10108385856
I0209 22:43:52.565008  6526 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_flat
I0209 22:43:52.565016  6526 net.cpp:100] Creating Layer conv8_2_mbox_loc_flat
I0209 22:43:52.565021  6526 net.cpp:434] conv8_2_mbox_loc_flat <- conv8_2_mbox_loc_perm
I0209 22:43:52.565026  6526 net.cpp:408] conv8_2_mbox_loc_flat -> conv8_2_mbox_loc_flat
I0209 22:43:52.565063  6526 net.cpp:150] Setting up conv8_2_mbox_loc_flat
I0209 22:43:52.565070  6526 net.cpp:157] Top shape: 40 144 (5760)
I0209 22:43:52.565073  6526 net.cpp:165] Memory required for data: 10108408896
I0209 22:43:52.565078  6526 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf
I0209 22:43:52.565088  6526 net.cpp:100] Creating Layer conv8_2_mbox_conf
I0209 22:43:52.565091  6526 net.cpp:434] conv8_2_mbox_conf <- conv8_2_conv8_2_relu_0_split_2
I0209 22:43:52.565099  6526 net.cpp:408] conv8_2_mbox_conf -> conv8_2_mbox_conf
I0209 22:43:52.568264  6526 net.cpp:150] Setting up conv8_2_mbox_conf
I0209 22:43:52.568281  6526 net.cpp:157] Top shape: 40 88 3 3 (31680)
I0209 22:43:52.568285  6526 net.cpp:165] Memory required for data: 10108535616
I0209 22:43:52.568292  6526 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_perm
I0209 22:43:52.568301  6526 net.cpp:100] Creating Layer conv8_2_mbox_conf_perm
I0209 22:43:52.568306  6526 net.cpp:434] conv8_2_mbox_conf_perm <- conv8_2_mbox_conf
I0209 22:43:52.568312  6526 net.cpp:408] conv8_2_mbox_conf_perm -> conv8_2_mbox_conf_perm
I0209 22:43:52.568470  6526 net.cpp:150] Setting up conv8_2_mbox_conf_perm
I0209 22:43:52.568480  6526 net.cpp:157] Top shape: 40 3 3 88 (31680)
I0209 22:43:52.568483  6526 net.cpp:165] Memory required for data: 10108662336
I0209 22:43:52.568487  6526 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_flat
I0209 22:43:52.568493  6526 net.cpp:100] Creating Layer conv8_2_mbox_conf_flat
I0209 22:43:52.568497  6526 net.cpp:434] conv8_2_mbox_conf_flat <- conv8_2_mbox_conf_perm
I0209 22:43:52.568505  6526 net.cpp:408] conv8_2_mbox_conf_flat -> conv8_2_mbox_conf_flat
I0209 22:43:52.568541  6526 net.cpp:150] Setting up conv8_2_mbox_conf_flat
I0209 22:43:52.568547  6526 net.cpp:157] Top shape: 40 792 (31680)
I0209 22:43:52.568550  6526 net.cpp:165] Memory required for data: 10108789056
I0209 22:43:52.568553  6526 layer_factory.hpp:77] Creating layer conv8_2_mbox_priorbox
I0209 22:43:52.568562  6526 net.cpp:100] Creating Layer conv8_2_mbox_priorbox
I0209 22:43:52.568567  6526 net.cpp:434] conv8_2_mbox_priorbox <- conv8_2_conv8_2_relu_0_split_3
I0209 22:43:52.568572  6526 net.cpp:434] conv8_2_mbox_priorbox <- data_data_0_split_5
I0209 22:43:52.568579  6526 net.cpp:408] conv8_2_mbox_priorbox -> conv8_2_mbox_priorbox
I0209 22:43:52.568615  6526 net.cpp:150] Setting up conv8_2_mbox_priorbox
I0209 22:43:52.568622  6526 net.cpp:157] Top shape: 1 2 144 (288)
I0209 22:43:52.568625  6526 net.cpp:165] Memory required for data: 10108790208
I0209 22:43:52.568629  6526 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc
I0209 22:43:52.568642  6526 net.cpp:100] Creating Layer conv9_2_mbox_loc
I0209 22:43:52.568647  6526 net.cpp:434] conv9_2_mbox_loc <- conv9_2_conv9_2_relu_0_split_0
I0209 22:43:52.568653  6526 net.cpp:408] conv9_2_mbox_loc -> conv9_2_mbox_loc
I0209 22:43:52.570207  6526 net.cpp:150] Setting up conv9_2_mbox_loc
I0209 22:43:52.570224  6526 net.cpp:157] Top shape: 40 16 1 1 (640)
I0209 22:43:52.570237  6526 net.cpp:165] Memory required for data: 10108792768
I0209 22:43:52.570245  6526 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_perm
I0209 22:43:52.570255  6526 net.cpp:100] Creating Layer conv9_2_mbox_loc_perm
I0209 22:43:52.570260  6526 net.cpp:434] conv9_2_mbox_loc_perm <- conv9_2_mbox_loc
I0209 22:43:52.570266  6526 net.cpp:408] conv9_2_mbox_loc_perm -> conv9_2_mbox_loc_perm
I0209 22:43:52.570432  6526 net.cpp:150] Setting up conv9_2_mbox_loc_perm
I0209 22:43:52.570442  6526 net.cpp:157] Top shape: 40 1 1 16 (640)
I0209 22:43:52.570446  6526 net.cpp:165] Memory required for data: 10108795328
I0209 22:43:52.570449  6526 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_flat
I0209 22:43:52.570456  6526 net.cpp:100] Creating Layer conv9_2_mbox_loc_flat
I0209 22:43:52.570461  6526 net.cpp:434] conv9_2_mbox_loc_flat <- conv9_2_mbox_loc_perm
I0209 22:43:52.570466  6526 net.cpp:408] conv9_2_mbox_loc_flat -> conv9_2_mbox_loc_flat
I0209 22:43:52.570502  6526 net.cpp:150] Setting up conv9_2_mbox_loc_flat
I0209 22:43:52.570510  6526 net.cpp:157] Top shape: 40 16 (640)
I0209 22:43:52.570513  6526 net.cpp:165] Memory required for data: 10108797888
I0209 22:43:52.570518  6526 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf
I0209 22:43:52.570528  6526 net.cpp:100] Creating Layer conv9_2_mbox_conf
I0209 22:43:52.570533  6526 net.cpp:434] conv9_2_mbox_conf <- conv9_2_conv9_2_relu_0_split_1
I0209 22:43:52.570539  6526 net.cpp:408] conv9_2_mbox_conf -> conv9_2_mbox_conf
I0209 22:43:52.573727  6526 net.cpp:150] Setting up conv9_2_mbox_conf
I0209 22:43:52.573743  6526 net.cpp:157] Top shape: 40 88 1 1 (3520)
I0209 22:43:52.573750  6526 net.cpp:165] Memory required for data: 10108811968
I0209 22:43:52.573756  6526 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_perm
I0209 22:43:52.573763  6526 net.cpp:100] Creating Layer conv9_2_mbox_conf_perm
I0209 22:43:52.573767  6526 net.cpp:434] conv9_2_mbox_conf_perm <- conv9_2_mbox_conf
I0209 22:43:52.573774  6526 net.cpp:408] conv9_2_mbox_conf_perm -> conv9_2_mbox_conf_perm
I0209 22:43:52.573933  6526 net.cpp:150] Setting up conv9_2_mbox_conf_perm
I0209 22:43:52.573942  6526 net.cpp:157] Top shape: 40 1 1 88 (3520)
I0209 22:43:52.573946  6526 net.cpp:165] Memory required for data: 10108826048
I0209 22:43:52.573949  6526 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_flat
I0209 22:43:52.573956  6526 net.cpp:100] Creating Layer conv9_2_mbox_conf_flat
I0209 22:43:52.573961  6526 net.cpp:434] conv9_2_mbox_conf_flat <- conv9_2_mbox_conf_perm
I0209 22:43:52.573966  6526 net.cpp:408] conv9_2_mbox_conf_flat -> conv9_2_mbox_conf_flat
I0209 22:43:52.574004  6526 net.cpp:150] Setting up conv9_2_mbox_conf_flat
I0209 22:43:52.574010  6526 net.cpp:157] Top shape: 40 88 (3520)
I0209 22:43:52.574013  6526 net.cpp:165] Memory required for data: 10108840128
I0209 22:43:52.574018  6526 layer_factory.hpp:77] Creating layer conv9_2_mbox_priorbox
I0209 22:43:52.574023  6526 net.cpp:100] Creating Layer conv9_2_mbox_priorbox
I0209 22:43:52.574028  6526 net.cpp:434] conv9_2_mbox_priorbox <- conv9_2_conv9_2_relu_0_split_2
I0209 22:43:52.574033  6526 net.cpp:434] conv9_2_mbox_priorbox <- data_data_0_split_6
I0209 22:43:52.574040  6526 net.cpp:408] conv9_2_mbox_priorbox -> conv9_2_mbox_priorbox
I0209 22:43:52.574079  6526 net.cpp:150] Setting up conv9_2_mbox_priorbox
I0209 22:43:52.574086  6526 net.cpp:157] Top shape: 1 2 16 (32)
I0209 22:43:52.574090  6526 net.cpp:165] Memory required for data: 10108840256
I0209 22:43:52.574093  6526 layer_factory.hpp:77] Creating layer mbox_loc
I0209 22:43:52.574100  6526 net.cpp:100] Creating Layer mbox_loc
I0209 22:43:52.574105  6526 net.cpp:434] mbox_loc <- conv4_3_norm_mbox_loc_flat
I0209 22:43:52.574111  6526 net.cpp:434] mbox_loc <- fc7_mbox_loc_flat
I0209 22:43:52.574116  6526 net.cpp:434] mbox_loc <- conv6_2_mbox_loc_flat
I0209 22:43:52.574121  6526 net.cpp:434] mbox_loc <- conv7_2_mbox_loc_flat
I0209 22:43:52.574126  6526 net.cpp:434] mbox_loc <- conv8_2_mbox_loc_flat
I0209 22:43:52.574131  6526 net.cpp:434] mbox_loc <- conv9_2_mbox_loc_flat
I0209 22:43:52.574152  6526 net.cpp:408] mbox_loc -> mbox_loc
I0209 22:43:52.574193  6526 net.cpp:150] Setting up mbox_loc
I0209 22:43:52.574201  6526 net.cpp:157] Top shape: 40 34928 (1397120)
I0209 22:43:52.574205  6526 net.cpp:165] Memory required for data: 10114428736
I0209 22:43:52.574208  6526 layer_factory.hpp:77] Creating layer mbox_conf
I0209 22:43:52.574215  6526 net.cpp:100] Creating Layer mbox_conf
I0209 22:43:52.574220  6526 net.cpp:434] mbox_conf <- conv4_3_norm_mbox_conf_flat
I0209 22:43:52.574225  6526 net.cpp:434] mbox_conf <- fc7_mbox_conf_flat
I0209 22:43:52.574230  6526 net.cpp:434] mbox_conf <- conv6_2_mbox_conf_flat
I0209 22:43:52.574235  6526 net.cpp:434] mbox_conf <- conv7_2_mbox_conf_flat
I0209 22:43:52.574239  6526 net.cpp:434] mbox_conf <- conv8_2_mbox_conf_flat
I0209 22:43:52.574244  6526 net.cpp:434] mbox_conf <- conv9_2_mbox_conf_flat
I0209 22:43:52.574249  6526 net.cpp:408] mbox_conf -> mbox_conf
I0209 22:43:52.574286  6526 net.cpp:150] Setting up mbox_conf
I0209 22:43:52.574292  6526 net.cpp:157] Top shape: 40 192104 (7684160)
I0209 22:43:52.574296  6526 net.cpp:165] Memory required for data: 10145165376
I0209 22:43:52.574300  6526 layer_factory.hpp:77] Creating layer mbox_priorbox
I0209 22:43:52.574306  6526 net.cpp:100] Creating Layer mbox_priorbox
I0209 22:43:52.574309  6526 net.cpp:434] mbox_priorbox <- conv4_3_norm_mbox_priorbox
I0209 22:43:52.574314  6526 net.cpp:434] mbox_priorbox <- fc7_mbox_priorbox
I0209 22:43:52.574318  6526 net.cpp:434] mbox_priorbox <- conv6_2_mbox_priorbox
I0209 22:43:52.574322  6526 net.cpp:434] mbox_priorbox <- conv7_2_mbox_priorbox
I0209 22:43:52.574326  6526 net.cpp:434] mbox_priorbox <- conv8_2_mbox_priorbox
I0209 22:43:52.574331  6526 net.cpp:434] mbox_priorbox <- conv9_2_mbox_priorbox
I0209 22:43:52.574335  6526 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0209 22:43:52.574379  6526 net.cpp:150] Setting up mbox_priorbox
I0209 22:43:52.574388  6526 net.cpp:157] Top shape: 1 2 34928 (69856)
I0209 22:43:52.574390  6526 net.cpp:165] Memory required for data: 10145444800
I0209 22:43:52.574393  6526 layer_factory.hpp:77] Creating layer mbox_conf_reshape
I0209 22:43:52.574409  6526 net.cpp:100] Creating Layer mbox_conf_reshape
I0209 22:43:52.574412  6526 net.cpp:434] mbox_conf_reshape <- mbox_conf
I0209 22:43:52.574419  6526 net.cpp:408] mbox_conf_reshape -> mbox_conf_reshape
I0209 22:43:52.574463  6526 net.cpp:150] Setting up mbox_conf_reshape
I0209 22:43:52.574470  6526 net.cpp:157] Top shape: 40 8732 22 (7684160)
I0209 22:43:52.574473  6526 net.cpp:165] Memory required for data: 10176181440
I0209 22:43:52.574477  6526 layer_factory.hpp:77] Creating layer mbox_conf_softmax
I0209 22:43:52.574486  6526 net.cpp:100] Creating Layer mbox_conf_softmax
I0209 22:43:52.574491  6526 net.cpp:434] mbox_conf_softmax <- mbox_conf_reshape
I0209 22:43:52.574496  6526 net.cpp:408] mbox_conf_softmax -> mbox_conf_softmax
I0209 22:43:52.574793  6526 net.cpp:150] Setting up mbox_conf_softmax
I0209 22:43:52.574805  6526 net.cpp:157] Top shape: 40 8732 22 (7684160)
I0209 22:43:52.574810  6526 net.cpp:165] Memory required for data: 10206918080
I0209 22:43:52.574813  6526 layer_factory.hpp:77] Creating layer mbox_conf_flatten
I0209 22:43:52.574820  6526 net.cpp:100] Creating Layer mbox_conf_flatten
I0209 22:43:52.574823  6526 net.cpp:434] mbox_conf_flatten <- mbox_conf_softmax
I0209 22:43:52.574829  6526 net.cpp:408] mbox_conf_flatten -> mbox_conf_flatten
I0209 22:43:52.574868  6526 net.cpp:150] Setting up mbox_conf_flatten
I0209 22:43:52.574877  6526 net.cpp:157] Top shape: 40 192104 (7684160)
I0209 22:43:52.574880  6526 net.cpp:165] Memory required for data: 10237654720
I0209 22:43:52.574883  6526 layer_factory.hpp:77] Creating layer detection_out
I0209 22:43:52.574903  6526 net.cpp:100] Creating Layer detection_out
I0209 22:43:52.574908  6526 net.cpp:434] detection_out <- mbox_loc
I0209 22:43:52.574913  6526 net.cpp:434] detection_out <- mbox_conf_flatten
I0209 22:43:52.574918  6526 net.cpp:434] detection_out <- mbox_priorbox
I0209 22:43:52.574934  6526 net.cpp:408] detection_out -> detection_out
I0209 22:43:52.577890  6526 net.cpp:150] Setting up detection_out
I0209 22:43:52.577906  6526 net.cpp:157] Top shape: 1 1 1 7 (7)
I0209 22:43:52.577910  6526 net.cpp:165] Memory required for data: 10237654748
I0209 22:43:52.577914  6526 layer_factory.hpp:77] Creating layer detection_eval
I0209 22:43:52.577922  6526 net.cpp:100] Creating Layer detection_eval
I0209 22:43:52.577927  6526 net.cpp:434] detection_eval <- detection_out
I0209 22:43:52.577932  6526 net.cpp:434] detection_eval <- label
I0209 22:43:52.577939  6526 net.cpp:408] detection_eval -> detection_eval
I0209 22:43:52.579072  6526 net.cpp:150] Setting up detection_eval
I0209 22:43:52.579084  6526 net.cpp:157] Top shape: 1 1 22 5 (110)
I0209 22:43:52.579088  6526 net.cpp:165] Memory required for data: 10237655188
I0209 22:43:52.579092  6526 net.cpp:228] detection_eval does not need backward computation.
I0209 22:43:52.579097  6526 net.cpp:228] detection_out does not need backward computation.
I0209 22:43:52.579102  6526 net.cpp:228] mbox_conf_flatten does not need backward computation.
I0209 22:43:52.579105  6526 net.cpp:228] mbox_conf_softmax does not need backward computation.
I0209 22:43:52.579109  6526 net.cpp:228] mbox_conf_reshape does not need backward computation.
I0209 22:43:52.579113  6526 net.cpp:228] mbox_priorbox does not need backward computation.
I0209 22:43:52.579118  6526 net.cpp:228] mbox_conf does not need backward computation.
I0209 22:43:52.579123  6526 net.cpp:228] mbox_loc does not need backward computation.
I0209 22:43:52.579128  6526 net.cpp:228] conv9_2_mbox_priorbox does not need backward computation.
I0209 22:43:52.579131  6526 net.cpp:228] conv9_2_mbox_conf_flat does not need backward computation.
I0209 22:43:52.579135  6526 net.cpp:228] conv9_2_mbox_conf_perm does not need backward computation.
I0209 22:43:52.579138  6526 net.cpp:228] conv9_2_mbox_conf does not need backward computation.
I0209 22:43:52.579143  6526 net.cpp:228] conv9_2_mbox_loc_flat does not need backward computation.
I0209 22:43:52.579146  6526 net.cpp:228] conv9_2_mbox_loc_perm does not need backward computation.
I0209 22:43:52.579149  6526 net.cpp:228] conv9_2_mbox_loc does not need backward computation.
I0209 22:43:52.579154  6526 net.cpp:228] conv8_2_mbox_priorbox does not need backward computation.
I0209 22:43:52.579157  6526 net.cpp:228] conv8_2_mbox_conf_flat does not need backward computation.
I0209 22:43:52.579161  6526 net.cpp:228] conv8_2_mbox_conf_perm does not need backward computation.
I0209 22:43:52.579165  6526 net.cpp:228] conv8_2_mbox_conf does not need backward computation.
I0209 22:43:52.579169  6526 net.cpp:228] conv8_2_mbox_loc_flat does not need backward computation.
I0209 22:43:52.579172  6526 net.cpp:228] conv8_2_mbox_loc_perm does not need backward computation.
I0209 22:43:52.579175  6526 net.cpp:228] conv8_2_mbox_loc does not need backward computation.
I0209 22:43:52.579180  6526 net.cpp:228] conv7_2_mbox_priorbox does not need backward computation.
I0209 22:43:52.579183  6526 net.cpp:228] conv7_2_mbox_conf_flat does not need backward computation.
I0209 22:43:52.579187  6526 net.cpp:228] conv7_2_mbox_conf_perm does not need backward computation.
I0209 22:43:52.579191  6526 net.cpp:228] conv7_2_mbox_conf does not need backward computation.
I0209 22:43:52.579195  6526 net.cpp:228] conv7_2_mbox_loc_flat does not need backward computation.
I0209 22:43:52.579198  6526 net.cpp:228] conv7_2_mbox_loc_perm does not need backward computation.
I0209 22:43:52.579202  6526 net.cpp:228] conv7_2_mbox_loc does not need backward computation.
I0209 22:43:52.579205  6526 net.cpp:228] conv6_2_mbox_priorbox does not need backward computation.
I0209 22:43:52.579210  6526 net.cpp:228] conv6_2_mbox_conf_flat does not need backward computation.
I0209 22:43:52.579213  6526 net.cpp:228] conv6_2_mbox_conf_perm does not need backward computation.
I0209 22:43:52.579216  6526 net.cpp:228] conv6_2_mbox_conf does not need backward computation.
I0209 22:43:52.579221  6526 net.cpp:228] conv6_2_mbox_loc_flat does not need backward computation.
I0209 22:43:52.579234  6526 net.cpp:228] conv6_2_mbox_loc_perm does not need backward computation.
I0209 22:43:52.579238  6526 net.cpp:228] conv6_2_mbox_loc does not need backward computation.
I0209 22:43:52.579242  6526 net.cpp:228] fc7_mbox_priorbox does not need backward computation.
I0209 22:43:52.579247  6526 net.cpp:228] fc7_mbox_conf_flat does not need backward computation.
I0209 22:43:52.579252  6526 net.cpp:228] fc7_mbox_conf_perm does not need backward computation.
I0209 22:43:52.579255  6526 net.cpp:228] fc7_mbox_conf does not need backward computation.
I0209 22:43:52.579259  6526 net.cpp:228] fc7_mbox_loc_flat does not need backward computation.
I0209 22:43:52.579263  6526 net.cpp:228] fc7_mbox_loc_perm does not need backward computation.
I0209 22:43:52.579267  6526 net.cpp:228] fc7_mbox_loc does not need backward computation.
I0209 22:43:52.579272  6526 net.cpp:228] conv4_3_norm_mbox_priorbox does not need backward computation.
I0209 22:43:52.579277  6526 net.cpp:228] conv4_3_norm_mbox_conf_flat does not need backward computation.
I0209 22:43:52.579280  6526 net.cpp:228] conv4_3_norm_mbox_conf_perm does not need backward computation.
I0209 22:43:52.579284  6526 net.cpp:228] conv4_3_norm_mbox_conf does not need backward computation.
I0209 22:43:52.579288  6526 net.cpp:228] conv4_3_norm_mbox_loc_flat does not need backward computation.
I0209 22:43:52.579293  6526 net.cpp:228] conv4_3_norm_mbox_loc_perm does not need backward computation.
I0209 22:43:52.579295  6526 net.cpp:228] conv4_3_norm_mbox_loc does not need backward computation.
I0209 22:43:52.579300  6526 net.cpp:228] conv4_3_norm_conv4_3_norm_0_split does not need backward computation.
I0209 22:43:52.579304  6526 net.cpp:228] conv4_3_norm does not need backward computation.
I0209 22:43:52.579308  6526 net.cpp:228] conv9_2_conv9_2_relu_0_split does not need backward computation.
I0209 22:43:52.579313  6526 net.cpp:228] conv9_2_relu does not need backward computation.
I0209 22:43:52.579316  6526 net.cpp:228] conv9_2 does not need backward computation.
I0209 22:43:52.579320  6526 net.cpp:228] conv9_1_relu does not need backward computation.
I0209 22:43:52.579324  6526 net.cpp:228] conv9_1 does not need backward computation.
I0209 22:43:52.579329  6526 net.cpp:228] conv8_2_conv8_2_relu_0_split does not need backward computation.
I0209 22:43:52.579331  6526 net.cpp:228] conv8_2_relu does not need backward computation.
I0209 22:43:52.579335  6526 net.cpp:228] conv8_2 does not need backward computation.
I0209 22:43:52.579339  6526 net.cpp:228] conv8_1_relu does not need backward computation.
I0209 22:43:52.579344  6526 net.cpp:228] conv8_1 does not need backward computation.
I0209 22:43:52.579347  6526 net.cpp:228] conv7_2_conv7_2_relu_0_split does not need backward computation.
I0209 22:43:52.579351  6526 net.cpp:228] conv7_2_relu does not need backward computation.
I0209 22:43:52.579355  6526 net.cpp:228] conv7_2 does not need backward computation.
I0209 22:43:52.579358  6526 net.cpp:228] conv7_1_relu does not need backward computation.
I0209 22:43:52.579362  6526 net.cpp:228] conv7_1 does not need backward computation.
I0209 22:43:52.579366  6526 net.cpp:228] conv6_2_conv6_2_relu_0_split does not need backward computation.
I0209 22:43:52.579370  6526 net.cpp:228] conv6_2_relu does not need backward computation.
I0209 22:43:52.579375  6526 net.cpp:228] conv6_2 does not need backward computation.
I0209 22:43:52.579378  6526 net.cpp:228] conv6_1_relu does not need backward computation.
I0209 22:43:52.579382  6526 net.cpp:228] conv6_1 does not need backward computation.
I0209 22:43:52.579386  6526 net.cpp:228] fc7_relu7_0_split does not need backward computation.
I0209 22:43:52.579391  6526 net.cpp:228] relu7 does not need backward computation.
I0209 22:43:52.579394  6526 net.cpp:228] fc7 does not need backward computation.
I0209 22:43:52.579398  6526 net.cpp:228] relu6 does not need backward computation.
I0209 22:43:52.579401  6526 net.cpp:228] fc6 does not need backward computation.
I0209 22:43:52.579406  6526 net.cpp:228] pool5 does not need backward computation.
I0209 22:43:52.579414  6526 net.cpp:228] relu5_3 does not need backward computation.
I0209 22:43:52.579418  6526 net.cpp:228] conv5_3 does not need backward computation.
I0209 22:43:52.579422  6526 net.cpp:228] relu5_2 does not need backward computation.
I0209 22:43:52.579426  6526 net.cpp:228] conv5_2 does not need backward computation.
I0209 22:43:52.579429  6526 net.cpp:228] relu5_1 does not need backward computation.
I0209 22:43:52.579432  6526 net.cpp:228] conv5_1 does not need backward computation.
I0209 22:43:52.579437  6526 net.cpp:228] pool4 does not need backward computation.
I0209 22:43:52.579442  6526 net.cpp:228] conv4_3_relu4_3_0_split does not need backward computation.
I0209 22:43:52.579445  6526 net.cpp:228] relu4_3 does not need backward computation.
I0209 22:43:52.579449  6526 net.cpp:228] conv4_3 does not need backward computation.
I0209 22:43:52.579453  6526 net.cpp:228] relu4_2 does not need backward computation.
I0209 22:43:52.579457  6526 net.cpp:228] conv4_2 does not need backward computation.
I0209 22:43:52.579460  6526 net.cpp:228] relu4_1 does not need backward computation.
I0209 22:43:52.579464  6526 net.cpp:228] conv4_1 does not need backward computation.
I0209 22:43:52.579468  6526 net.cpp:228] pool3 does not need backward computation.
I0209 22:43:52.579471  6526 net.cpp:228] relu3_3 does not need backward computation.
I0209 22:43:52.579475  6526 net.cpp:228] conv3_3 does not need backward computation.
I0209 22:43:52.579479  6526 net.cpp:228] relu3_2 does not need backward computation.
I0209 22:43:52.579483  6526 net.cpp:228] conv3_2 does not need backward computation.
I0209 22:43:52.579488  6526 net.cpp:228] relu3_1 does not need backward computation.
I0209 22:43:52.579490  6526 net.cpp:228] conv3_1 does not need backward computation.
I0209 22:43:52.579494  6526 net.cpp:228] pool2 does not need backward computation.
I0209 22:43:52.579499  6526 net.cpp:228] relu2_2 does not need backward computation.
I0209 22:43:52.579501  6526 net.cpp:228] conv2_2 does not need backward computation.
I0209 22:43:52.579505  6526 net.cpp:228] relu2_1 does not need backward computation.
I0209 22:43:52.579509  6526 net.cpp:228] conv2_1 does not need backward computation.
I0209 22:43:52.579512  6526 net.cpp:228] pool1 does not need backward computation.
I0209 22:43:52.579516  6526 net.cpp:228] relu1_2 does not need backward computation.
I0209 22:43:52.579520  6526 net.cpp:228] conv1_2 does not need backward computation.
I0209 22:43:52.579524  6526 net.cpp:228] relu1_1 does not need backward computation.
I0209 22:43:52.579529  6526 net.cpp:228] conv1_1_rgbd does not need backward computation.
I0209 22:43:52.579532  6526 net.cpp:228] data_data_0_split does not need backward computation.
I0209 22:43:52.579537  6526 net.cpp:228] data does not need backward computation.
I0209 22:43:52.579540  6526 net.cpp:270] This network produces output detection_eval
I0209 22:43:52.579613  6526 net.cpp:283] Network initialization done.
I0209 22:43:52.579970  6526 solver.cpp:75] Solver scaffolding done.
I0209 22:43:52.583770  6526 caffe.cpp:241] Resuming from models/VGGNet/VOC0712/SSD_RGBD_test_300x300/VGG_VOC0712_SSD_RGBD_test_300x300_iter_4383.solverstate
I0209 22:43:52.911563  6526 sgd_solver.cpp:356] SGDSolver: restoring history
I0209 22:43:52.985260  6526 parallel.cpp:392] GPUs pairs 1:2, 1:0
I0209 22:43:53.224622  6526 annotated_data_layer.cpp:62] output data size: 40,4,300,300
I0209 22:43:54.246208  6526 annotated_data_layer.cpp:62] output data size: 40,4,300,300
I0209 22:43:55.097769  6526 parallel.cpp:425] Starting Optimization
I0209 22:43:55.098706  6526 solver.cpp:294] Solving VGG_VOC0712_SSD_RGBD_test_300x300_train
I0209 22:43:55.098724  6526 solver.cpp:295] Learning Rate Policy: multistep
I0209 22:43:55.118180  6526 blocking_queue.cpp:50] Data layer prefetch queue empty
I0209 22:44:55.778070  6526 solver.cpp:243] Iteration 4390, loss = 6.4111
I0209 22:44:55.789012  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.00132 (* 1 = 6.00132 loss)
I0209 22:44:55.789085  6526 sgd_solver.cpp:138] Iteration 4390, lr = 2.5e-05
I0209 22:46:04.677410  6526 solver.cpp:243] Iteration 4400, loss = 6.48295
I0209 22:46:04.677552  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.64167 (* 1 = 6.64167 loss)
I0209 22:46:04.677603  6526 sgd_solver.cpp:138] Iteration 4400, lr = 2.5e-05
I0209 22:47:13.447922  6526 solver.cpp:243] Iteration 4410, loss = 6.38673
I0209 22:47:13.448094  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.43937 (* 1 = 6.43937 loss)
I0209 22:47:13.448184  6526 sgd_solver.cpp:138] Iteration 4410, lr = 2.5e-05
I0209 22:48:22.367789  6526 solver.cpp:243] Iteration 4420, loss = 6.2938
I0209 22:48:22.367909  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.03916 (* 1 = 6.03916 loss)
I0209 22:48:22.367976  6526 sgd_solver.cpp:138] Iteration 4420, lr = 2.5e-05
I0209 22:49:27.785540  6526 solver.cpp:243] Iteration 4430, loss = 6.27255
I0209 22:49:27.788956  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.6629 (* 1 = 6.6629 loss)
I0209 22:49:32.175667  6526 sgd_solver.cpp:138] Iteration 4430, lr = 2.5e-05
I0209 22:50:35.674108  6526 solver.cpp:243] Iteration 4440, loss = 6.57518
I0209 22:50:35.674238  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.35622 (* 1 = 6.35622 loss)
I0209 22:50:42.662906  6526 sgd_solver.cpp:138] Iteration 4440, lr = 2.5e-05
I0209 22:51:45.628911  6526 solver.cpp:243] Iteration 4450, loss = 6.34747
I0209 22:51:45.629022  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.58795 (* 1 = 6.58795 loss)
I0209 22:51:52.415801  6526 sgd_solver.cpp:138] Iteration 4450, lr = 2.5e-05
I0209 22:52:56.514430  6526 solver.cpp:243] Iteration 4460, loss = 6.19245
I0209 22:52:56.514583  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.15461 (* 1 = 6.15461 loss)
I0209 22:53:02.614078  6526 sgd_solver.cpp:138] Iteration 4460, lr = 2.5e-05
I0209 22:54:03.588008  6526 solver.cpp:243] Iteration 4470, loss = 6.34071
I0209 22:54:03.602422  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.55186 (* 1 = 6.55186 loss)
I0209 22:54:09.455432  6526 sgd_solver.cpp:138] Iteration 4470, lr = 2.5e-05
I0209 22:55:18.073058  6526 solver.cpp:243] Iteration 4480, loss = 6.35577
I0209 22:55:18.073232  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.39732 (* 1 = 6.39732 loss)
I0209 22:55:18.073299  6526 sgd_solver.cpp:138] Iteration 4480, lr = 2.5e-05
I0209 22:56:29.403591  6526 solver.cpp:243] Iteration 4490, loss = 6.31074
I0209 22:56:29.403724  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.04583 (* 1 = 6.04583 loss)
I0209 22:56:29.403772  6526 sgd_solver.cpp:138] Iteration 4490, lr = 2.5e-05
I0209 22:57:42.030114  6526 solver.cpp:243] Iteration 4500, loss = 6.42456
I0209 22:57:42.030283  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.56718 (* 1 = 6.56718 loss)
I0209 22:57:42.030365  6526 sgd_solver.cpp:138] Iteration 4500, lr = 2.5e-05
I0209 22:58:50.782320  6526 solver.cpp:243] Iteration 4510, loss = 6.30045
I0209 22:58:50.782812  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.72615 (* 1 = 5.72615 loss)
I0209 22:58:50.782878  6526 sgd_solver.cpp:138] Iteration 4510, lr = 2.5e-05
I0209 23:00:00.683231  6526 solver.cpp:243] Iteration 4520, loss = 6.67039
I0209 23:00:00.683356  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.63805 (* 1 = 6.63805 loss)
I0209 23:00:00.683421  6526 sgd_solver.cpp:138] Iteration 4520, lr = 2.5e-05
I0209 23:01:11.198321  6526 solver.cpp:243] Iteration 4530, loss = 6.22883
I0209 23:01:11.199129  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.76701 (* 1 = 5.76701 loss)
I0209 23:01:11.199223  6526 sgd_solver.cpp:138] Iteration 4530, lr = 2.5e-05
I0209 23:02:19.308789  6526 solver.cpp:243] Iteration 4540, loss = 6.36276
I0209 23:02:19.309311  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.42287 (* 1 = 6.42287 loss)
I0209 23:02:20.749228  6526 sgd_solver.cpp:138] Iteration 4540, lr = 2.5e-05
I0209 23:03:32.976590  6526 solver.cpp:243] Iteration 4550, loss = 6.25004
I0209 23:03:32.976760  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.90217 (* 1 = 5.90217 loss)
I0209 23:03:32.976811  6526 sgd_solver.cpp:138] Iteration 4550, lr = 2.5e-05
I0209 23:04:43.857357  6526 solver.cpp:243] Iteration 4560, loss = 6.46556
I0209 23:04:43.874405  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.02179 (* 1 = 6.02179 loss)
I0209 23:04:43.874498  6526 sgd_solver.cpp:138] Iteration 4560, lr = 2.5e-05
I0209 23:05:55.803015  6526 solver.cpp:243] Iteration 4570, loss = 6.52516
I0209 23:05:55.803186  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.05266 (* 1 = 6.05266 loss)
I0209 23:05:55.803273  6526 sgd_solver.cpp:138] Iteration 4570, lr = 2.5e-05
I0209 23:07:06.074357  6526 solver.cpp:243] Iteration 4580, loss = 6.40007
I0209 23:07:06.074525  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.78815 (* 1 = 6.78815 loss)
I0209 23:07:06.074594  6526 sgd_solver.cpp:138] Iteration 4580, lr = 2.5e-05
I0209 23:08:12.902130  6526 solver.cpp:243] Iteration 4590, loss = 6.35245
I0209 23:08:12.902251  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.80926 (* 1 = 5.80926 loss)
I0209 23:08:12.902318  6526 sgd_solver.cpp:138] Iteration 4590, lr = 2.5e-05
I0209 23:09:24.800592  6526 solver.cpp:243] Iteration 4600, loss = 6.14739
I0209 23:09:24.800719  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.61829 (* 1 = 5.61829 loss)
I0209 23:09:24.800788  6526 sgd_solver.cpp:138] Iteration 4600, lr = 2.5e-05
I0209 23:10:32.300452  6526 solver.cpp:243] Iteration 4610, loss = 6.45872
I0209 23:10:32.300580  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.61979 (* 1 = 6.61979 loss)
I0209 23:10:32.300629  6526 sgd_solver.cpp:138] Iteration 4610, lr = 2.5e-05
I0209 23:11:42.495375  6526 solver.cpp:243] Iteration 4620, loss = 6.18637
I0209 23:11:42.495507  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.67502 (* 1 = 6.67502 loss)
I0209 23:11:42.495571  6526 sgd_solver.cpp:138] Iteration 4620, lr = 2.5e-05
I0209 23:12:52.654536  6526 solver.cpp:243] Iteration 4630, loss = 6.14595
I0209 23:12:52.654671  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.73012 (* 1 = 5.73012 loss)
I0209 23:12:52.654747  6526 sgd_solver.cpp:138] Iteration 4630, lr = 2.5e-05
I0209 23:14:01.058099  6526 solver.cpp:243] Iteration 4640, loss = 6.2113
I0209 23:14:01.058220  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.82624 (* 1 = 5.82624 loss)
I0209 23:14:01.058269  6526 sgd_solver.cpp:138] Iteration 4640, lr = 2.5e-05
I0209 23:15:12.574527  6526 solver.cpp:243] Iteration 4650, loss = 6.1784
I0209 23:15:12.574645  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.44941 (* 1 = 6.44941 loss)
I0209 23:15:12.574693  6526 sgd_solver.cpp:138] Iteration 4650, lr = 2.5e-05
I0209 23:16:21.390843  6526 solver.cpp:243] Iteration 4660, loss = 6.34504
I0209 23:16:21.391142  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.95854 (* 1 = 5.95854 loss)
I0209 23:16:21.391283  6526 sgd_solver.cpp:138] Iteration 4660, lr = 2.5e-05
I0209 23:17:31.781502  6526 solver.cpp:243] Iteration 4670, loss = 6.32008
I0209 23:17:31.781668  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.68024 (* 1 = 6.68024 loss)
I0209 23:17:31.781755  6526 sgd_solver.cpp:138] Iteration 4670, lr = 2.5e-05
I0209 23:18:40.939163  6526 solver.cpp:243] Iteration 4680, loss = 6.43787
I0209 23:18:40.939292  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.55485 (* 1 = 6.55485 loss)
I0209 23:18:40.939342  6526 sgd_solver.cpp:138] Iteration 4680, lr = 2.5e-05
I0209 23:19:49.613682  6526 solver.cpp:243] Iteration 4690, loss = 6.41945
I0209 23:19:49.614068  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.55448 (* 1 = 6.55448 loss)
I0209 23:19:51.192119  6526 sgd_solver.cpp:138] Iteration 4690, lr = 2.5e-05
I0209 23:21:03.175833  6526 solver.cpp:243] Iteration 4700, loss = 6.40087
I0209 23:21:03.175950  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.35202 (* 1 = 6.35202 loss)
I0209 23:21:03.175997  6526 sgd_solver.cpp:138] Iteration 4700, lr = 2.5e-05
I0209 23:22:13.339305  6526 solver.cpp:243] Iteration 4710, loss = 6.34936
I0209 23:22:13.339468  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.8766 (* 1 = 6.8766 loss)
I0209 23:22:13.339517  6526 sgd_solver.cpp:138] Iteration 4710, lr = 2.5e-05
I0209 23:23:22.694833  6526 solver.cpp:243] Iteration 4720, loss = 6.38662
I0209 23:23:22.695004  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.01007 (* 1 = 6.01007 loss)
I0209 23:23:25.772294  6526 sgd_solver.cpp:138] Iteration 4720, lr = 2.5e-05
I0209 23:24:33.992714  6526 solver.cpp:243] Iteration 4730, loss = 6.44328
I0209 23:24:33.992836  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.34399 (* 1 = 6.34399 loss)
I0209 23:24:33.992883  6526 sgd_solver.cpp:138] Iteration 4730, lr = 2.5e-05
I0209 23:25:42.669234  6526 solver.cpp:243] Iteration 4740, loss = 6.34542
I0209 23:25:42.669412  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.40712 (* 1 = 6.40712 loss)
I0209 23:25:42.669577  6526 sgd_solver.cpp:138] Iteration 4740, lr = 2.5e-05
I0209 23:26:52.796730  6526 solver.cpp:243] Iteration 4750, loss = 6.24506
I0209 23:26:52.796895  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.67049 (* 1 = 5.67049 loss)
I0209 23:26:52.796980  6526 sgd_solver.cpp:138] Iteration 4750, lr = 2.5e-05
I0209 23:28:03.288933  6526 solver.cpp:243] Iteration 4760, loss = 6.27759
I0209 23:28:03.289594  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.24215 (* 1 = 6.24215 loss)
I0209 23:28:03.289667  6526 sgd_solver.cpp:138] Iteration 4760, lr = 2.5e-05
I0209 23:29:19.213724  6526 solver.cpp:243] Iteration 4770, loss = 6.59556
I0209 23:29:19.213855  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.44306 (* 1 = 6.44306 loss)
I0209 23:29:19.213922  6526 sgd_solver.cpp:138] Iteration 4770, lr = 2.5e-05
I0209 23:30:27.344018  6526 solver.cpp:243] Iteration 4780, loss = 6.52888
I0209 23:30:27.344146  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.74897 (* 1 = 6.74897 loss)
I0209 23:30:27.344210  6526 sgd_solver.cpp:138] Iteration 4780, lr = 2.5e-05
I0209 23:31:39.878409  6526 solver.cpp:243] Iteration 4790, loss = 6.19204
I0209 23:31:39.878589  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.96187 (* 1 = 5.96187 loss)
I0209 23:31:39.878657  6526 sgd_solver.cpp:138] Iteration 4790, lr = 2.5e-05
I0209 23:32:46.489476  6526 solver.cpp:243] Iteration 4800, loss = 6.48506
I0209 23:32:46.499385  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.2246 (* 1 = 6.2246 loss)
I0209 23:32:46.499552  6526 sgd_solver.cpp:138] Iteration 4800, lr = 2.5e-05
I0209 23:33:58.676970  6526 solver.cpp:243] Iteration 4810, loss = 6.23723
I0209 23:33:58.677098  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.77608 (* 1 = 6.77608 loss)
I0209 23:33:58.677165  6526 sgd_solver.cpp:138] Iteration 4810, lr = 2.5e-05
I0209 23:35:07.496316  6526 solver.cpp:243] Iteration 4820, loss = 6.31562
I0209 23:35:07.496433  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.64829 (* 1 = 6.64829 loss)
I0209 23:35:07.496500  6526 sgd_solver.cpp:138] Iteration 4820, lr = 2.5e-05
I0209 23:36:16.067683  6526 solver.cpp:243] Iteration 4830, loss = 6.31262
I0209 23:36:16.067862  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.36084 (* 1 = 6.36084 loss)
I0209 23:36:16.068020  6526 sgd_solver.cpp:138] Iteration 4830, lr = 2.5e-05
I0209 23:37:24.474678  6526 solver.cpp:243] Iteration 4840, loss = 6.2792
I0209 23:37:24.474809  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.37725 (* 1 = 6.37725 loss)
I0209 23:37:24.474856  6526 sgd_solver.cpp:138] Iteration 4840, lr = 2.5e-05
I0209 23:38:35.617990  6526 solver.cpp:243] Iteration 4850, loss = 6.31492
I0209 23:38:35.618165  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.50936 (* 1 = 6.50936 loss)
I0209 23:38:35.618233  6526 sgd_solver.cpp:138] Iteration 4850, lr = 2.5e-05
I0209 23:39:42.763386  6526 solver.cpp:243] Iteration 4860, loss = 6.22346
I0209 23:39:42.763593  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.91475 (* 1 = 5.91475 loss)
I0209 23:39:42.763686  6526 sgd_solver.cpp:138] Iteration 4860, lr = 2.5e-05
I0209 23:40:52.052620  6526 solver.cpp:243] Iteration 4870, loss = 6.39845
I0209 23:40:52.052757  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.49903 (* 1 = 6.49903 loss)
I0209 23:40:52.052809  6526 sgd_solver.cpp:138] Iteration 4870, lr = 2.5e-05
I0209 23:42:01.705474  6526 solver.cpp:243] Iteration 4880, loss = 6.23931
I0209 23:42:01.705600  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.1755 (* 1 = 6.1755 loss)
I0209 23:42:01.705648  6526 sgd_solver.cpp:138] Iteration 4880, lr = 2.5e-05
I0209 23:43:12.169458  6526 solver.cpp:243] Iteration 4890, loss = 6.31829
I0209 23:43:12.180301  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.38644 (* 1 = 6.38644 loss)
I0209 23:43:12.180451  6526 sgd_solver.cpp:138] Iteration 4890, lr = 2.5e-05
I0209 23:44:20.248404  6526 solver.cpp:243] Iteration 4900, loss = 6.35514
I0209 23:44:20.258271  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.18807 (* 1 = 6.18807 loss)
I0209 23:44:20.258512  6526 sgd_solver.cpp:138] Iteration 4900, lr = 2.5e-05
I0209 23:45:31.580659  6526 solver.cpp:243] Iteration 4910, loss = 6.21522
I0209 23:45:31.580791  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.53382 (* 1 = 6.53382 loss)
I0209 23:45:31.580839  6526 sgd_solver.cpp:138] Iteration 4910, lr = 2.5e-05
I0209 23:46:38.686813  6526 solver.cpp:243] Iteration 4920, loss = 6.29414
I0209 23:46:38.689684  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.72088 (* 1 = 5.72088 loss)
I0209 23:46:40.011482  6526 sgd_solver.cpp:138] Iteration 4920, lr = 2.5e-05
I0209 23:47:09.593565  6526 blocking_queue.cpp:50] Data layer prefetch queue empty
I0209 23:47:49.937532  6526 solver.cpp:243] Iteration 4930, loss = 6.42936
I0209 23:47:49.937662  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.58004 (* 1 = 6.58004 loss)
I0209 23:47:52.695612  6526 sgd_solver.cpp:138] Iteration 4930, lr = 2.5e-05
I0209 23:49:02.333330  6526 solver.cpp:243] Iteration 4940, loss = 6.18093
I0209 23:49:02.333444  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.22394 (* 1 = 6.22394 loss)
I0209 23:49:02.333511  6526 sgd_solver.cpp:138] Iteration 4940, lr = 2.5e-05
I0209 23:50:12.781936  6526 solver.cpp:243] Iteration 4950, loss = 6.32976
I0209 23:50:12.782065  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.61445 (* 1 = 6.61445 loss)
I0209 23:50:12.782230  6526 sgd_solver.cpp:138] Iteration 4950, lr = 2.5e-05
I0209 23:51:19.057142  6526 solver.cpp:243] Iteration 4960, loss = 6.31721
I0209 23:51:19.067803  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.43632 (* 1 = 6.43632 loss)
I0209 23:51:23.387790  6526 sgd_solver.cpp:138] Iteration 4960, lr = 2.5e-05
I0209 23:52:28.900682  6526 solver.cpp:243] Iteration 4970, loss = 6.40927
I0209 23:52:28.900905  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.81059 (* 1 = 6.81059 loss)
I0209 23:52:35.170859  6526 sgd_solver.cpp:138] Iteration 4970, lr = 2.5e-05
I0209 23:53:40.684676  6526 solver.cpp:243] Iteration 4980, loss = 6.4679
I0209 23:53:40.684806  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.46731 (* 1 = 6.46731 loss)
I0209 23:53:46.273392  6526 sgd_solver.cpp:138] Iteration 4980, lr = 2.5e-05
I0209 23:54:50.485443  6526 solver.cpp:243] Iteration 4990, loss = 6.3293
I0209 23:54:50.485569  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.14194 (* 1 = 6.14194 loss)
I0209 23:54:56.352573  6526 sgd_solver.cpp:138] Iteration 4990, lr = 2.5e-05
I0209 23:56:00.702782  6526 solver.cpp:243] Iteration 5000, loss = 6.14975
I0209 23:56:00.702955  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.49782 (* 1 = 6.49782 loss)
I0209 23:56:04.058337  6526 sgd_solver.cpp:138] Iteration 5000, lr = 2.5e-05
I0209 23:57:11.008613  6526 solver.cpp:243] Iteration 5010, loss = 6.20707
I0209 23:57:11.008759  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.57371 (* 1 = 6.57371 loss)
I0209 23:57:13.954638  6526 sgd_solver.cpp:138] Iteration 5010, lr = 2.5e-05
I0209 23:58:21.889032  6526 solver.cpp:243] Iteration 5020, loss = 6.34487
I0209 23:58:21.889230  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.99029 (* 1 = 6.99029 loss)
I0209 23:58:26.782338  6526 sgd_solver.cpp:138] Iteration 5020, lr = 2.5e-05
I0209 23:59:34.776916  6526 solver.cpp:243] Iteration 5030, loss = 6.37229
I0209 23:59:34.778585  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.20878 (* 1 = 6.20878 loss)
I0209 23:59:39.506525  6526 sgd_solver.cpp:138] Iteration 5030, lr = 2.5e-05
I0210 00:00:43.717895  6526 solver.cpp:243] Iteration 5040, loss = 6.37068
I0210 00:00:43.718036  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.49166 (* 1 = 6.49166 loss)
I0210 00:00:47.394441  6526 sgd_solver.cpp:138] Iteration 5040, lr = 2.5e-05
I0210 00:01:55.700006  6526 solver.cpp:243] Iteration 5050, loss = 6.28634
I0210 00:01:55.700179  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.28889 (* 1 = 6.28889 loss)
I0210 00:02:00.076894  6526 sgd_solver.cpp:138] Iteration 5050, lr = 2.5e-05
I0210 00:03:05.599017  6526 solver.cpp:243] Iteration 5060, loss = 6.14683
I0210 00:03:05.599189  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.35592 (* 1 = 6.35592 loss)
I0210 00:03:11.500313  6526 sgd_solver.cpp:138] Iteration 5060, lr = 2.5e-05
I0210 00:04:14.200460  6526 solver.cpp:243] Iteration 5070, loss = 6.29002
I0210 00:04:14.200631  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.78169 (* 1 = 6.78169 loss)
I0210 00:04:20.760378  6526 sgd_solver.cpp:138] Iteration 5070, lr = 2.5e-05
I0210 00:05:24.512795  6526 solver.cpp:243] Iteration 5080, loss = 6.33922
I0210 00:05:24.513989  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.83815 (* 1 = 5.83815 loss)
I0210 00:05:27.427600  6526 sgd_solver.cpp:138] Iteration 5080, lr = 2.5e-05
I0210 00:06:33.635713  6526 solver.cpp:243] Iteration 5090, loss = 6.28945
I0210 00:06:33.635877  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.01188 (* 1 = 6.01188 loss)
I0210 00:06:39.558957  6526 sgd_solver.cpp:138] Iteration 5090, lr = 2.5e-05
I0210 00:07:47.199664  6526 solver.cpp:243] Iteration 5100, loss = 6.15546
I0210 00:07:47.199787  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.15391 (* 1 = 6.15391 loss)
I0210 00:07:52.816066  6526 sgd_solver.cpp:138] Iteration 5100, lr = 2.5e-05
I0210 00:08:58.470696  6526 solver.cpp:243] Iteration 5110, loss = 6.20419
I0210 00:08:58.470808  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.05063 (* 1 = 6.05063 loss)
I0210 00:09:02.775105  6526 sgd_solver.cpp:138] Iteration 5110, lr = 2.5e-05
I0210 00:10:08.278424  6526 solver.cpp:243] Iteration 5120, loss = 6.28812
I0210 00:10:08.278553  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.42436 (* 1 = 6.42436 loss)
I0210 00:10:13.285220  6526 sgd_solver.cpp:138] Iteration 5120, lr = 2.5e-05
I0210 00:11:18.746484  6526 solver.cpp:243] Iteration 5130, loss = 6.23144
I0210 00:11:18.746635  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.48239 (* 1 = 6.48239 loss)
I0210 00:11:24.427294  6526 sgd_solver.cpp:138] Iteration 5130, lr = 2.5e-05
I0210 00:12:27.527307  6526 solver.cpp:243] Iteration 5140, loss = 6.20429
I0210 00:12:27.536459  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.43961 (* 1 = 6.43961 loss)
I0210 00:12:33.590345  6526 sgd_solver.cpp:138] Iteration 5140, lr = 2.5e-05
I0210 00:13:41.473961  6526 solver.cpp:243] Iteration 5150, loss = 6.46044
I0210 00:13:41.474086  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.25552 (* 1 = 6.25552 loss)
I0210 00:13:46.820513  6526 sgd_solver.cpp:138] Iteration 5150, lr = 2.5e-05
I0210 00:14:51.151965  6526 solver.cpp:243] Iteration 5160, loss = 6.3492
I0210 00:14:51.152137  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.98612 (* 1 = 5.98612 loss)
I0210 00:14:56.126729  6526 sgd_solver.cpp:138] Iteration 5160, lr = 2.5e-05
I0210 00:15:58.287963  6526 solver.cpp:243] Iteration 5170, loss = 6.25159
I0210 00:15:58.291488  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.34939 (* 1 = 6.34939 loss)
I0210 00:16:03.622169  6526 sgd_solver.cpp:138] Iteration 5170, lr = 2.5e-05
I0210 00:17:09.454192  6526 solver.cpp:243] Iteration 5180, loss = 6.32853
I0210 00:17:09.454373  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.90428 (* 1 = 5.90428 loss)
I0210 00:17:13.725739  6526 sgd_solver.cpp:138] Iteration 5180, lr = 2.5e-05
I0210 00:18:16.932070  6526 solver.cpp:243] Iteration 5190, loss = 6.34241
I0210 00:18:16.934011  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.33837 (* 1 = 6.33837 loss)
I0210 00:18:21.994758  6526 sgd_solver.cpp:138] Iteration 5190, lr = 2.5e-05
I0210 00:19:24.876749  6526 solver.cpp:243] Iteration 5200, loss = 6.31096
I0210 00:19:24.878149  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.41918 (* 1 = 6.41918 loss)
I0210 00:19:27.829052  6526 sgd_solver.cpp:138] Iteration 5200, lr = 2.5e-05
I0210 00:20:33.090783  6526 solver.cpp:243] Iteration 5210, loss = 6.23246
I0210 00:20:33.095000  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.1015 (* 1 = 6.1015 loss)
I0210 00:20:36.645246  6526 sgd_solver.cpp:138] Iteration 5210, lr = 2.5e-05
I0210 00:21:43.251974  6526 solver.cpp:243] Iteration 5220, loss = 6.33833
I0210 00:21:43.252152  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.34066 (* 1 = 6.34066 loss)
I0210 00:21:46.852294  6526 sgd_solver.cpp:138] Iteration 5220, lr = 2.5e-05
I0210 00:22:54.413609  6526 solver.cpp:243] Iteration 5230, loss = 6.475
I0210 00:22:54.413769  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.78723 (* 1 = 6.78723 loss)
I0210 00:22:57.263061  6526 sgd_solver.cpp:138] Iteration 5230, lr = 2.5e-05
I0210 00:24:03.267132  6526 solver.cpp:243] Iteration 5240, loss = 6.42178
I0210 00:24:03.267910  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.48987 (* 1 = 6.48987 loss)
I0210 00:24:07.893720  6526 sgd_solver.cpp:138] Iteration 5240, lr = 2.5e-05
I0210 00:25:15.858309  6526 solver.cpp:243] Iteration 5250, loss = 6.38665
I0210 00:25:15.869040  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.16674 (* 1 = 6.16674 loss)
I0210 00:25:15.869112  6526 sgd_solver.cpp:138] Iteration 5250, lr = 2.5e-05
I0210 00:26:24.215662  6526 solver.cpp:243] Iteration 5260, loss = 6.33249
I0210 00:26:24.215827  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.24872 (* 1 = 6.24872 loss)
I0210 00:26:24.215894  6526 sgd_solver.cpp:138] Iteration 5260, lr = 2.5e-05
I0210 00:27:33.922474  6526 solver.cpp:243] Iteration 5270, loss = 6.20899
I0210 00:27:33.922629  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.1299 (* 1 = 6.1299 loss)
I0210 00:27:33.922714  6526 sgd_solver.cpp:138] Iteration 5270, lr = 2.5e-05
I0210 00:28:43.359988  6526 solver.cpp:243] Iteration 5280, loss = 6.27765
I0210 00:28:43.361007  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.06876 (* 1 = 6.06876 loss)
I0210 00:28:43.361208  6526 sgd_solver.cpp:138] Iteration 5280, lr = 2.5e-05
I0210 00:29:53.441742  6526 solver.cpp:243] Iteration 5290, loss = 6.28951
I0210 00:29:53.441922  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.38414 (* 1 = 6.38414 loss)
I0210 00:29:53.441994  6526 sgd_solver.cpp:138] Iteration 5290, lr = 2.5e-05
I0210 00:31:00.245543  6526 solver.cpp:243] Iteration 5300, loss = 6.33804
I0210 00:31:00.245668  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.38284 (* 1 = 6.38284 loss)
I0210 00:31:00.245717  6526 sgd_solver.cpp:138] Iteration 5300, lr = 2.5e-05
I0210 00:32:08.603641  6526 solver.cpp:243] Iteration 5310, loss = 6.28648
I0210 00:32:08.607167  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.62155 (* 1 = 6.62155 loss)
I0210 00:32:08.607228  6526 sgd_solver.cpp:138] Iteration 5310, lr = 2.5e-05
I0210 00:33:18.351003  6526 solver.cpp:243] Iteration 5320, loss = 6.34551
I0210 00:33:18.351133  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.20628 (* 1 = 6.20628 loss)
I0210 00:33:21.247439  6526 sgd_solver.cpp:138] Iteration 5320, lr = 2.5e-05
I0210 00:34:26.175467  6526 solver.cpp:243] Iteration 5330, loss = 6.33073
I0210 00:34:26.190417  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.2538 (* 1 = 6.2538 loss)
I0210 00:34:29.202546  6526 sgd_solver.cpp:138] Iteration 5330, lr = 2.5e-05
I0210 00:35:34.049767  6526 solver.cpp:243] Iteration 5340, loss = 6.31552
I0210 00:35:34.060433  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.13511 (* 1 = 6.13511 loss)
I0210 00:35:40.436542  6526 sgd_solver.cpp:138] Iteration 5340, lr = 2.5e-05
I0210 00:36:45.285675  6526 solver.cpp:243] Iteration 5350, loss = 6.29332
I0210 00:36:45.285771  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.2048 (* 1 = 6.2048 loss)
I0210 00:36:51.825736  6526 sgd_solver.cpp:138] Iteration 5350, lr = 2.5e-05
I0210 00:37:57.632979  6526 solver.cpp:243] Iteration 5360, loss = 6.25868
I0210 00:37:57.633515  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.35008 (* 1 = 6.35008 loss)
I0210 00:38:03.697860  6526 sgd_solver.cpp:138] Iteration 5360, lr = 2.5e-05
I0210 00:39:09.204905  6526 solver.cpp:243] Iteration 5370, loss = 6.41347
I0210 00:39:09.205087  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.27968 (* 1 = 6.27968 loss)
I0210 00:39:15.901139  6526 sgd_solver.cpp:138] Iteration 5370, lr = 2.5e-05
I0210 00:40:19.187309  6526 solver.cpp:243] Iteration 5380, loss = 6.28171
I0210 00:40:19.189496  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.52828 (* 1 = 6.52828 loss)
I0210 00:40:25.137614  6526 sgd_solver.cpp:138] Iteration 5380, lr = 2.5e-05
I0210 00:41:29.080925  6526 solver.cpp:243] Iteration 5390, loss = 6.27236
I0210 00:41:29.081759  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.2697 (* 1 = 6.2697 loss)
I0210 00:41:34.556274  6526 sgd_solver.cpp:138] Iteration 5390, lr = 2.5e-05
I0210 00:42:41.077816  6526 solver.cpp:243] Iteration 5400, loss = 6.20185
I0210 00:42:41.077953  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.54736 (* 1 = 6.54736 loss)
I0210 00:42:47.353456  6526 sgd_solver.cpp:138] Iteration 5400, lr = 2.5e-05
I0210 00:43:50.757949  6526 solver.cpp:243] Iteration 5410, loss = 6.28126
I0210 00:43:50.758122  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.3656 (* 1 = 6.3656 loss)
I0210 00:43:56.373366  6526 sgd_solver.cpp:138] Iteration 5410, lr = 2.5e-05
I0210 00:45:01.620203  6526 solver.cpp:243] Iteration 5420, loss = 6.25215
I0210 00:45:01.620458  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.59872 (* 1 = 6.59872 loss)
I0210 00:45:07.145450  6526 sgd_solver.cpp:138] Iteration 5420, lr = 2.5e-05
I0210 00:46:12.934854  6526 solver.cpp:243] Iteration 5430, loss = 6.46783
I0210 00:46:12.935024  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.78227 (* 1 = 6.78227 loss)
I0210 00:46:18.624114  6526 sgd_solver.cpp:138] Iteration 5430, lr = 2.5e-05
I0210 00:47:27.367480  6526 solver.cpp:243] Iteration 5440, loss = 6.17321
I0210 00:47:27.367642  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.05474 (* 1 = 6.05474 loss)
I0210 00:47:33.667619  6526 sgd_solver.cpp:138] Iteration 5440, lr = 2.5e-05
I0210 00:48:37.119153  6526 solver.cpp:243] Iteration 5450, loss = 6.35248
I0210 00:48:37.119290  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.58836 (* 1 = 6.58836 loss)
I0210 00:48:43.545359  6526 sgd_solver.cpp:138] Iteration 5450, lr = 2.5e-05
I0210 00:49:46.957029  6526 solver.cpp:243] Iteration 5460, loss = 6.28579
I0210 00:49:46.957240  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.08624 (* 1 = 6.08624 loss)
I0210 00:49:54.467478  6526 sgd_solver.cpp:138] Iteration 5460, lr = 2.5e-05
I0210 00:51:00.157109  6526 solver.cpp:243] Iteration 5470, loss = 6.23295
I0210 00:51:00.167826  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.60017 (* 1 = 6.60017 loss)
I0210 00:51:06.521971  6526 sgd_solver.cpp:138] Iteration 5470, lr = 2.5e-05
I0210 00:52:13.702261  6526 solver.cpp:243] Iteration 5480, loss = 6.1785
I0210 00:52:13.713057  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.3891 (* 1 = 6.3891 loss)
I0210 00:52:19.616714  6526 sgd_solver.cpp:138] Iteration 5480, lr = 2.5e-05
I0210 00:53:21.305313  6526 solver.cpp:243] Iteration 5490, loss = 6.40127
I0210 00:53:21.305486  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.62802 (* 1 = 6.62802 loss)
I0210 00:53:27.796870  6526 sgd_solver.cpp:138] Iteration 5490, lr = 2.5e-05
I0210 00:54:32.212900  6526 solver.cpp:243] Iteration 5500, loss = 6.56501
I0210 00:54:32.213024  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.6381 (* 1 = 6.6381 loss)
I0210 00:54:37.455260  6526 sgd_solver.cpp:138] Iteration 5500, lr = 2.5e-05
I0210 00:55:39.650432  6526 solver.cpp:243] Iteration 5510, loss = 6.30631
I0210 00:55:39.650559  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.27493 (* 1 = 6.27493 loss)
I0210 00:55:46.082227  6526 sgd_solver.cpp:138] Iteration 5510, lr = 2.5e-05
I0210 00:56:49.185498  6526 solver.cpp:243] Iteration 5520, loss = 6.1712
I0210 00:56:49.198415  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.55649 (* 1 = 6.55649 loss)
I0210 00:56:54.812161  6526 sgd_solver.cpp:138] Iteration 5520, lr = 2.5e-05
I0210 00:57:02.066403  6557 blocking_queue.cpp:50] Data layer prefetch queue empty
I0210 00:58:00.225705  6526 solver.cpp:243] Iteration 5530, loss = 6.37209
I0210 00:58:00.225828  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.87981 (* 1 = 5.87981 loss)
I0210 00:58:07.079772  6526 sgd_solver.cpp:138] Iteration 5530, lr = 2.5e-05
I0210 00:59:14.887997  6526 solver.cpp:243] Iteration 5540, loss = 6.58405
I0210 00:59:14.888118  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.4937 (* 1 = 6.4937 loss)
I0210 00:59:20.008851  6526 sgd_solver.cpp:138] Iteration 5540, lr = 2.5e-05
I0210 01:00:21.296968  6526 solver.cpp:243] Iteration 5550, loss = 6.21405
I0210 01:00:21.307601  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.27669 (* 1 = 6.27669 loss)
I0210 01:00:27.261384  6526 sgd_solver.cpp:138] Iteration 5550, lr = 2.5e-05
I0210 01:01:31.890842  6526 solver.cpp:243] Iteration 5560, loss = 6.25092
I0210 01:01:31.891772  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.20331 (* 1 = 6.20331 loss)
I0210 01:01:37.504314  6526 sgd_solver.cpp:138] Iteration 5560, lr = 2.5e-05
I0210 01:02:38.320613  6526 solver.cpp:243] Iteration 5570, loss = 6.29535
I0210 01:02:38.324388  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.14021 (* 1 = 6.14021 loss)
I0210 01:02:43.527611  6526 sgd_solver.cpp:138] Iteration 5570, lr = 2.5e-05
I0210 01:03:50.019330  6526 solver.cpp:243] Iteration 5580, loss = 6.23535
I0210 01:03:50.026388  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.15806 (* 1 = 6.15806 loss)
I0210 01:03:56.142935  6526 sgd_solver.cpp:138] Iteration 5580, lr = 2.5e-05
I0210 01:04:57.623178  6526 solver.cpp:243] Iteration 5590, loss = 6.26559
I0210 01:04:57.623353  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.2401 (* 1 = 6.2401 loss)
I0210 01:05:05.001983  6526 sgd_solver.cpp:138] Iteration 5590, lr = 2.5e-05
I0210 01:06:09.754925  6526 solver.cpp:243] Iteration 5600, loss = 6.27118
I0210 01:06:09.755090  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.1051 (* 1 = 6.1051 loss)
I0210 01:06:14.214136  6526 sgd_solver.cpp:138] Iteration 5600, lr = 2.5e-05
I0210 01:07:16.061734  6526 solver.cpp:243] Iteration 5610, loss = 6.39464
I0210 01:07:16.061961  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.46521 (* 1 = 6.46521 loss)
I0210 01:07:22.014731  6526 sgd_solver.cpp:138] Iteration 5610, lr = 2.5e-05
I0210 01:08:25.072276  6526 solver.cpp:243] Iteration 5620, loss = 6.16194
I0210 01:08:25.073271  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.78186 (* 1 = 5.78186 loss)
I0210 01:08:31.567306  6526 sgd_solver.cpp:138] Iteration 5620, lr = 2.5e-05
I0210 01:09:32.881544  6526 solver.cpp:243] Iteration 5630, loss = 6.32806
I0210 01:09:32.885103  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.20441 (* 1 = 6.20441 loss)
I0210 01:09:38.969961  6526 sgd_solver.cpp:138] Iteration 5630, lr = 2.5e-05
I0210 01:10:44.051570  6526 solver.cpp:243] Iteration 5640, loss = 6.30461
I0210 01:10:44.051735  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.57332 (* 1 = 6.57332 loss)
I0210 01:10:51.019485  6526 sgd_solver.cpp:138] Iteration 5640, lr = 2.5e-05
I0210 01:11:56.774966  6526 solver.cpp:243] Iteration 5650, loss = 6.3778
I0210 01:11:56.775092  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.60659 (* 1 = 6.60659 loss)
I0210 01:12:01.086735  6526 sgd_solver.cpp:138] Iteration 5650, lr = 2.5e-05
I0210 01:13:07.002213  6526 solver.cpp:243] Iteration 5660, loss = 6.32439
I0210 01:13:07.002383  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.58222 (* 1 = 6.58222 loss)
I0210 01:13:12.602437  6526 sgd_solver.cpp:138] Iteration 5660, lr = 2.5e-05
I0210 01:14:18.393148  6526 solver.cpp:243] Iteration 5670, loss = 6.35506
I0210 01:14:18.403863  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.42803 (* 1 = 6.42803 loss)
I0210 01:14:23.011960  6526 sgd_solver.cpp:138] Iteration 5670, lr = 2.5e-05
I0210 01:15:28.119009  6526 solver.cpp:243] Iteration 5680, loss = 6.32214
I0210 01:15:28.119132  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.28297 (* 1 = 6.28297 loss)
I0210 01:15:34.443845  6526 sgd_solver.cpp:138] Iteration 5680, lr = 2.5e-05
I0210 01:16:38.232568  6526 solver.cpp:243] Iteration 5690, loss = 6.30912
I0210 01:16:38.232692  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.0551 (* 1 = 6.0551 loss)
I0210 01:16:42.251482  6526 sgd_solver.cpp:138] Iteration 5690, lr = 2.5e-05
I0210 01:17:47.409348  6526 solver.cpp:243] Iteration 5700, loss = 6.47766
I0210 01:17:47.419276  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.81176 (* 1 = 6.81176 loss)
I0210 01:17:52.288120  6526 sgd_solver.cpp:138] Iteration 5700, lr = 2.5e-05
I0210 01:18:52.791676  6526 solver.cpp:243] Iteration 5710, loss = 6.38214
I0210 01:18:52.795059  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.81945 (* 1 = 5.81945 loss)
I0210 01:18:58.993432  6526 sgd_solver.cpp:138] Iteration 5710, lr = 2.5e-05
I0210 01:20:02.173230  6526 solver.cpp:243] Iteration 5720, loss = 6.39856
I0210 01:20:02.173360  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.0307 (* 1 = 6.0307 loss)
I0210 01:20:07.822764  6526 sgd_solver.cpp:138] Iteration 5720, lr = 2.5e-05
I0210 01:21:12.382908  6526 solver.cpp:243] Iteration 5730, loss = 6.30446
I0210 01:21:12.383074  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.44189 (* 1 = 6.44189 loss)
I0210 01:21:16.950075  6526 sgd_solver.cpp:138] Iteration 5730, lr = 2.5e-05
I0210 01:22:21.988243  6526 solver.cpp:243] Iteration 5740, loss = 6.18883
I0210 01:22:21.988349  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.875 (* 1 = 5.875 loss)
I0210 01:22:29.076005  6526 sgd_solver.cpp:138] Iteration 5740, lr = 2.5e-05
I0210 01:23:33.081851  6526 solver.cpp:243] Iteration 5750, loss = 6.33537
I0210 01:23:33.082018  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.14273 (* 1 = 6.14273 loss)
I0210 01:23:38.611450  6526 sgd_solver.cpp:138] Iteration 5750, lr = 2.5e-05
I0210 01:24:42.559181  6526 solver.cpp:243] Iteration 5760, loss = 6.26862
I0210 01:24:42.559310  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.24923 (* 1 = 6.24923 loss)
I0210 01:24:47.987562  6526 sgd_solver.cpp:138] Iteration 5760, lr = 2.5e-05
I0210 01:25:52.506273  6526 solver.cpp:243] Iteration 5770, loss = 6.42781
I0210 01:25:52.517079  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.22281 (* 1 = 6.22281 loss)
I0210 01:25:58.703821  6526 sgd_solver.cpp:138] Iteration 5770, lr = 2.5e-05
I0210 01:27:04.794843  6526 solver.cpp:243] Iteration 5780, loss = 6.22232
I0210 01:27:04.794976  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.07503 (* 1 = 6.07503 loss)
I0210 01:27:07.543551  6526 sgd_solver.cpp:138] Iteration 5780, lr = 2.5e-05
I0210 01:28:14.299196  6526 solver.cpp:243] Iteration 5790, loss = 6.20244
I0210 01:28:14.301143  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.0319 (* 1 = 6.0319 loss)
I0210 01:28:17.210760  6526 sgd_solver.cpp:138] Iteration 5790, lr = 2.5e-05
I0210 01:29:25.619770  6526 solver.cpp:243] Iteration 5800, loss = 6.32158
I0210 01:29:25.619889  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.13836 (* 1 = 6.13836 loss)
I0210 01:29:28.354732  6526 sgd_solver.cpp:138] Iteration 5800, lr = 2.5e-05
I0210 01:30:34.768118  6526 solver.cpp:243] Iteration 5810, loss = 6.17401
I0210 01:30:34.773654  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.68869 (* 1 = 6.68869 loss)
I0210 01:30:36.232913  6526 sgd_solver.cpp:138] Iteration 5810, lr = 2.5e-05
I0210 01:31:46.252766  6526 solver.cpp:243] Iteration 5820, loss = 6.28933
I0210 01:31:46.254866  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.58361 (* 1 = 6.58361 loss)
I0210 01:31:49.669119  6526 sgd_solver.cpp:138] Iteration 5820, lr = 2.5e-05
I0210 01:32:55.464283  6526 solver.cpp:243] Iteration 5830, loss = 6.38727
I0210 01:32:55.464449  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.87094 (* 1 = 5.87094 loss)
I0210 01:32:59.774819  6526 sgd_solver.cpp:138] Iteration 5830, lr = 2.5e-05
I0210 01:34:05.390496  6526 solver.cpp:243] Iteration 5840, loss = 6.19071
I0210 01:34:05.390607  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.30077 (* 1 = 6.30077 loss)
I0210 01:34:09.478592  6526 sgd_solver.cpp:138] Iteration 5840, lr = 2.5e-05
I0210 01:35:16.841775  6526 solver.cpp:243] Iteration 5850, loss = 6.20213
I0210 01:35:16.849896  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.06358 (* 1 = 6.06358 loss)
I0210 01:35:21.432412  6526 sgd_solver.cpp:138] Iteration 5850, lr = 2.5e-05
I0210 01:36:26.829530  6526 solver.cpp:243] Iteration 5860, loss = 6.25301
I0210 01:36:26.829742  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.86441 (* 1 = 5.86441 loss)
I0210 01:36:32.128440  6526 sgd_solver.cpp:138] Iteration 5860, lr = 2.5e-05
I0210 01:37:36.619629  6526 solver.cpp:243] Iteration 5870, loss = 6.32189
I0210 01:37:36.620486  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.28308 (* 1 = 6.28308 loss)
I0210 01:37:40.637686  6526 sgd_solver.cpp:138] Iteration 5870, lr = 2.5e-05
I0210 01:38:45.264762  6526 solver.cpp:243] Iteration 5880, loss = 6.19781
I0210 01:38:45.264935  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.8439 (* 1 = 5.8439 loss)
I0210 01:38:49.893187  6526 sgd_solver.cpp:138] Iteration 5880, lr = 2.5e-05
I0210 01:39:51.359143  6526 solver.cpp:243] Iteration 5890, loss = 6.34193
I0210 01:39:51.362190  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.36065 (* 1 = 6.36065 loss)
I0210 01:39:56.956007  6526 sgd_solver.cpp:138] Iteration 5890, lr = 2.5e-05
I0210 01:41:00.384901  6526 solver.cpp:243] Iteration 5900, loss = 6.26426
I0210 01:41:00.385026  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.84617 (* 1 = 5.84617 loss)
I0210 01:41:05.658128  6526 sgd_solver.cpp:138] Iteration 5900, lr = 2.5e-05
I0210 01:42:12.350953  6526 solver.cpp:243] Iteration 5910, loss = 6.37643
I0210 01:42:12.351361  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.31527 (* 1 = 6.31527 loss)
I0210 01:42:16.566498  6526 sgd_solver.cpp:138] Iteration 5910, lr = 2.5e-05
I0210 01:43:24.372520  6526 solver.cpp:243] Iteration 5920, loss = 6.22554
I0210 01:43:24.372654  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.05227 (* 1 = 6.05227 loss)
I0210 01:43:28.126334  6526 sgd_solver.cpp:138] Iteration 5920, lr = 2.5e-05
I0210 01:44:33.285516  6526 solver.cpp:243] Iteration 5930, loss = 6.28452
I0210 01:44:33.285665  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.19569 (* 1 = 6.19569 loss)
I0210 01:44:37.092453  6526 sgd_solver.cpp:138] Iteration 5930, lr = 2.5e-05
I0210 01:45:41.205770  6526 solver.cpp:243] Iteration 5940, loss = 6.22489
I0210 01:45:41.205899  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.81068 (* 1 = 5.81068 loss)
I0210 01:45:47.371666  6526 sgd_solver.cpp:138] Iteration 5940, lr = 2.5e-05
I0210 01:46:51.636099  6526 solver.cpp:243] Iteration 5950, loss = 6.25642
I0210 01:46:51.644630  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.82197 (* 1 = 5.82197 loss)
I0210 01:46:57.027909  6526 sgd_solver.cpp:138] Iteration 5950, lr = 2.5e-05
I0210 01:48:00.890766  6526 solver.cpp:243] Iteration 5960, loss = 6.35272
I0210 01:48:00.890878  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.98323 (* 1 = 5.98323 loss)
I0210 01:48:05.642930  6526 sgd_solver.cpp:138] Iteration 5960, lr = 2.5e-05
I0210 01:49:09.434710  6526 solver.cpp:243] Iteration 5970, loss = 6.31834
I0210 01:49:09.439285  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.56711 (* 1 = 6.56711 loss)
I0210 01:49:14.953876  6526 sgd_solver.cpp:138] Iteration 5970, lr = 2.5e-05
I0210 01:50:17.741662  6526 solver.cpp:243] Iteration 5980, loss = 6.30865
I0210 01:50:17.751678  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.81252 (* 1 = 5.81252 loss)
I0210 01:50:23.210283  6526 sgd_solver.cpp:138] Iteration 5980, lr = 2.5e-05
I0210 01:51:31.750573  6526 solver.cpp:243] Iteration 5990, loss = 6.26901
I0210 01:51:31.750705  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.99792 (* 1 = 5.99792 loss)
I0210 01:51:31.750754  6526 sgd_solver.cpp:138] Iteration 5990, lr = 2.5e-05
I0210 01:52:41.583912  6526 solver.cpp:243] Iteration 6000, loss = 6.41222
I0210 01:52:41.587746  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.59142 (* 1 = 6.59142 loss)
I0210 01:52:41.587846  6526 sgd_solver.cpp:138] Iteration 6000, lr = 2.5e-05
I0210 01:53:48.839701  6526 solver.cpp:243] Iteration 6010, loss = 6.22893
I0210 01:53:48.841902  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.84866 (* 1 = 6.84866 loss)
I0210 01:53:51.687717  6526 sgd_solver.cpp:138] Iteration 6010, lr = 2.5e-05
I0210 01:54:57.625636  6526 solver.cpp:243] Iteration 6020, loss = 6.23791
I0210 01:54:57.636243  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.00222 (* 1 = 6.00222 loss)
I0210 01:55:01.159881  6526 sgd_solver.cpp:138] Iteration 6020, lr = 2.5e-05
I0210 01:56:04.544548  6526 solver.cpp:243] Iteration 6030, loss = 6.18742
I0210 01:56:04.544684  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.90891 (* 1 = 5.90891 loss)
I0210 01:56:10.827350  6526 sgd_solver.cpp:138] Iteration 6030, lr = 2.5e-05
I0210 01:57:14.594204  6526 solver.cpp:243] Iteration 6040, loss = 6.06351
I0210 01:57:14.594382  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.76091 (* 1 = 5.76091 loss)
I0210 01:57:20.953393  6526 sgd_solver.cpp:138] Iteration 6040, lr = 2.5e-05
I0210 01:58:25.253368  6526 solver.cpp:243] Iteration 6050, loss = 6.21478
I0210 01:58:25.253549  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.19097 (* 1 = 6.19097 loss)
I0210 01:58:29.280032  6526 sgd_solver.cpp:138] Iteration 6050, lr = 2.5e-05
I0210 01:59:35.170327  6526 solver.cpp:243] Iteration 6060, loss = 6.31593
I0210 01:59:35.170599  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.57702 (* 1 = 6.57702 loss)
I0210 01:59:41.605805  6526 sgd_solver.cpp:138] Iteration 6060, lr = 2.5e-05
I0210 02:00:46.019645  6526 solver.cpp:243] Iteration 6070, loss = 6.18308
I0210 02:00:46.022434  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.12085 (* 1 = 6.12085 loss)
I0210 02:00:51.220585  6526 sgd_solver.cpp:138] Iteration 6070, lr = 2.5e-05
I0210 02:01:55.038965  6526 solver.cpp:243] Iteration 6080, loss = 6.23044
I0210 02:01:55.039155  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.51315 (* 1 = 6.51315 loss)
I0210 02:02:01.072113  6526 sgd_solver.cpp:138] Iteration 6080, lr = 2.5e-05
I0210 02:03:05.507315  6526 solver.cpp:243] Iteration 6090, loss = 6.37996
I0210 02:03:05.507446  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.57283 (* 1 = 6.57283 loss)
I0210 02:03:11.563951  6526 sgd_solver.cpp:138] Iteration 6090, lr = 2.5e-05
I0210 02:04:18.016834  6526 solver.cpp:243] Iteration 6100, loss = 6.3298
I0210 02:04:18.016955  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.99226 (* 1 = 6.99226 loss)
I0210 02:04:22.669025  6526 sgd_solver.cpp:138] Iteration 6100, lr = 2.5e-05
I0210 02:05:27.390929  6526 solver.cpp:243] Iteration 6110, loss = 6.30936
I0210 02:05:27.391099  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.61823 (* 1 = 6.61823 loss)
I0210 02:05:32.364293  6526 sgd_solver.cpp:138] Iteration 6110, lr = 2.5e-05
I0210 02:06:39.578410  6526 solver.cpp:243] Iteration 6120, loss = 6.31587
I0210 02:06:39.578516  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.87838 (* 1 = 6.87838 loss)
I0210 02:06:43.384316  6526 sgd_solver.cpp:138] Iteration 6120, lr = 2.5e-05
I0210 02:07:46.092942  6526 solver.cpp:243] Iteration 6130, loss = 6.22439
I0210 02:07:46.093060  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.90944 (* 1 = 5.90944 loss)
I0210 02:07:52.068374  6526 sgd_solver.cpp:138] Iteration 6130, lr = 2.5e-05
I0210 02:08:56.019353  6526 solver.cpp:243] Iteration 6140, loss = 6.16434
I0210 02:08:56.019481  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.01129 (* 1 = 6.01129 loss)
I0210 02:09:01.029894  6526 sgd_solver.cpp:138] Iteration 6140, lr = 2.5e-05
I0210 02:10:06.574272  6526 solver.cpp:243] Iteration 6150, loss = 6.08863
I0210 02:10:06.574441  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.92654 (* 1 = 5.92654 loss)
I0210 02:10:11.138413  6526 sgd_solver.cpp:138] Iteration 6150, lr = 2.5e-05
I0210 02:11:17.358584  6526 solver.cpp:243] Iteration 6160, loss = 6.39345
I0210 02:11:17.358759  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.10385 (* 1 = 6.10385 loss)
I0210 02:11:23.071529  6526 sgd_solver.cpp:138] Iteration 6160, lr = 2.5e-05
I0210 02:11:51.773473  6556 blocking_queue.cpp:50] Data layer prefetch queue empty
I0210 02:12:29.446787  6526 solver.cpp:243] Iteration 6170, loss = 6.33064
I0210 02:12:29.446907  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.36054 (* 1 = 6.36054 loss)
I0210 02:12:34.408502  6526 sgd_solver.cpp:138] Iteration 6170, lr = 2.5e-05
I0210 02:13:38.933290  6526 solver.cpp:243] Iteration 6180, loss = 6.24481
I0210 02:13:38.933411  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.98479 (* 1 = 5.98479 loss)
I0210 02:13:44.643112  6526 sgd_solver.cpp:138] Iteration 6180, lr = 2.5e-05
I0210 02:14:50.363340  6526 solver.cpp:243] Iteration 6190, loss = 6.31616
I0210 02:14:50.363435  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.29788 (* 1 = 6.29788 loss)
I0210 02:14:55.460685  6526 sgd_solver.cpp:138] Iteration 6190, lr = 2.5e-05
I0210 02:15:58.411626  6526 solver.cpp:243] Iteration 6200, loss = 6.29105
I0210 02:15:58.413280  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.52767 (* 1 = 6.52767 loss)
I0210 02:16:04.176740  6526 sgd_solver.cpp:138] Iteration 6200, lr = 2.5e-05
I0210 02:17:07.357106  6526 solver.cpp:243] Iteration 6210, loss = 6.34243
I0210 02:17:07.357352  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.51193 (* 1 = 6.51193 loss)
I0210 02:17:11.832558  6526 sgd_solver.cpp:138] Iteration 6210, lr = 2.5e-05
I0210 02:18:12.912086  6526 solver.cpp:243] Iteration 6220, loss = 6.17776
I0210 02:18:12.912185  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.34886 (* 1 = 6.34886 loss)
I0210 02:18:18.590220  6526 sgd_solver.cpp:138] Iteration 6220, lr = 2.5e-05
I0210 02:19:21.733162  6526 solver.cpp:243] Iteration 6230, loss = 6.29709
I0210 02:19:21.733337  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.62722 (* 1 = 6.62722 loss)
I0210 02:19:28.282762  6526 sgd_solver.cpp:138] Iteration 6230, lr = 2.5e-05
I0210 02:20:32.656159  6526 solver.cpp:243] Iteration 6240, loss = 6.26157
I0210 02:20:32.658412  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.54308 (* 1 = 6.54308 loss)
I0210 02:20:38.079059  6526 sgd_solver.cpp:138] Iteration 6240, lr = 2.5e-05
I0210 02:21:42.277318  6526 solver.cpp:243] Iteration 6250, loss = 6.21298
I0210 02:21:42.287997  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.38287 (* 1 = 6.38287 loss)
I0210 02:21:47.385766  6526 sgd_solver.cpp:138] Iteration 6250, lr = 2.5e-05
I0210 02:22:52.853909  6526 solver.cpp:243] Iteration 6260, loss = 6.38324
I0210 02:22:52.854038  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.29749 (* 1 = 6.29749 loss)
I0210 02:22:58.008781  6526 sgd_solver.cpp:138] Iteration 6260, lr = 2.5e-05
I0210 02:24:01.045532  6526 solver.cpp:243] Iteration 6270, loss = 6.07579
I0210 02:24:01.045666  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.14924 (* 1 = 6.14924 loss)
I0210 02:24:06.484742  6526 sgd_solver.cpp:138] Iteration 6270, lr = 2.5e-05
I0210 02:25:13.648036  6526 solver.cpp:243] Iteration 6280, loss = 6.3608
I0210 02:25:13.649834  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.25986 (* 1 = 6.25986 loss)
I0210 02:25:20.128543  6526 sgd_solver.cpp:138] Iteration 6280, lr = 2.5e-05
I0210 02:26:26.025637  6526 solver.cpp:243] Iteration 6290, loss = 6.39472
I0210 02:26:26.025775  6526 solver.cpp:259]     Train net output #0: mbox_loss = 7.8233 (* 1 = 7.8233 loss)
I0210 02:26:31.507647  6526 sgd_solver.cpp:138] Iteration 6290, lr = 2.5e-05
I0210 02:27:35.752849  6526 solver.cpp:243] Iteration 6300, loss = 6.20817
I0210 02:27:35.755280  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.34013 (* 1 = 6.34013 loss)
I0210 02:27:40.782670  6526 sgd_solver.cpp:138] Iteration 6300, lr = 2.5e-05
I0210 02:28:45.214275  6526 solver.cpp:243] Iteration 6310, loss = 6.39932
I0210 02:28:45.223554  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.12737 (* 1 = 6.12737 loss)
I0210 02:28:50.806260  6526 sgd_solver.cpp:138] Iteration 6310, lr = 2.5e-05
I0210 02:29:57.712532  6526 solver.cpp:243] Iteration 6320, loss = 6.3401
I0210 02:29:57.733122  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.15862 (* 1 = 6.15862 loss)
I0210 02:30:03.671548  6526 sgd_solver.cpp:138] Iteration 6320, lr = 2.5e-05
I0210 02:31:10.252418  6526 solver.cpp:243] Iteration 6330, loss = 6.2337
I0210 02:31:10.252583  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.12416 (* 1 = 6.12416 loss)
I0210 02:31:15.458811  6526 sgd_solver.cpp:138] Iteration 6330, lr = 2.5e-05
I0210 02:32:20.956517  6526 solver.cpp:243] Iteration 6340, loss = 6.3006
I0210 02:32:20.966498  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.73615 (* 1 = 6.73615 loss)
I0210 02:32:27.518717  6526 sgd_solver.cpp:138] Iteration 6340, lr = 2.5e-05
I0210 02:33:28.758373  6526 solver.cpp:243] Iteration 6350, loss = 6.07914
I0210 02:33:28.758553  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.18548 (* 1 = 6.18548 loss)
I0210 02:33:36.537760  6526 sgd_solver.cpp:138] Iteration 6350, lr = 2.5e-05
I0210 02:34:38.687019  6526 solver.cpp:243] Iteration 6360, loss = 6.48164
I0210 02:34:38.687197  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.36318 (* 1 = 6.36318 loss)
I0210 02:34:44.357589  6526 sgd_solver.cpp:138] Iteration 6360, lr = 2.5e-05
I0210 02:35:49.941303  6526 solver.cpp:243] Iteration 6370, loss = 6.17306
I0210 02:35:49.941401  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.00472 (* 1 = 6.00472 loss)
I0210 02:35:55.029642  6526 sgd_solver.cpp:138] Iteration 6370, lr = 2.5e-05
I0210 02:36:57.046638  6526 solver.cpp:243] Iteration 6380, loss = 6.34112
I0210 02:36:57.046795  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.16722 (* 1 = 6.16722 loss)
I0210 02:37:03.926679  6526 sgd_solver.cpp:138] Iteration 6380, lr = 2.5e-05
I0210 02:38:09.162313  6526 solver.cpp:243] Iteration 6390, loss = 6.09319
I0210 02:38:09.162504  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.85104 (* 1 = 5.85104 loss)
I0210 02:38:15.251981  6526 sgd_solver.cpp:138] Iteration 6390, lr = 2.5e-05
I0210 02:39:19.565060  6526 solver.cpp:243] Iteration 6400, loss = 6.28435
I0210 02:39:19.568977  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.14005 (* 1 = 6.14005 loss)
I0210 02:39:25.602134  6526 sgd_solver.cpp:138] Iteration 6400, lr = 2.5e-05
I0210 02:40:32.158244  6526 solver.cpp:243] Iteration 6410, loss = 6.28473
I0210 02:40:32.158383  6526 solver.cpp:259]     Train net output #0: mbox_loss = 7.51173 (* 1 = 7.51173 loss)
I0210 02:40:38.648104  6526 sgd_solver.cpp:138] Iteration 6410, lr = 2.5e-05
I0210 02:41:44.160197  6526 solver.cpp:243] Iteration 6420, loss = 6.32093
I0210 02:41:44.160356  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.45943 (* 1 = 6.45943 loss)
I0210 02:41:48.517371  6526 sgd_solver.cpp:138] Iteration 6420, lr = 2.5e-05
I0210 02:42:51.272807  6526 solver.cpp:243] Iteration 6430, loss = 6.32202
I0210 02:42:51.281916  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.64459 (* 1 = 6.64459 loss)
I0210 02:42:57.650563  6526 sgd_solver.cpp:138] Iteration 6430, lr = 2.5e-05
I0210 02:44:00.750193  6526 solver.cpp:243] Iteration 6440, loss = 6.23133
I0210 02:44:00.750298  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.45401 (* 1 = 6.45401 loss)
I0210 02:44:04.369020  6526 sgd_solver.cpp:138] Iteration 6440, lr = 2.5e-05
I0210 02:45:08.271369  6526 solver.cpp:243] Iteration 6450, loss = 6.2302
I0210 02:45:08.275641  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.19928 (* 1 = 6.19928 loss)
I0210 02:45:15.159801  6526 sgd_solver.cpp:138] Iteration 6450, lr = 2.5e-05
I0210 02:46:16.344971  6526 solver.cpp:243] Iteration 6460, loss = 6.31946
I0210 02:46:16.345106  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.28 (* 1 = 6.28 loss)
I0210 02:46:22.686934  6526 sgd_solver.cpp:138] Iteration 6460, lr = 2.5e-05
I0210 02:47:27.203810  6526 solver.cpp:243] Iteration 6470, loss = 6.30967
I0210 02:47:27.203910  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.99725 (* 1 = 5.99725 loss)
I0210 02:47:32.783752  6526 sgd_solver.cpp:138] Iteration 6470, lr = 2.5e-05
I0210 02:48:39.327989  6526 solver.cpp:243] Iteration 6480, loss = 6.31909
I0210 02:48:39.342516  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.33837 (* 1 = 6.33837 loss)
I0210 02:48:44.264152  6526 sgd_solver.cpp:138] Iteration 6480, lr = 2.5e-05
I0210 02:49:52.165783  6526 solver.cpp:243] Iteration 6490, loss = 6.1326
I0210 02:49:52.165907  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.04156 (* 1 = 6.04156 loss)
I0210 02:49:56.768165  6526 sgd_solver.cpp:138] Iteration 6490, lr = 2.5e-05
I0210 02:51:02.634809  6526 solver.cpp:243] Iteration 6500, loss = 6.16065
I0210 02:51:02.646379  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.93956 (* 1 = 5.93956 loss)
I0210 02:51:06.690528  6526 sgd_solver.cpp:138] Iteration 6500, lr = 2.5e-05
I0210 02:52:12.205754  6526 solver.cpp:243] Iteration 6510, loss = 6.19465
I0210 02:52:12.205888  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.26136 (* 1 = 6.26136 loss)
I0210 02:52:18.135855  6526 sgd_solver.cpp:138] Iteration 6510, lr = 2.5e-05
I0210 02:53:21.205678  6526 solver.cpp:243] Iteration 6520, loss = 6.21652
I0210 02:53:21.205811  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.51011 (* 1 = 6.51011 loss)
I0210 02:53:28.143616  6526 sgd_solver.cpp:138] Iteration 6520, lr = 2.5e-05
I0210 02:54:31.943724  6526 solver.cpp:243] Iteration 6530, loss = 6.1961
I0210 02:54:31.943886  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.28065 (* 1 = 6.28065 loss)
I0210 02:54:37.763120  6526 sgd_solver.cpp:138] Iteration 6530, lr = 2.5e-05
I0210 02:55:40.062369  6526 solver.cpp:243] Iteration 6540, loss = 6.27777
I0210 02:55:40.062489  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.34672 (* 1 = 6.34672 loss)
I0210 02:55:46.113524  6526 sgd_solver.cpp:138] Iteration 6540, lr = 2.5e-05
I0210 02:56:49.846130  6526 solver.cpp:243] Iteration 6550, loss = 6.34278
I0210 02:56:49.846295  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.66011 (* 1 = 6.66011 loss)
I0210 02:56:54.184320  6526 sgd_solver.cpp:138] Iteration 6550, lr = 2.5e-05
I0210 02:58:01.010776  6526 solver.cpp:243] Iteration 6560, loss = 6.2252
I0210 02:58:01.010882  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.66142 (* 1 = 6.66142 loss)
I0210 02:58:05.622323  6526 sgd_solver.cpp:138] Iteration 6560, lr = 2.5e-05
I0210 02:59:07.730468  6526 solver.cpp:243] Iteration 6570, loss = 6.32221
I0210 02:59:07.730641  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.37962 (* 1 = 6.37962 loss)
I0210 02:59:13.471829  6526 sgd_solver.cpp:138] Iteration 6570, lr = 2.5e-05
I0210 03:00:19.774302  6526 solver.cpp:243] Iteration 6580, loss = 6.2972
I0210 03:00:19.774402  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.04092 (* 1 = 6.04092 loss)
I0210 03:00:23.858880  6526 sgd_solver.cpp:138] Iteration 6580, lr = 2.5e-05
I0210 03:01:26.883548  6526 solver.cpp:243] Iteration 6590, loss = 6.33262
I0210 03:01:26.883666  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.18338 (* 1 = 6.18338 loss)
I0210 03:01:31.390100  6526 sgd_solver.cpp:138] Iteration 6590, lr = 2.5e-05
I0210 03:02:35.902751  6526 solver.cpp:243] Iteration 6600, loss = 6.20502
I0210 03:02:35.902935  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.29876 (* 1 = 6.29876 loss)
I0210 03:02:42.851876  6526 sgd_solver.cpp:138] Iteration 6600, lr = 2.5e-05
I0210 03:03:44.477593  6526 solver.cpp:243] Iteration 6610, loss = 6.27143
I0210 03:03:44.480024  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.34484 (* 1 = 6.34484 loss)
I0210 03:03:50.175009  6526 sgd_solver.cpp:138] Iteration 6610, lr = 2.5e-05
I0210 03:04:51.316565  6526 solver.cpp:243] Iteration 6620, loss = 6.37494
I0210 03:04:51.325428  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.9494 (* 1 = 6.9494 loss)
I0210 03:04:57.830524  6526 sgd_solver.cpp:138] Iteration 6620, lr = 2.5e-05
I0210 03:06:02.786883  6526 solver.cpp:243] Iteration 6630, loss = 6.23674
I0210 03:06:02.786999  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.33343 (* 1 = 6.33343 loss)
I0210 03:06:07.935477  6526 sgd_solver.cpp:138] Iteration 6630, lr = 2.5e-05
I0210 03:07:13.604516  6526 solver.cpp:243] Iteration 6640, loss = 6.31798
I0210 03:07:13.604630  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.56178 (* 1 = 6.56178 loss)
I0210 03:07:20.197428  6526 sgd_solver.cpp:138] Iteration 6640, lr = 2.5e-05
I0210 03:08:23.906611  6526 solver.cpp:243] Iteration 6650, loss = 6.19721
I0210 03:08:23.906713  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.10731 (* 1 = 6.10731 loss)
I0210 03:08:27.494753  6526 sgd_solver.cpp:138] Iteration 6650, lr = 2.5e-05
I0210 03:09:32.228207  6526 solver.cpp:243] Iteration 6660, loss = 6.23876
I0210 03:09:32.228368  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.66941 (* 1 = 6.66941 loss)
I0210 03:09:38.328627  6526 sgd_solver.cpp:138] Iteration 6660, lr = 2.5e-05
I0210 03:10:44.493932  6526 solver.cpp:243] Iteration 6670, loss = 6.13505
I0210 03:10:44.515242  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.07658 (* 1 = 6.07658 loss)
I0210 03:10:50.785204  6526 sgd_solver.cpp:138] Iteration 6670, lr = 2.5e-05
I0210 03:11:54.094228  6526 solver.cpp:243] Iteration 6680, loss = 6.25682
I0210 03:11:54.094406  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.43752 (* 1 = 6.43752 loss)
I0210 03:12:00.733285  6526 sgd_solver.cpp:138] Iteration 6680, lr = 2.5e-05
I0210 03:13:02.959574  6526 solver.cpp:243] Iteration 6690, loss = 6.18174
I0210 03:13:02.959702  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.20881 (* 1 = 6.20881 loss)
I0210 03:13:08.531108  6526 sgd_solver.cpp:138] Iteration 6690, lr = 2.5e-05
I0210 03:14:14.060662  6526 solver.cpp:243] Iteration 6700, loss = 6.31544
I0210 03:14:14.060792  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.21567 (* 1 = 6.21567 loss)
I0210 03:14:18.575130  6526 sgd_solver.cpp:138] Iteration 6700, lr = 2.5e-05
I0210 03:15:22.412562  6526 solver.cpp:243] Iteration 6710, loss = 6.38697
I0210 03:15:22.416391  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.86664 (* 1 = 6.86664 loss)
I0210 03:15:29.471997  6526 sgd_solver.cpp:138] Iteration 6710, lr = 2.5e-05
I0210 03:16:33.927310  6526 solver.cpp:243] Iteration 6720, loss = 6.184
I0210 03:16:33.927423  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.03536 (* 1 = 6.03536 loss)
I0210 03:16:39.439389  6526 sgd_solver.cpp:138] Iteration 6720, lr = 2.5e-05
I0210 03:17:41.258333  6526 solver.cpp:243] Iteration 6730, loss = 6.22199
I0210 03:17:41.258553  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.47034 (* 1 = 6.47034 loss)
I0210 03:17:46.569133  6526 sgd_solver.cpp:138] Iteration 6730, lr = 2.5e-05
I0210 03:18:49.357403  6526 solver.cpp:243] Iteration 6740, loss = 6.25316
I0210 03:18:49.362957  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.78548 (* 1 = 6.78548 loss)
I0210 03:18:55.606384  6526 sgd_solver.cpp:138] Iteration 6740, lr = 2.5e-05
I0210 03:19:59.374758  6526 solver.cpp:243] Iteration 6750, loss = 6.20659
I0210 03:19:59.374929  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.1211 (* 1 = 6.1211 loss)
I0210 03:20:03.315609  6526 sgd_solver.cpp:138] Iteration 6750, lr = 2.5e-05
I0210 03:21:06.929704  6526 solver.cpp:243] Iteration 6760, loss = 6.22809
I0210 03:21:06.929836  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.64736 (* 1 = 5.64736 loss)
I0210 03:21:11.072170  6526 sgd_solver.cpp:138] Iteration 6760, lr = 2.5e-05
I0210 03:22:17.547739  6526 solver.cpp:243] Iteration 6770, loss = 6.27184
I0210 03:22:17.547866  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.27522 (* 1 = 6.27522 loss)
I0210 03:22:21.033027  6526 sgd_solver.cpp:138] Iteration 6770, lr = 2.5e-05
I0210 03:23:26.789582  6526 solver.cpp:243] Iteration 6780, loss = 5.94348
I0210 03:23:26.802474  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.84804 (* 1 = 5.84804 loss)
I0210 03:23:30.152968  6526 sgd_solver.cpp:138] Iteration 6780, lr = 2.5e-05
I0210 03:24:38.378898  6526 solver.cpp:243] Iteration 6790, loss = 6.30172
I0210 03:24:38.379079  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.3788 (* 1 = 6.3788 loss)
I0210 03:24:39.753901  6526 sgd_solver.cpp:138] Iteration 6790, lr = 2.5e-05
I0210 03:25:49.707630  6526 solver.cpp:243] Iteration 6800, loss = 6.15526
I0210 03:25:49.707754  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.49522 (* 1 = 6.49522 loss)
I0210 03:25:49.707821  6526 sgd_solver.cpp:138] Iteration 6800, lr = 2.5e-05
I0210 03:26:57.456969  6526 solver.cpp:243] Iteration 6810, loss = 6.23039
I0210 03:26:57.457110  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.09742 (* 1 = 6.09742 loss)
I0210 03:27:00.526175  6526 sgd_solver.cpp:138] Iteration 6810, lr = 2.5e-05
I0210 03:28:06.336747  6526 solver.cpp:243] Iteration 6820, loss = 6.21995
I0210 03:28:06.336869  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.48141 (* 1 = 6.48141 loss)
I0210 03:28:10.935428  6526 sgd_solver.cpp:138] Iteration 6820, lr = 2.5e-05
I0210 03:29:13.540896  6526 solver.cpp:243] Iteration 6830, loss = 6.30868
I0210 03:29:13.541085  6526 solver.cpp:259]     Train net output #0: mbox_loss = 7.21961 (* 1 = 7.21961 loss)
I0210 03:29:19.764538  6526 sgd_solver.cpp:138] Iteration 6830, lr = 2.5e-05
I0210 03:30:22.923751  6526 solver.cpp:243] Iteration 6840, loss = 6.29422
I0210 03:30:22.925529  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.93646 (* 1 = 5.93646 loss)
I0210 03:30:28.596738  6526 sgd_solver.cpp:138] Iteration 6840, lr = 2.5e-05
I0210 03:31:31.780764  6526 solver.cpp:243] Iteration 6850, loss = 6.0929
I0210 03:31:31.781777  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.92801 (* 1 = 5.92801 loss)
I0210 03:31:38.540305  6526 sgd_solver.cpp:138] Iteration 6850, lr = 2.5e-05
I0210 03:32:42.186733  6526 solver.cpp:243] Iteration 6860, loss = 6.33334
I0210 03:32:42.186903  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.98793 (* 1 = 5.98793 loss)
I0210 03:32:48.556687  6526 sgd_solver.cpp:138] Iteration 6860, lr = 2.5e-05
I0210 03:33:56.515805  6526 solver.cpp:243] Iteration 6870, loss = 6.07188
I0210 03:33:56.515923  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.35751 (* 1 = 6.35751 loss)
I0210 03:34:01.261587  6526 sgd_solver.cpp:138] Iteration 6870, lr = 2.5e-05
I0210 03:35:03.591843  6526 solver.cpp:243] Iteration 6880, loss = 6.31227
I0210 03:35:03.591964  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.17635 (* 1 = 6.17635 loss)
I0210 03:35:06.492032  6526 sgd_solver.cpp:138] Iteration 6880, lr = 2.5e-05
I0210 03:36:15.147238  6526 solver.cpp:243] Iteration 6890, loss = 6.40057
I0210 03:36:15.147452  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.28625 (* 1 = 6.28625 loss)
I0210 03:36:15.147526  6526 sgd_solver.cpp:138] Iteration 6890, lr = 2.5e-05
I0210 03:37:27.063180  6526 solver.cpp:243] Iteration 6900, loss = 6.28859
I0210 03:37:27.063369  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.4817 (* 1 = 6.4817 loss)
I0210 03:37:27.063444  6526 sgd_solver.cpp:138] Iteration 6900, lr = 2.5e-05
I0210 03:38:33.858405  6526 solver.cpp:243] Iteration 6910, loss = 6.3297
I0210 03:38:33.858503  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.3161 (* 1 = 6.3161 loss)
I0210 03:38:36.501158  6526 sgd_solver.cpp:138] Iteration 6910, lr = 2.5e-05
I0210 03:38:36.527154  6556 blocking_queue.cpp:50] Data layer prefetch queue empty
I0210 03:39:42.079634  6526 solver.cpp:243] Iteration 6920, loss = 6.33242
I0210 03:39:42.079761  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.10475 (* 1 = 6.10475 loss)
I0210 03:39:45.337788  6526 sgd_solver.cpp:138] Iteration 6920, lr = 2.5e-05
I0210 03:40:50.944828  6526 solver.cpp:243] Iteration 6930, loss = 6.26482
I0210 03:40:50.954727  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.20883 (* 1 = 6.20883 loss)
I0210 03:40:55.816987  6526 sgd_solver.cpp:138] Iteration 6930, lr = 2.5e-05
I0210 03:42:02.192821  6526 solver.cpp:243] Iteration 6940, loss = 6.16905
I0210 03:42:02.195201  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.9482 (* 1 = 5.9482 loss)
I0210 03:42:07.057914  6526 sgd_solver.cpp:138] Iteration 6940, lr = 2.5e-05
I0210 03:43:14.322710  6526 solver.cpp:243] Iteration 6950, loss = 6.1926
I0210 03:43:14.323194  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.13309 (* 1 = 6.13309 loss)
I0210 03:43:20.097394  6526 sgd_solver.cpp:138] Iteration 6950, lr = 2.5e-05
I0210 03:44:28.371877  6526 solver.cpp:243] Iteration 6960, loss = 6.14072
I0210 03:44:28.371989  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.62492 (* 1 = 5.62492 loss)
I0210 03:44:32.816936  6526 sgd_solver.cpp:138] Iteration 6960, lr = 2.5e-05
I0210 03:45:39.691661  6526 solver.cpp:243] Iteration 6970, loss = 6.11915
I0210 03:45:39.691766  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.7721 (* 1 = 5.7721 loss)
I0210 03:45:43.284751  6526 sgd_solver.cpp:138] Iteration 6970, lr = 2.5e-05
I0210 03:46:43.008570  6526 solver.cpp:243] Iteration 6980, loss = 6.18523
I0210 03:46:43.008692  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.02188 (* 1 = 6.02188 loss)
I0210 03:46:48.454324  6526 sgd_solver.cpp:138] Iteration 6980, lr = 2.5e-05
I0210 03:47:50.545110  6526 solver.cpp:243] Iteration 6990, loss = 6.28712
I0210 03:47:50.545809  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.76927 (* 1 = 5.76927 loss)
I0210 03:47:56.038790  6526 sgd_solver.cpp:138] Iteration 6990, lr = 2.5e-05
I0210 03:49:02.373780  6526 solver.cpp:243] Iteration 7000, loss = 6.25898
I0210 03:49:02.373883  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.39394 (* 1 = 6.39394 loss)
I0210 03:49:06.785197  6526 sgd_solver.cpp:138] Iteration 7000, lr = 2.5e-05
I0210 03:50:09.723251  6526 solver.cpp:243] Iteration 7010, loss = 6.3282
I0210 03:50:09.723383  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.81392 (* 1 = 5.81392 loss)
I0210 03:50:15.830683  6526 sgd_solver.cpp:138] Iteration 7010, lr = 2.5e-05
I0210 03:51:19.583137  6526 solver.cpp:243] Iteration 7020, loss = 6.30908
I0210 03:51:19.583312  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.4539 (* 1 = 6.4539 loss)
I0210 03:51:23.999179  6526 sgd_solver.cpp:138] Iteration 7020, lr = 2.5e-05
I0210 03:52:28.826782  6526 solver.cpp:243] Iteration 7030, loss = 6.32584
I0210 03:52:28.826957  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.46599 (* 1 = 6.46599 loss)
I0210 03:52:34.823267  6526 sgd_solver.cpp:138] Iteration 7030, lr = 2.5e-05
I0210 03:53:41.359122  6526 solver.cpp:243] Iteration 7040, loss = 6.36996
I0210 03:53:41.359328  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.34266 (* 1 = 6.34266 loss)
I0210 03:53:46.224309  6526 sgd_solver.cpp:138] Iteration 7040, lr = 2.5e-05
I0210 03:54:50.935322  6526 solver.cpp:243] Iteration 7050, loss = 6.14975
I0210 03:54:50.935719  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.20787 (* 1 = 6.20787 loss)
I0210 03:54:55.373667  6526 sgd_solver.cpp:138] Iteration 7050, lr = 2.5e-05
I0210 03:56:01.450995  6526 solver.cpp:243] Iteration 7060, loss = 6.32542
I0210 03:56:01.451342  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.04426 (* 1 = 6.04426 loss)
I0210 03:56:05.849418  6526 sgd_solver.cpp:138] Iteration 7060, lr = 2.5e-05
I0210 03:57:12.736506  6526 solver.cpp:243] Iteration 7070, loss = 6.11235
I0210 03:57:12.736680  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.83875 (* 1 = 5.83875 loss)
I0210 03:57:17.948467  6526 sgd_solver.cpp:138] Iteration 7070, lr = 2.5e-05
I0210 03:58:20.349951  6526 solver.cpp:243] Iteration 7080, loss = 6.23835
I0210 03:58:20.350113  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.66348 (* 1 = 6.66348 loss)
I0210 03:58:25.061347  6526 sgd_solver.cpp:138] Iteration 7080, lr = 2.5e-05
I0210 03:59:28.366829  6526 solver.cpp:243] Iteration 7090, loss = 6.25027
I0210 03:59:28.366948  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.88949 (* 1 = 5.88949 loss)
I0210 03:59:33.794325  6526 sgd_solver.cpp:138] Iteration 7090, lr = 2.5e-05
I0210 04:00:36.028029  6526 solver.cpp:243] Iteration 7100, loss = 6.47786
I0210 04:00:36.028167  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.33233 (* 1 = 6.33233 loss)
I0210 04:00:41.656973  6526 sgd_solver.cpp:138] Iteration 7100, lr = 2.5e-05
I0210 04:01:49.943553  6526 solver.cpp:243] Iteration 7110, loss = 6.29654
I0210 04:01:49.943675  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.93893 (* 1 = 5.93893 loss)
I0210 04:01:49.943722  6526 sgd_solver.cpp:138] Iteration 7110, lr = 2.5e-05
I0210 04:02:54.920235  6526 solver.cpp:243] Iteration 7120, loss = 6.23256
I0210 04:02:54.920410  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.39719 (* 1 = 6.39719 loss)
I0210 04:03:01.536872  6526 sgd_solver.cpp:138] Iteration 7120, lr = 2.5e-05
I0210 04:04:02.536840  6526 solver.cpp:243] Iteration 7130, loss = 6.14566
I0210 04:04:02.538100  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.24465 (* 1 = 6.24465 loss)
I0210 04:04:07.751003  6526 sgd_solver.cpp:138] Iteration 7130, lr = 2.5e-05
I0210 04:05:11.640856  6526 solver.cpp:243] Iteration 7140, loss = 6.1311
I0210 04:05:11.640986  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.96867 (* 1 = 5.96867 loss)
I0210 04:05:17.116696  6526 sgd_solver.cpp:138] Iteration 7140, lr = 2.5e-05
I0210 04:06:21.688556  6526 solver.cpp:243] Iteration 7150, loss = 6.20845
I0210 04:06:21.693644  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.54869 (* 1 = 6.54869 loss)
I0210 04:06:26.695443  6526 sgd_solver.cpp:138] Iteration 7150, lr = 2.5e-05
I0210 04:07:30.149344  6526 solver.cpp:243] Iteration 7160, loss = 6.24427
I0210 04:07:30.149520  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.52122 (* 1 = 6.52122 loss)
I0210 04:07:36.364019  6526 sgd_solver.cpp:138] Iteration 7160, lr = 2.5e-05
I0210 04:08:40.495281  6526 solver.cpp:243] Iteration 7170, loss = 6.11407
I0210 04:08:40.495450  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.26425 (* 1 = 6.26425 loss)
I0210 04:08:46.120332  6526 sgd_solver.cpp:138] Iteration 7170, lr = 2.5e-05
I0210 04:09:49.138900  6526 solver.cpp:243] Iteration 7180, loss = 6.20937
I0210 04:09:49.139034  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.30446 (* 1 = 6.30446 loss)
I0210 04:09:54.901581  6526 sgd_solver.cpp:138] Iteration 7180, lr = 2.5e-05
I0210 04:10:59.116700  6526 solver.cpp:243] Iteration 7190, loss = 6.27104
I0210 04:10:59.116859  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.18474 (* 1 = 6.18474 loss)
I0210 04:11:05.444211  6526 sgd_solver.cpp:138] Iteration 7190, lr = 2.5e-05
I0210 04:12:11.101505  6526 solver.cpp:243] Iteration 7200, loss = 6.16001
I0210 04:12:11.114398  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.77222 (* 1 = 6.77222 loss)
I0210 04:12:17.107336  6526 sgd_solver.cpp:138] Iteration 7200, lr = 2.5e-05
I0210 04:13:16.557312  6526 solver.cpp:243] Iteration 7210, loss = 6.18373
I0210 04:13:16.564296  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.44467 (* 1 = 6.44467 loss)
I0210 04:13:23.604382  6526 sgd_solver.cpp:138] Iteration 7210, lr = 2.5e-05
I0210 04:14:27.872903  6526 solver.cpp:243] Iteration 7220, loss = 6.42383
I0210 04:14:27.873528  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.62272 (* 1 = 6.62272 loss)
I0210 04:14:34.621506  6526 sgd_solver.cpp:138] Iteration 7220, lr = 2.5e-05
I0210 04:15:36.743731  6526 solver.cpp:243] Iteration 7230, loss = 6.16439
I0210 04:15:36.745712  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.01889 (* 1 = 6.01889 loss)
I0210 04:15:42.792788  6526 sgd_solver.cpp:138] Iteration 7230, lr = 2.5e-05
I0210 04:16:48.291198  6526 solver.cpp:243] Iteration 7240, loss = 6.08668
I0210 04:16:48.291399  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.05741 (* 1 = 6.05741 loss)
I0210 04:16:54.044602  6526 sgd_solver.cpp:138] Iteration 7240, lr = 2.5e-05
I0210 04:17:58.414273  6526 solver.cpp:243] Iteration 7250, loss = 6.22269
I0210 04:17:58.424906  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.93416 (* 1 = 5.93416 loss)
I0210 04:18:03.521337  6526 sgd_solver.cpp:138] Iteration 7250, lr = 2.5e-05
I0210 04:19:03.954432  6526 solver.cpp:243] Iteration 7260, loss = 6.17142
I0210 04:19:03.954615  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.29073 (* 1 = 6.29073 loss)
I0210 04:19:10.731498  6526 sgd_solver.cpp:138] Iteration 7260, lr = 2.5e-05
I0210 04:20:11.581871  6526 solver.cpp:243] Iteration 7270, loss = 6.1636
I0210 04:20:11.581979  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.03337 (* 1 = 6.03337 loss)
I0210 04:20:17.482664  6526 sgd_solver.cpp:138] Iteration 7270, lr = 2.5e-05
I0210 04:21:22.045233  6526 solver.cpp:243] Iteration 7280, loss = 6.18502
I0210 04:21:22.055131  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.28288 (* 1 = 6.28288 loss)
I0210 04:21:27.821282  6526 sgd_solver.cpp:138] Iteration 7280, lr = 2.5e-05
I0210 04:22:30.623982  6526 solver.cpp:243] Iteration 7290, loss = 6.2891
I0210 04:22:30.624114  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.05834 (* 1 = 6.05834 loss)
I0210 04:22:37.172617  6526 sgd_solver.cpp:138] Iteration 7290, lr = 2.5e-05
I0210 04:23:40.096303  6526 solver.cpp:243] Iteration 7300, loss = 6.32617
I0210 04:23:40.099228  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.10275 (* 1 = 6.10275 loss)
I0210 04:23:45.805907  6526 sgd_solver.cpp:138] Iteration 7300, lr = 2.5e-05
I0210 04:24:47.573237  6526 solver.cpp:243] Iteration 7310, loss = 6.17298
I0210 04:24:47.573348  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.91733 (* 1 = 5.91733 loss)
I0210 04:24:52.918004  6526 sgd_solver.cpp:138] Iteration 7310, lr = 2.5e-05
I0210 04:25:57.824798  6526 solver.cpp:243] Iteration 7320, loss = 6.11245
I0210 04:25:57.838443  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.18713 (* 1 = 6.18713 loss)
I0210 04:26:03.688663  6526 sgd_solver.cpp:138] Iteration 7320, lr = 2.5e-05
I0210 04:27:09.662503  6526 solver.cpp:243] Iteration 7330, loss = 6.12505
I0210 04:27:09.662675  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.94278 (* 1 = 5.94278 loss)
I0210 04:27:14.913033  6526 sgd_solver.cpp:138] Iteration 7330, lr = 2.5e-05
I0210 04:28:20.269340  6526 solver.cpp:243] Iteration 7340, loss = 6.24003
I0210 04:28:20.269474  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.95976 (* 1 = 5.95976 loss)
I0210 04:28:24.316390  6526 sgd_solver.cpp:138] Iteration 7340, lr = 2.5e-05
I0210 04:29:27.279799  6526 solver.cpp:243] Iteration 7350, loss = 6.32832
I0210 04:29:27.280246  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.84548 (* 1 = 5.84548 loss)
I0210 04:29:33.930693  6526 sgd_solver.cpp:138] Iteration 7350, lr = 2.5e-05
I0210 04:30:38.146154  6526 solver.cpp:243] Iteration 7360, loss = 6.1194
I0210 04:30:38.149756  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.57246 (* 1 = 6.57246 loss)
I0210 04:30:42.910254  6526 sgd_solver.cpp:138] Iteration 7360, lr = 2.5e-05
I0210 04:31:45.537912  6526 solver.cpp:243] Iteration 7370, loss = 6.26451
I0210 04:31:45.548787  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.02888 (* 1 = 6.02888 loss)
I0210 04:31:50.495492  6526 sgd_solver.cpp:138] Iteration 7370, lr = 2.5e-05
I0210 04:32:54.410249  6526 solver.cpp:243] Iteration 7380, loss = 6.151
I0210 04:32:54.410384  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.44775 (* 1 = 5.44775 loss)
I0210 04:32:57.653877  6526 sgd_solver.cpp:138] Iteration 7380, lr = 2.5e-05
I0210 04:34:06.227161  6526 solver.cpp:243] Iteration 7390, loss = 6.28638
I0210 04:34:06.227265  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.04838 (* 1 = 6.04838 loss)
I0210 04:34:10.546416  6526 sgd_solver.cpp:138] Iteration 7390, lr = 2.5e-05
I0210 04:35:14.679780  6526 solver.cpp:243] Iteration 7400, loss = 6.18074
I0210 04:35:14.679996  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.63472 (* 1 = 6.63472 loss)
I0210 04:35:20.031574  6526 sgd_solver.cpp:138] Iteration 7400, lr = 2.5e-05
I0210 04:36:22.917392  6526 solver.cpp:243] Iteration 7410, loss = 6.09393
I0210 04:36:22.920204  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.30827 (* 1 = 6.30827 loss)
I0210 04:36:28.955428  6526 sgd_solver.cpp:138] Iteration 7410, lr = 2.5e-05
I0210 04:37:32.640458  6526 solver.cpp:243] Iteration 7420, loss = 6.12026
I0210 04:37:32.651105  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.11554 (* 1 = 6.11554 loss)
I0210 04:37:39.049007  6526 sgd_solver.cpp:138] Iteration 7420, lr = 2.5e-05
I0210 04:38:41.737299  6526 solver.cpp:243] Iteration 7430, loss = 6.04007
I0210 04:38:41.737507  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.47123 (* 1 = 5.47123 loss)
I0210 04:38:47.368772  6526 sgd_solver.cpp:138] Iteration 7430, lr = 2.5e-05
I0210 04:39:51.419703  6526 solver.cpp:243] Iteration 7440, loss = 6.30446
I0210 04:39:51.419865  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.87341 (* 1 = 5.87341 loss)
I0210 04:39:57.659482  6526 sgd_solver.cpp:138] Iteration 7440, lr = 2.5e-05
I0210 04:40:58.699051  6526 solver.cpp:243] Iteration 7450, loss = 6.189
I0210 04:40:58.699209  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.48618 (* 1 = 6.48618 loss)
I0210 04:41:04.762974  6526 sgd_solver.cpp:138] Iteration 7450, lr = 2.5e-05
I0210 04:42:10.213145  6526 solver.cpp:243] Iteration 7460, loss = 6.14318
I0210 04:42:10.213310  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.27627 (* 1 = 6.27627 loss)
I0210 04:42:16.959151  6526 sgd_solver.cpp:138] Iteration 7460, lr = 2.5e-05
I0210 04:43:18.796111  6526 solver.cpp:243] Iteration 7470, loss = 6.31921
I0210 04:43:18.796241  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.56294 (* 1 = 6.56294 loss)
I0210 04:43:25.965376  6526 sgd_solver.cpp:138] Iteration 7470, lr = 2.5e-05
I0210 04:44:28.902242  6526 solver.cpp:243] Iteration 7480, loss = 6.264
I0210 04:44:28.902429  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.44665 (* 1 = 6.44665 loss)
I0210 04:44:35.202729  6526 sgd_solver.cpp:138] Iteration 7480, lr = 2.5e-05
I0210 04:45:39.847785  6526 solver.cpp:243] Iteration 7490, loss = 6.18887
I0210 04:45:39.853894  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.7619 (* 1 = 6.7619 loss)
I0210 04:45:46.324352  6526 sgd_solver.cpp:138] Iteration 7490, lr = 2.5e-05
I0210 04:46:51.044850  6526 solver.cpp:243] Iteration 7500, loss = 6.27187
I0210 04:46:51.045022  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.70525 (* 1 = 6.70525 loss)
I0210 04:46:56.620964  6526 sgd_solver.cpp:138] Iteration 7500, lr = 2.5e-05
I0210 04:48:01.090030  6526 solver.cpp:243] Iteration 7510, loss = 6.08394
I0210 04:48:01.090272  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.48318 (* 1 = 6.48318 loss)
I0210 04:48:07.918221  6526 sgd_solver.cpp:138] Iteration 7510, lr = 2.5e-05
I0210 04:49:11.405807  6526 solver.cpp:243] Iteration 7520, loss = 6.32585
I0210 04:49:11.418411  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.30668 (* 1 = 6.30668 loss)
I0210 04:49:17.833415  6526 sgd_solver.cpp:138] Iteration 7520, lr = 2.5e-05
I0210 04:50:20.950253  6526 solver.cpp:243] Iteration 7530, loss = 6.25566
I0210 04:50:20.954946  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.2506 (* 1 = 6.2506 loss)
I0210 04:50:26.169229  6526 sgd_solver.cpp:138] Iteration 7530, lr = 2.5e-05
I0210 04:51:31.607447  6526 solver.cpp:243] Iteration 7540, loss = 6.19785
I0210 04:51:31.607553  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.30145 (* 1 = 6.30145 loss)
I0210 04:51:37.515854  6526 sgd_solver.cpp:138] Iteration 7540, lr = 2.5e-05
I0210 04:52:42.552511  6526 solver.cpp:243] Iteration 7550, loss = 6.32168
I0210 04:52:42.552623  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.85841 (* 1 = 5.85841 loss)
I0210 04:52:47.022475  6526 sgd_solver.cpp:138] Iteration 7550, lr = 2.5e-05
I0210 04:53:49.963345  6526 solver.cpp:243] Iteration 7560, loss = 6.25256
I0210 04:53:49.963512  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.89448 (* 1 = 5.89448 loss)
I0210 04:53:56.521891  6526 sgd_solver.cpp:138] Iteration 7560, lr = 2.5e-05
I0210 04:55:05.044534  6526 solver.cpp:243] Iteration 7570, loss = 6.20158
I0210 04:55:05.044667  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.13805 (* 1 = 6.13805 loss)
I0210 04:55:09.899636  6526 sgd_solver.cpp:138] Iteration 7570, lr = 2.5e-05
I0210 04:56:13.287431  6526 solver.cpp:243] Iteration 7580, loss = 6.13406
I0210 04:56:13.288712  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.31812 (* 1 = 6.31812 loss)
I0210 04:56:19.901338  6526 sgd_solver.cpp:138] Iteration 7580, lr = 2.5e-05
I0210 04:57:24.054558  6526 solver.cpp:243] Iteration 7590, loss = 6.11976
I0210 04:57:24.070389  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.49357 (* 1 = 6.49357 loss)
I0210 04:57:30.582849  6526 sgd_solver.cpp:138] Iteration 7590, lr = 2.5e-05
I0210 04:58:32.872877  6526 solver.cpp:243] Iteration 7600, loss = 6.18971
I0210 04:58:32.873004  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.38563 (* 1 = 6.38563 loss)
I0210 04:58:38.234118  6526 sgd_solver.cpp:138] Iteration 7600, lr = 2.5e-05
I0210 04:59:40.686511  6526 solver.cpp:243] Iteration 7610, loss = 6.26242
I0210 04:59:40.686724  6526 solver.cpp:259]     Train net output #0: mbox_loss = 7.10717 (* 1 = 7.10717 loss)
I0210 04:59:47.336616  6526 sgd_solver.cpp:138] Iteration 7610, lr = 2.5e-05
I0210 05:00:48.360942  6526 solver.cpp:243] Iteration 7620, loss = 6.24481
I0210 05:00:48.362557  6526 solver.cpp:259]     Train net output #0: mbox_loss = 7.14433 (* 1 = 7.14433 loss)
I0210 05:00:54.655953  6526 sgd_solver.cpp:138] Iteration 7620, lr = 2.5e-05
I0210 05:01:58.387460  6526 solver.cpp:243] Iteration 7630, loss = 6.23483
I0210 05:01:58.387639  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.46396 (* 1 = 6.46396 loss)
I0210 05:02:04.119370  6526 sgd_solver.cpp:138] Iteration 7630, lr = 2.5e-05
I0210 05:03:05.532065  6526 solver.cpp:243] Iteration 7640, loss = 6.11266
I0210 05:03:05.532228  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.2925 (* 1 = 6.2925 loss)
I0210 05:03:10.693927  6526 sgd_solver.cpp:138] Iteration 7640, lr = 2.5e-05
I0210 05:04:14.928596  6526 solver.cpp:243] Iteration 7650, loss = 6.33819
I0210 05:04:14.928740  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.29031 (* 1 = 6.29031 loss)
I0210 05:04:21.270015  6526 sgd_solver.cpp:138] Iteration 7650, lr = 2.5e-05
I0210 05:05:26.283596  6526 solver.cpp:243] Iteration 7660, loss = 6.18137
I0210 05:05:26.283799  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.07929 (* 1 = 6.07929 loss)
I0210 05:05:30.783920  6526 sgd_solver.cpp:138] Iteration 7660, lr = 2.5e-05
I0210 05:06:35.260383  6526 solver.cpp:243] Iteration 7670, loss = 6.1579
I0210 05:06:35.262708  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.09313 (* 1 = 6.09313 loss)
I0210 05:06:41.576592  6526 sgd_solver.cpp:138] Iteration 7670, lr = 2.5e-05
I0210 05:07:44.353037  6526 solver.cpp:243] Iteration 7680, loss = 6.28382
I0210 05:07:44.353158  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.9606 (* 1 = 6.9606 loss)
I0210 05:07:49.469794  6526 sgd_solver.cpp:138] Iteration 7680, lr = 2.5e-05
I0210 05:08:52.533313  6526 solver.cpp:243] Iteration 7690, loss = 6.10543
I0210 05:08:52.533447  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.91978 (* 1 = 5.91978 loss)
I0210 05:08:59.208125  6526 sgd_solver.cpp:138] Iteration 7690, lr = 2.5e-05
I0210 05:10:00.607522  6526 solver.cpp:243] Iteration 7700, loss = 6.18841
I0210 05:10:00.607762  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.77057 (* 1 = 5.77057 loss)
I0210 05:10:06.481820  6526 sgd_solver.cpp:138] Iteration 7700, lr = 2.5e-05
I0210 05:10:06.497010  6557 blocking_queue.cpp:50] Data layer prefetch queue empty
I0210 05:11:09.557166  6526 solver.cpp:243] Iteration 7710, loss = 6.19263
I0210 05:11:09.563318  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.10531 (* 1 = 6.10531 loss)
I0210 05:11:15.678630  6526 sgd_solver.cpp:138] Iteration 7710, lr = 2.5e-05
I0210 05:12:18.171816  6526 solver.cpp:243] Iteration 7720, loss = 6.05628
I0210 05:12:18.172948  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.31651 (* 1 = 6.31651 loss)
I0210 05:12:23.801698  6526 sgd_solver.cpp:138] Iteration 7720, lr = 2.5e-05
I0210 05:13:26.155182  6526 solver.cpp:243] Iteration 7730, loss = 6.15398
I0210 05:13:26.156766  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.42624 (* 1 = 6.42624 loss)
I0210 05:13:31.950052  6526 sgd_solver.cpp:138] Iteration 7730, lr = 2.5e-05
I0210 05:14:39.379128  6526 solver.cpp:243] Iteration 7740, loss = 6.18197
I0210 05:14:39.379300  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.03879 (* 1 = 6.03879 loss)
I0210 05:14:45.551697  6526 sgd_solver.cpp:138] Iteration 7740, lr = 2.5e-05
I0210 05:15:52.238073  6526 solver.cpp:243] Iteration 7750, loss = 6.29575
I0210 05:15:52.238191  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.4514 (* 1 = 6.4514 loss)
I0210 05:15:57.256638  6526 sgd_solver.cpp:138] Iteration 7750, lr = 2.5e-05
I0210 05:17:01.055583  6526 solver.cpp:243] Iteration 7760, loss = 6.12065
I0210 05:17:01.061206  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.16043 (* 1 = 6.16043 loss)
I0210 05:17:06.903642  6526 sgd_solver.cpp:138] Iteration 7760, lr = 2.5e-05
I0210 05:18:12.009161  6526 solver.cpp:243] Iteration 7770, loss = 6.22136
I0210 05:18:12.014796  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.37112 (* 1 = 6.37112 loss)
I0210 05:18:18.013443  6526 sgd_solver.cpp:138] Iteration 7770, lr = 2.5e-05
I0210 05:19:19.760908  6526 solver.cpp:243] Iteration 7780, loss = 6.16415
I0210 05:19:19.771612  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.12747 (* 1 = 6.12747 loss)
I0210 05:19:25.960475  6526 sgd_solver.cpp:138] Iteration 7780, lr = 2.5e-05
I0210 05:20:31.333701  6526 solver.cpp:243] Iteration 7790, loss = 6.18439
I0210 05:20:31.333823  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.95799 (* 1 = 5.95799 loss)
I0210 05:20:37.303850  6526 sgd_solver.cpp:138] Iteration 7790, lr = 2.5e-05
I0210 05:21:39.274415  6526 solver.cpp:243] Iteration 7800, loss = 6.13642
I0210 05:21:39.274540  6526 solver.cpp:259]     Train net output #0: mbox_loss = 7.03088 (* 1 = 7.03088 loss)
I0210 05:21:45.941474  6526 sgd_solver.cpp:138] Iteration 7800, lr = 2.5e-05
I0210 05:22:48.684358  6526 solver.cpp:243] Iteration 7810, loss = 6.20166
I0210 05:22:48.685911  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.29574 (* 1 = 6.29574 loss)
I0210 05:22:54.504540  6526 sgd_solver.cpp:138] Iteration 7810, lr = 2.5e-05
I0210 05:23:58.815112  6526 solver.cpp:243] Iteration 7820, loss = 6.28005
I0210 05:23:58.815281  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.28989 (* 1 = 6.28989 loss)
I0210 05:24:05.190498  6526 sgd_solver.cpp:138] Iteration 7820, lr = 2.5e-05
I0210 05:25:06.318665  6526 solver.cpp:243] Iteration 7830, loss = 6.18818
I0210 05:25:06.318783  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.11063 (* 1 = 6.11063 loss)
I0210 05:25:11.920804  6526 sgd_solver.cpp:138] Iteration 7830, lr = 2.5e-05
I0210 05:26:13.980334  6526 solver.cpp:243] Iteration 7840, loss = 6.24174
I0210 05:26:13.980520  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.04689 (* 1 = 6.04689 loss)
I0210 05:26:19.910143  6526 sgd_solver.cpp:138] Iteration 7840, lr = 2.5e-05
I0210 05:27:23.288560  6526 solver.cpp:243] Iteration 7850, loss = 6.18215
I0210 05:27:23.288744  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.12286 (* 1 = 6.12286 loss)
I0210 05:27:29.102946  6526 sgd_solver.cpp:138] Iteration 7850, lr = 2.5e-05
I0210 05:28:33.761332  6526 solver.cpp:243] Iteration 7860, loss = 6.18102
I0210 05:28:33.761471  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.76258 (* 1 = 5.76258 loss)
I0210 05:28:39.450095  6526 sgd_solver.cpp:138] Iteration 7860, lr = 2.5e-05
I0210 05:29:44.264921  6526 solver.cpp:243] Iteration 7870, loss = 6.26226
I0210 05:29:44.270030  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.21651 (* 1 = 6.21651 loss)
I0210 05:29:49.989796  6526 sgd_solver.cpp:138] Iteration 7870, lr = 2.5e-05
I0210 05:30:53.277130  6526 solver.cpp:243] Iteration 7880, loss = 6.01005
I0210 05:30:53.290410  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.86427 (* 1 = 5.86427 loss)
I0210 05:30:59.056537  6526 sgd_solver.cpp:138] Iteration 7880, lr = 2.5e-05
I0210 05:31:58.977035  6526 solver.cpp:243] Iteration 7890, loss = 6.07936
I0210 05:31:58.990411  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.94712 (* 1 = 5.94712 loss)
I0210 05:32:05.357771  6526 sgd_solver.cpp:138] Iteration 7890, lr = 2.5e-05
I0210 05:33:12.485054  6526 solver.cpp:243] Iteration 7900, loss = 6.21666
I0210 05:33:12.485226  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.29403 (* 1 = 6.29403 loss)
I0210 05:33:18.619405  6526 sgd_solver.cpp:138] Iteration 7900, lr = 2.5e-05
I0210 05:34:22.179615  6526 solver.cpp:243] Iteration 7910, loss = 6.13947
I0210 05:34:22.179808  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.09063 (* 1 = 6.09063 loss)
I0210 05:34:27.619086  6526 sgd_solver.cpp:138] Iteration 7910, lr = 2.5e-05
I0210 05:35:30.715890  6526 solver.cpp:243] Iteration 7920, loss = 6.15262
I0210 05:35:30.716068  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.1934 (* 1 = 6.1934 loss)
I0210 05:35:35.491987  6526 sgd_solver.cpp:138] Iteration 7920, lr = 2.5e-05
I0210 05:36:38.637563  6526 solver.cpp:243] Iteration 7930, loss = 6.24097
I0210 05:36:38.637696  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.96452 (* 1 = 5.96452 loss)
I0210 05:36:45.173075  6526 sgd_solver.cpp:138] Iteration 7930, lr = 2.5e-05
I0210 05:37:49.384506  6526 solver.cpp:243] Iteration 7940, loss = 6.14696
I0210 05:37:49.384670  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.99718 (* 1 = 5.99718 loss)
I0210 05:37:55.631548  6526 sgd_solver.cpp:138] Iteration 7940, lr = 2.5e-05
I0210 05:39:00.235294  6526 solver.cpp:243] Iteration 7950, loss = 6.13827
I0210 05:39:00.235458  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.134 (* 1 = 6.134 loss)
I0210 05:39:06.160851  6526 sgd_solver.cpp:138] Iteration 7950, lr = 2.5e-05
I0210 05:40:08.883496  6526 solver.cpp:243] Iteration 7960, loss = 6.2464
I0210 05:40:08.884793  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.14387 (* 1 = 6.14387 loss)
I0210 05:40:14.146643  6526 sgd_solver.cpp:138] Iteration 7960, lr = 2.5e-05
I0210 05:41:20.327677  6526 solver.cpp:243] Iteration 7970, loss = 6.31732
I0210 05:41:20.327816  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.09881 (* 1 = 6.09881 loss)
I0210 05:41:25.520815  6526 sgd_solver.cpp:138] Iteration 7970, lr = 2.5e-05
I0210 05:42:29.648927  6526 solver.cpp:243] Iteration 7980, loss = 6.20157
I0210 05:42:29.649627  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.2204 (* 1 = 6.2204 loss)
I0210 05:42:35.208092  6526 sgd_solver.cpp:138] Iteration 7980, lr = 2.5e-05
I0210 05:43:38.607390  6526 solver.cpp:243] Iteration 7990, loss = 6.12753
I0210 05:43:38.622400  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.45308 (* 1 = 6.45308 loss)
I0210 05:43:44.217964  6526 sgd_solver.cpp:138] Iteration 7990, lr = 2.5e-05
I0210 05:44:47.371455  6526 solver.cpp:243] Iteration 8000, loss = 6.1551
I0210 05:44:47.382460  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.51686 (* 1 = 5.51686 loss)
I0210 05:44:54.079233  6526 sgd_solver.cpp:138] Iteration 8000, lr = 2.5e-05
I0210 05:45:59.519157  6526 solver.cpp:243] Iteration 8010, loss = 6.39605
I0210 05:45:59.534413  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.65772 (* 1 = 6.65772 loss)
I0210 05:46:04.087296  6526 sgd_solver.cpp:138] Iteration 8010, lr = 2.5e-05
I0210 05:47:09.811965  6526 solver.cpp:243] Iteration 8020, loss = 6.29216
I0210 05:47:09.812141  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.38197 (* 1 = 6.38197 loss)
I0210 05:47:12.583968  6526 sgd_solver.cpp:138] Iteration 8020, lr = 2.5e-05
I0210 05:48:18.765019  6526 solver.cpp:243] Iteration 8030, loss = 6.34531
I0210 05:48:18.765190  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.16078 (* 1 = 6.16078 loss)
I0210 05:48:23.519970  6526 sgd_solver.cpp:138] Iteration 8030, lr = 2.5e-05
I0210 05:49:28.320188  6526 solver.cpp:243] Iteration 8040, loss = 6.21027
I0210 05:49:28.320338  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.47144 (* 1 = 6.47144 loss)
I0210 05:49:35.339936  6526 sgd_solver.cpp:138] Iteration 8040, lr = 2.5e-05
I0210 05:50:40.849308  6526 solver.cpp:243] Iteration 8050, loss = 6.04572
I0210 05:50:40.857241  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.70407 (* 1 = 5.70407 loss)
I0210 05:50:46.234603  6526 sgd_solver.cpp:138] Iteration 8050, lr = 2.5e-05
I0210 05:51:48.653966  6526 solver.cpp:243] Iteration 8060, loss = 6.26664
I0210 05:51:48.664643  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.27238 (* 1 = 6.27238 loss)
I0210 05:51:54.554447  6526 sgd_solver.cpp:138] Iteration 8060, lr = 2.5e-05
I0210 05:52:55.635041  6526 solver.cpp:243] Iteration 8070, loss = 6.16738
I0210 05:52:55.639988  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.24021 (* 1 = 6.24021 loss)
I0210 05:53:01.884804  6526 sgd_solver.cpp:138] Iteration 8070, lr = 2.5e-05
I0210 05:54:04.717025  6526 solver.cpp:243] Iteration 8080, loss = 6.19907
I0210 05:54:04.717281  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.2775 (* 1 = 6.2775 loss)
I0210 05:54:10.730410  6526 sgd_solver.cpp:138] Iteration 8080, lr = 2.5e-05
I0210 05:55:12.643472  6526 solver.cpp:243] Iteration 8090, loss = 6.20437
I0210 05:55:12.643604  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.08231 (* 1 = 6.08231 loss)
I0210 05:55:19.504215  6526 sgd_solver.cpp:138] Iteration 8090, lr = 2.5e-05
I0210 05:56:26.254492  6526 solver.cpp:243] Iteration 8100, loss = 6.19156
I0210 05:56:26.254623  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.36291 (* 1 = 6.36291 loss)
I0210 05:56:32.625677  6526 sgd_solver.cpp:138] Iteration 8100, lr = 2.5e-05
I0210 05:57:39.224690  6526 solver.cpp:243] Iteration 8110, loss = 6.30592
I0210 05:57:39.233757  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.641 (* 1 = 6.641 loss)
I0210 05:57:46.433554  6526 sgd_solver.cpp:138] Iteration 8110, lr = 2.5e-05
I0210 05:58:52.088889  6526 solver.cpp:243] Iteration 8120, loss = 6.20835
I0210 05:58:52.089057  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.22071 (* 1 = 6.22071 loss)
I0210 05:58:56.504346  6526 sgd_solver.cpp:138] Iteration 8120, lr = 2.5e-05
I0210 06:00:01.060324  6526 solver.cpp:243] Iteration 8130, loss = 6.27757
I0210 06:00:01.060547  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.38049 (* 1 = 6.38049 loss)
I0210 06:00:06.155700  6526 sgd_solver.cpp:138] Iteration 8130, lr = 2.5e-05
I0210 06:01:11.285038  6526 solver.cpp:243] Iteration 8140, loss = 6.18067
I0210 06:01:11.286798  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.93355 (* 1 = 5.93355 loss)
I0210 06:01:16.898228  6526 sgd_solver.cpp:138] Iteration 8140, lr = 2.5e-05
I0210 06:02:19.650741  6526 solver.cpp:243] Iteration 8150, loss = 6.20238
I0210 06:02:19.654651  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.83053 (* 1 = 5.83053 loss)
I0210 06:02:25.914621  6526 sgd_solver.cpp:138] Iteration 8150, lr = 2.5e-05
I0210 06:03:29.580772  6526 solver.cpp:243] Iteration 8160, loss = 6.23249
I0210 06:03:29.589251  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.82975 (* 1 = 6.82975 loss)
I0210 06:03:36.037849  6526 sgd_solver.cpp:138] Iteration 8160, lr = 2.5e-05
I0210 06:04:39.051605  6526 solver.cpp:243] Iteration 8170, loss = 6.14244
I0210 06:04:39.051735  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.29657 (* 1 = 6.29657 loss)
I0210 06:04:44.811857  6526 sgd_solver.cpp:138] Iteration 8170, lr = 2.5e-05
I0210 06:05:44.886287  6526 solver.cpp:243] Iteration 8180, loss = 6.07327
I0210 06:05:44.886461  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.29092 (* 1 = 5.29092 loss)
I0210 06:05:51.643591  6526 sgd_solver.cpp:138] Iteration 8180, lr = 2.5e-05
I0210 06:06:56.716049  6526 solver.cpp:243] Iteration 8190, loss = 6.15562
I0210 06:06:56.716146  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.22958 (* 1 = 6.22958 loss)
I0210 06:07:00.624014  6526 sgd_solver.cpp:138] Iteration 8190, lr = 2.5e-05
I0210 06:08:05.919842  6526 solver.cpp:243] Iteration 8200, loss = 6.15109
I0210 06:08:05.919945  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.97647 (* 1 = 5.97647 loss)
I0210 06:08:11.259922  6526 sgd_solver.cpp:138] Iteration 8200, lr = 2.5e-05
I0210 06:09:14.736083  6526 solver.cpp:243] Iteration 8210, loss = 6.26431
I0210 06:09:14.736245  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.57234 (* 1 = 6.57234 loss)
I0210 06:09:18.508653  6526 sgd_solver.cpp:138] Iteration 8210, lr = 2.5e-05
I0210 06:10:24.242630  6526 solver.cpp:243] Iteration 8220, loss = 6.11275
I0210 06:10:24.242797  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.92413 (* 1 = 6.92413 loss)
I0210 06:10:31.447336  6526 sgd_solver.cpp:138] Iteration 8220, lr = 2.5e-05
I0210 06:11:35.653259  6526 solver.cpp:243] Iteration 8230, loss = 6.11484
I0210 06:11:35.664500  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.52682 (* 1 = 5.52682 loss)
I0210 06:11:40.328198  6526 sgd_solver.cpp:138] Iteration 8230, lr = 2.5e-05
I0210 06:12:43.162107  6526 solver.cpp:243] Iteration 8240, loss = 6.13148
I0210 06:12:43.162271  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.01709 (* 1 = 6.01709 loss)
I0210 06:12:49.239228  6526 sgd_solver.cpp:138] Iteration 8240, lr = 2.5e-05
I0210 06:13:53.755777  6526 solver.cpp:243] Iteration 8250, loss = 6.07333
I0210 06:13:53.755911  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.64241 (* 1 = 5.64241 loss)
I0210 06:13:58.943475  6526 sgd_solver.cpp:138] Iteration 8250, lr = 2.5e-05
I0210 06:15:02.021000  6526 solver.cpp:243] Iteration 8260, loss = 6.03356
I0210 06:15:02.023499  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.25112 (* 1 = 6.25112 loss)
I0210 06:15:07.498440  6526 sgd_solver.cpp:138] Iteration 8260, lr = 2.5e-05
I0210 06:16:11.728581  6526 solver.cpp:243] Iteration 8270, loss = 6.38758
I0210 06:16:11.728714  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.62782 (* 1 = 6.62782 loss)
I0210 06:16:15.858507  6526 sgd_solver.cpp:138] Iteration 8270, lr = 2.5e-05
I0210 06:17:21.827806  6526 solver.cpp:243] Iteration 8280, loss = 6.15633
I0210 06:17:21.827978  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.23875 (* 1 = 6.23875 loss)
I0210 06:17:26.415223  6526 sgd_solver.cpp:138] Iteration 8280, lr = 2.5e-05
I0210 06:18:28.632280  6526 solver.cpp:243] Iteration 8290, loss = 6.16096
I0210 06:18:28.632458  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.54474 (* 1 = 5.54474 loss)
I0210 06:18:34.271756  6526 sgd_solver.cpp:138] Iteration 8290, lr = 2.5e-05
I0210 06:19:40.572450  6526 solver.cpp:243] Iteration 8300, loss = 6.20926
I0210 06:19:40.572592  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.24323 (* 1 = 6.24323 loss)
I0210 06:19:44.143719  6526 sgd_solver.cpp:138] Iteration 8300, lr = 2.5e-05
I0210 06:20:49.968083  6526 solver.cpp:243] Iteration 8310, loss = 6.09099
I0210 06:20:49.968197  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.77207 (* 1 = 5.77207 loss)
I0210 06:20:54.366739  6526 sgd_solver.cpp:138] Iteration 8310, lr = 2.5e-05
I0210 06:22:02.486042  6526 solver.cpp:243] Iteration 8320, loss = 6.27707
I0210 06:22:02.486147  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.29357 (* 1 = 6.29357 loss)
I0210 06:22:07.283871  6526 sgd_solver.cpp:138] Iteration 8320, lr = 2.5e-05
I0210 06:23:09.143689  6526 solver.cpp:243] Iteration 8330, loss = 5.95294
I0210 06:23:09.143815  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.71088 (* 1 = 5.71088 loss)
I0210 06:23:14.326949  6526 sgd_solver.cpp:138] Iteration 8330, lr = 2.5e-05
I0210 06:24:17.234459  6526 solver.cpp:243] Iteration 8340, loss = 6.0581
I0210 06:24:17.234594  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.26879 (* 1 = 6.26879 loss)
I0210 06:24:23.249081  6526 sgd_solver.cpp:138] Iteration 8340, lr = 2.5e-05
I0210 06:25:27.275712  6526 solver.cpp:243] Iteration 8350, loss = 5.97347
I0210 06:25:27.275876  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.50644 (* 1 = 5.50644 loss)
I0210 06:25:32.914878  6526 sgd_solver.cpp:138] Iteration 8350, lr = 2.5e-05
I0210 06:26:38.092286  6526 solver.cpp:243] Iteration 8360, loss = 6.04262
I0210 06:26:38.092422  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.75461 (* 1 = 5.75461 loss)
I0210 06:26:43.727237  6526 sgd_solver.cpp:138] Iteration 8360, lr = 2.5e-05
I0210 06:27:47.805850  6526 solver.cpp:243] Iteration 8370, loss = 6.19479
I0210 06:27:47.806023  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.08487 (* 1 = 6.08487 loss)
I0210 06:27:52.918411  6526 sgd_solver.cpp:138] Iteration 8370, lr = 2.5e-05
I0210 06:28:55.973924  6526 solver.cpp:243] Iteration 8380, loss = 6.1793
I0210 06:28:55.984678  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.34675 (* 1 = 6.34675 loss)
I0210 06:29:01.234678  6526 sgd_solver.cpp:138] Iteration 8380, lr = 2.5e-05
I0210 06:30:06.461825  6526 solver.cpp:243] Iteration 8390, loss = 6.21992
I0210 06:30:06.461998  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.0079 (* 1 = 6.0079 loss)
I0210 06:30:11.321805  6526 sgd_solver.cpp:138] Iteration 8390, lr = 2.5e-05
I0210 06:31:17.442731  6526 solver.cpp:243] Iteration 8400, loss = 6.09775
I0210 06:31:17.449403  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.01404 (* 1 = 6.01404 loss)
I0210 06:31:23.355890  6526 sgd_solver.cpp:138] Iteration 8400, lr = 2.5e-05
I0210 06:32:27.130120  6526 solver.cpp:243] Iteration 8410, loss = 6.22172
I0210 06:32:27.132920  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.32097 (* 1 = 6.32097 loss)
I0210 06:32:33.848906  6526 sgd_solver.cpp:138] Iteration 8410, lr = 2.5e-05
I0210 06:33:40.953341  6526 solver.cpp:243] Iteration 8420, loss = 6.1266
I0210 06:33:40.953548  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.0564 (* 1 = 6.0564 loss)
I0210 06:33:44.801093  6526 sgd_solver.cpp:138] Iteration 8420, lr = 2.5e-05
I0210 06:34:50.235143  6526 solver.cpp:243] Iteration 8430, loss = 6.24472
I0210 06:34:50.235329  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.38061 (* 1 = 6.38061 loss)
I0210 06:34:56.503031  6526 sgd_solver.cpp:138] Iteration 8430, lr = 2.5e-05
I0210 06:36:03.548280  6526 solver.cpp:243] Iteration 8440, loss = 6.11841
I0210 06:36:03.548375  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.15467 (* 1 = 6.15467 loss)
I0210 06:36:07.674144  6526 sgd_solver.cpp:138] Iteration 8440, lr = 2.5e-05
I0210 06:36:07.689323  6557 blocking_queue.cpp:50] Data layer prefetch queue empty
I0210 06:37:10.944520  6526 solver.cpp:243] Iteration 8450, loss = 6.04179
I0210 06:37:10.944689  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.88669 (* 1 = 5.88669 loss)
I0210 06:37:16.659649  6526 sgd_solver.cpp:138] Iteration 8450, lr = 2.5e-05
I0210 06:38:18.218133  6526 solver.cpp:243] Iteration 8460, loss = 6.18874
I0210 06:38:18.218255  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.08173 (* 1 = 6.08173 loss)
I0210 06:38:24.221222  6526 sgd_solver.cpp:138] Iteration 8460, lr = 2.5e-05
I0210 06:39:28.952643  6526 solver.cpp:243] Iteration 8470, loss = 6.11995
I0210 06:39:28.952774  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.1011 (* 1 = 6.1011 loss)
I0210 06:39:34.525486  6526 sgd_solver.cpp:138] Iteration 8470, lr = 2.5e-05
I0210 06:40:35.858391  6526 solver.cpp:243] Iteration 8480, loss = 6.18626
I0210 06:40:35.858546  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.59832 (* 1 = 5.59832 loss)
I0210 06:40:42.885126  6526 sgd_solver.cpp:138] Iteration 8480, lr = 2.5e-05
I0210 06:41:49.649788  6526 solver.cpp:243] Iteration 8490, loss = 6.18706
I0210 06:41:49.649998  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.78673 (* 1 = 5.78673 loss)
I0210 06:41:55.879827  6526 sgd_solver.cpp:138] Iteration 8490, lr = 2.5e-05
I0210 06:43:01.253775  6526 solver.cpp:243] Iteration 8500, loss = 6.21374
I0210 06:43:01.253984  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.50693 (* 1 = 6.50693 loss)
I0210 06:43:08.144182  6526 sgd_solver.cpp:138] Iteration 8500, lr = 2.5e-05
I0210 06:44:10.848711  6526 solver.cpp:243] Iteration 8510, loss = 6.07608
I0210 06:44:10.848877  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.01886 (* 1 = 6.01886 loss)
I0210 06:44:17.415232  6526 sgd_solver.cpp:138] Iteration 8510, lr = 2.5e-05
I0210 06:45:19.200045  6526 solver.cpp:243] Iteration 8520, loss = 6.16691
I0210 06:45:19.214411  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.02807 (* 1 = 6.02807 loss)
I0210 06:45:24.387369  6526 sgd_solver.cpp:138] Iteration 8520, lr = 2.5e-05
I0210 06:46:28.133013  6526 solver.cpp:243] Iteration 8530, loss = 6.16776
I0210 06:46:28.133149  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.82801 (* 1 = 6.82801 loss)
I0210 06:46:33.899111  6526 sgd_solver.cpp:138] Iteration 8530, lr = 2.5e-05
I0210 06:47:37.311203  6526 solver.cpp:243] Iteration 8540, loss = 6.13729
I0210 06:47:37.311389  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.51403 (* 1 = 6.51403 loss)
I0210 06:47:44.022299  6526 sgd_solver.cpp:138] Iteration 8540, lr = 2.5e-05
I0210 06:48:48.606781  6526 solver.cpp:243] Iteration 8550, loss = 6.2036
I0210 06:48:48.606969  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.8422 (* 1 = 6.8422 loss)
I0210 06:48:54.414163  6526 sgd_solver.cpp:138] Iteration 8550, lr = 2.5e-05
I0210 06:49:59.325052  6526 solver.cpp:243] Iteration 8560, loss = 6.11623
I0210 06:49:59.334380  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.07553 (* 1 = 6.07553 loss)
I0210 06:50:05.256721  6526 sgd_solver.cpp:138] Iteration 8560, lr = 2.5e-05
I0210 06:51:09.619915  6526 solver.cpp:243] Iteration 8570, loss = 6.29028
I0210 06:51:09.625265  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.06733 (* 1 = 6.06733 loss)
I0210 06:51:15.407459  6526 sgd_solver.cpp:138] Iteration 8570, lr = 2.5e-05
I0210 06:52:17.853246  6526 solver.cpp:243] Iteration 8580, loss = 6.1485
I0210 06:52:17.853417  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.04351 (* 1 = 6.04351 loss)
I0210 06:52:24.592669  6526 sgd_solver.cpp:138] Iteration 8580, lr = 2.5e-05
I0210 06:53:31.338855  6526 solver.cpp:243] Iteration 8590, loss = 6.2153
I0210 06:53:31.338979  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.94178 (* 1 = 6.94178 loss)
I0210 06:53:34.282315  6526 sgd_solver.cpp:138] Iteration 8590, lr = 2.5e-05
I0210 06:54:42.085763  6526 solver.cpp:243] Iteration 8600, loss = 6.26265
I0210 06:54:42.085918  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.95307 (* 1 = 5.95307 loss)
I0210 06:54:42.085970  6526 sgd_solver.cpp:138] Iteration 8600, lr = 2.5e-05
I0210 06:55:48.421064  6526 solver.cpp:243] Iteration 8610, loss = 6.20964
I0210 06:55:48.421233  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.56777 (* 1 = 6.56777 loss)
I0210 06:55:51.236049  6526 sgd_solver.cpp:138] Iteration 8610, lr = 2.5e-05
I0210 06:56:59.188913  6526 solver.cpp:243] Iteration 8620, loss = 6.12524
I0210 06:56:59.197801  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.16102 (* 1 = 6.16102 loss)
I0210 06:57:01.918654  6526 sgd_solver.cpp:138] Iteration 8620, lr = 2.5e-05
I0210 06:58:09.574532  6526 solver.cpp:243] Iteration 8630, loss = 6.1079
I0210 06:58:09.582486  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.1804 (* 1 = 6.1804 loss)
I0210 06:58:12.327422  6526 sgd_solver.cpp:138] Iteration 8630, lr = 2.5e-05
I0210 06:59:21.849776  6526 solver.cpp:243] Iteration 8640, loss = 6.15885
I0210 06:59:21.851989  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.58418 (* 1 = 5.58418 loss)
I0210 06:59:21.852067  6526 sgd_solver.cpp:138] Iteration 8640, lr = 2.5e-05
I0210 07:00:30.817396  6526 solver.cpp:243] Iteration 8650, loss = 6.10161
I0210 07:00:30.817523  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.86583 (* 1 = 6.86583 loss)
I0210 07:00:30.817572  6526 sgd_solver.cpp:138] Iteration 8650, lr = 2.5e-05
I0210 07:01:39.154824  6526 solver.cpp:243] Iteration 8660, loss = 6.10453
I0210 07:01:39.154958  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.83393 (* 1 = 5.83393 loss)
I0210 07:01:39.155007  6526 sgd_solver.cpp:138] Iteration 8660, lr = 2.5e-05
I0210 07:02:49.363713  6526 solver.cpp:243] Iteration 8670, loss = 6.27494
I0210 07:02:49.364595  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.51293 (* 1 = 6.51293 loss)
I0210 07:02:49.364715  6526 sgd_solver.cpp:138] Iteration 8670, lr = 2.5e-05
I0210 07:03:58.715766  6526 solver.cpp:243] Iteration 8680, loss = 6.18179
I0210 07:03:58.715893  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.68694 (* 1 = 5.68694 loss)
I0210 07:03:58.715958  6526 sgd_solver.cpp:138] Iteration 8680, lr = 2.5e-05
I0210 07:05:11.264874  6526 solver.cpp:243] Iteration 8690, loss = 6.28792
I0210 07:05:11.266345  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.9155 (* 1 = 5.9155 loss)
I0210 07:05:11.266469  6526 sgd_solver.cpp:138] Iteration 8690, lr = 2.5e-05
I0210 07:06:22.262579  6526 solver.cpp:243] Iteration 8700, loss = 6.23841
I0210 07:06:22.262702  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.31335 (* 1 = 6.31335 loss)
I0210 07:06:22.262750  6526 sgd_solver.cpp:138] Iteration 8700, lr = 2.5e-05
I0210 07:07:31.784955  6526 solver.cpp:243] Iteration 8710, loss = 6.18282
I0210 07:07:31.785122  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.44083 (* 1 = 6.44083 loss)
I0210 07:07:31.785210  6526 sgd_solver.cpp:138] Iteration 8710, lr = 2.5e-05
I0210 07:08:40.666929  6526 solver.cpp:243] Iteration 8720, loss = 6.14169
I0210 07:08:40.667064  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.20076 (* 1 = 6.20076 loss)
I0210 07:08:40.667114  6526 sgd_solver.cpp:138] Iteration 8720, lr = 2.5e-05
I0210 07:09:49.223624  6526 solver.cpp:243] Iteration 8730, loss = 6.16467
I0210 07:09:49.229281  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.95709 (* 1 = 5.95709 loss)
I0210 07:09:49.229358  6526 sgd_solver.cpp:138] Iteration 8730, lr = 2.5e-05
I0210 07:10:57.488327  6526 solver.cpp:243] Iteration 8740, loss = 6.22454
I0210 07:10:57.488499  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.27405 (* 1 = 6.27405 loss)
I0210 07:10:57.488566  6526 sgd_solver.cpp:138] Iteration 8740, lr = 2.5e-05
I0210 07:12:07.508687  6526 solver.cpp:243] Iteration 8750, loss = 6.12782
I0210 07:12:07.511445  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.23192 (* 1 = 6.23192 loss)
I0210 07:12:07.511512  6526 sgd_solver.cpp:138] Iteration 8750, lr = 2.5e-05
I0210 07:13:14.853510  6526 solver.cpp:243] Iteration 8760, loss = 6.04992
I0210 07:13:14.853667  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.11145 (* 1 = 6.11145 loss)
I0210 07:13:14.853732  6526 sgd_solver.cpp:138] Iteration 8760, lr = 2.5e-05
I0210 07:14:26.242578  6526 solver.cpp:243] Iteration 8770, loss = 6.1805
I0210 07:14:26.242712  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.1928 (* 1 = 6.1928 loss)
I0210 07:14:26.242761  6526 sgd_solver.cpp:138] Iteration 8770, lr = 2.5e-05
I0210 07:15:33.422852  6526 solver.cpp:243] Iteration 8780, loss = 6.28455
I0210 07:15:33.423027  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.48038 (* 1 = 6.48038 loss)
I0210 07:15:33.423099  6526 sgd_solver.cpp:138] Iteration 8780, lr = 2.5e-05
I0210 07:16:43.385612  6526 solver.cpp:243] Iteration 8790, loss = 6.04138
I0210 07:16:43.385716  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.34435 (* 1 = 6.34435 loss)
I0210 07:16:43.385752  6526 sgd_solver.cpp:138] Iteration 8790, lr = 2.5e-05
I0210 07:17:52.921713  6526 solver.cpp:243] Iteration 8800, loss = 6.14441
I0210 07:17:52.921839  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.06103 (* 1 = 6.06103 loss)
I0210 07:17:52.921905  6526 sgd_solver.cpp:138] Iteration 8800, lr = 2.5e-05
I0210 07:18:58.634176  6526 solver.cpp:243] Iteration 8810, loss = 6.09138
I0210 07:18:58.634297  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.03086 (* 1 = 6.03086 loss)
I0210 07:19:01.587877  6526 sgd_solver.cpp:138] Iteration 8810, lr = 2.5e-05
I0210 07:20:06.492805  6526 solver.cpp:243] Iteration 8820, loss = 6.07607
I0210 07:20:06.493630  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.95394 (* 1 = 5.95394 loss)
I0210 07:20:11.852780  6526 sgd_solver.cpp:138] Iteration 8820, lr = 2.5e-05
I0210 07:21:18.664607  6526 solver.cpp:243] Iteration 8830, loss = 6.27379
I0210 07:21:18.664737  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.81367 (* 1 = 5.81367 loss)
I0210 07:21:24.821663  6526 sgd_solver.cpp:138] Iteration 8830, lr = 2.5e-05
I0210 07:22:26.338141  6526 solver.cpp:243] Iteration 8840, loss = 6.08116
I0210 07:22:26.338268  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.84998 (* 1 = 5.84998 loss)
I0210 07:22:32.387615  6526 sgd_solver.cpp:138] Iteration 8840, lr = 2.5e-05
I0210 07:23:35.195571  6526 solver.cpp:243] Iteration 8850, loss = 6.10566
I0210 07:23:35.197293  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.02882 (* 1 = 6.02882 loss)
I0210 07:23:42.682746  6526 sgd_solver.cpp:138] Iteration 8850, lr = 2.5e-05
I0210 07:24:44.053108  6526 solver.cpp:243] Iteration 8860, loss = 6.30327
I0210 07:24:44.053263  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.42605 (* 1 = 6.42605 loss)
I0210 07:24:50.679842  6526 sgd_solver.cpp:138] Iteration 8860, lr = 2.5e-05
I0210 07:25:55.862105  6526 solver.cpp:243] Iteration 8870, loss = 6.12795
I0210 07:25:55.862229  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.39694 (* 1 = 6.39694 loss)
I0210 07:26:02.224503  6526 sgd_solver.cpp:138] Iteration 8870, lr = 2.5e-05
I0210 07:27:05.317561  6526 solver.cpp:243] Iteration 8880, loss = 6.07784
I0210 07:27:05.317690  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.6161 (* 1 = 6.6161 loss)
I0210 07:27:11.231575  6526 sgd_solver.cpp:138] Iteration 8880, lr = 2.5e-05
I0210 07:28:14.942811  6526 solver.cpp:243] Iteration 8890, loss = 6.24879
I0210 07:28:14.958456  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.88651 (* 1 = 5.88651 loss)
I0210 07:28:21.290387  6526 sgd_solver.cpp:138] Iteration 8890, lr = 2.5e-05
I0210 07:29:23.144093  6526 solver.cpp:243] Iteration 8900, loss = 6.19492
I0210 07:29:23.144261  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.67426 (* 1 = 6.67426 loss)
I0210 07:29:27.848911  6526 sgd_solver.cpp:138] Iteration 8900, lr = 2.5e-05
I0210 07:30:31.801180  6526 solver.cpp:243] Iteration 8910, loss = 6.12819
I0210 07:30:31.807137  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.40307 (* 1 = 6.40307 loss)
I0210 07:30:38.681396  6526 sgd_solver.cpp:138] Iteration 8910, lr = 2.5e-05
I0210 07:31:42.489070  6526 solver.cpp:243] Iteration 8920, loss = 6.14893
I0210 07:31:42.489203  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.13323 (* 1 = 6.13323 loss)
I0210 07:31:48.979766  6526 sgd_solver.cpp:138] Iteration 8920, lr = 2.5e-05
I0210 07:32:49.500823  6526 solver.cpp:243] Iteration 8930, loss = 6.10686
I0210 07:32:49.500954  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.20628 (* 1 = 6.20628 loss)
I0210 07:32:55.363097  6526 sgd_solver.cpp:138] Iteration 8930, lr = 2.5e-05
I0210 07:34:00.224017  6526 solver.cpp:243] Iteration 8940, loss = 6.34841
I0210 07:34:00.224187  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.59751 (* 1 = 6.59751 loss)
I0210 07:34:04.511559  6526 sgd_solver.cpp:138] Iteration 8940, lr = 2.5e-05
I0210 07:35:10.535243  6526 solver.cpp:243] Iteration 8950, loss = 6.14158
I0210 07:35:10.535411  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.26217 (* 1 = 6.26217 loss)
I0210 07:35:13.428058  6526 sgd_solver.cpp:138] Iteration 8950, lr = 2.5e-05
I0210 07:36:21.539849  6526 solver.cpp:243] Iteration 8960, loss = 6.23059
I0210 07:36:21.540292  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.83345 (* 1 = 5.83345 loss)
I0210 07:36:24.591357  6526 sgd_solver.cpp:138] Iteration 8960, lr = 2.5e-05
I0210 07:37:32.705397  6526 solver.cpp:243] Iteration 8970, loss = 6.16081
I0210 07:37:32.716085  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.08718 (* 1 = 6.08718 loss)
I0210 07:37:37.122259  6526 sgd_solver.cpp:138] Iteration 8970, lr = 2.5e-05
I0210 07:38:45.198705  6526 solver.cpp:243] Iteration 8980, loss = 6.03751
I0210 07:38:45.198827  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.96093 (* 1 = 5.96093 loss)
I0210 07:38:49.815184  6526 sgd_solver.cpp:138] Iteration 8980, lr = 2.5e-05
I0210 07:39:54.771013  6526 solver.cpp:243] Iteration 8990, loss = 6.11754
I0210 07:39:54.771184  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.27783 (* 1 = 6.27783 loss)
I0210 07:39:59.465026  6526 sgd_solver.cpp:138] Iteration 8990, lr = 2.5e-05
I0210 07:41:01.995234  6526 solver.cpp:243] Iteration 9000, loss = 6.20224
I0210 07:41:02.000365  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.44129 (* 1 = 6.44129 loss)
I0210 07:41:09.718982  6526 sgd_solver.cpp:138] Iteration 9000, lr = 2.5e-05
I0210 07:42:11.864912  6526 solver.cpp:243] Iteration 9010, loss = 6.21787
I0210 07:42:11.866850  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.32684 (* 1 = 6.32684 loss)
I0210 07:42:17.812386  6526 sgd_solver.cpp:138] Iteration 9010, lr = 2.5e-05
I0210 07:43:21.951099  6526 solver.cpp:243] Iteration 9020, loss = 6.19381
I0210 07:43:21.951236  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.62417 (* 1 = 6.62417 loss)
I0210 07:43:26.307234  6526 sgd_solver.cpp:138] Iteration 9020, lr = 2.5e-05
I0210 07:44:31.263905  6526 solver.cpp:243] Iteration 9030, loss = 6.06751
I0210 07:44:31.264034  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.67624 (* 1 = 5.67624 loss)
I0210 07:44:37.056176  6526 sgd_solver.cpp:138] Iteration 9030, lr = 2.5e-05
I0210 07:45:42.067343  6526 solver.cpp:243] Iteration 9040, loss = 6.22715
I0210 07:45:42.067513  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.14312 (* 1 = 6.14312 loss)
I0210 07:45:48.153564  6526 sgd_solver.cpp:138] Iteration 9040, lr = 2.5e-05
I0210 07:46:53.698887  6526 solver.cpp:243] Iteration 9050, loss = 6.16726
I0210 07:46:53.703951  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.10135 (* 1 = 6.10135 loss)
I0210 07:47:00.475389  6526 sgd_solver.cpp:138] Iteration 9050, lr = 2.5e-05
I0210 07:47:35.383692  6557 blocking_queue.cpp:50] Data layer prefetch queue empty
I0210 07:48:03.269753  6526 solver.cpp:243] Iteration 9060, loss = 6.13109
I0210 07:48:03.269909  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.38225 (* 1 = 6.38225 loss)
I0210 07:48:10.119706  6526 sgd_solver.cpp:138] Iteration 9060, lr = 2.5e-05
I0210 07:49:12.149866  6526 solver.cpp:243] Iteration 9070, loss = 6.19198
I0210 07:49:12.160559  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.45983 (* 1 = 6.45983 loss)
I0210 07:49:17.787431  6526 sgd_solver.cpp:138] Iteration 9070, lr = 2.5e-05
I0210 07:50:25.212338  6526 solver.cpp:243] Iteration 9080, loss = 6.00484
I0210 07:50:25.212440  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.56515 (* 1 = 5.56515 loss)
I0210 07:50:30.654342  6526 sgd_solver.cpp:138] Iteration 9080, lr = 2.5e-05
I0210 07:51:31.895155  6526 solver.cpp:243] Iteration 9090, loss = 6.1789
I0210 07:51:31.895320  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.85793 (* 1 = 5.85793 loss)
I0210 07:51:38.879004  6526 sgd_solver.cpp:138] Iteration 9090, lr = 2.5e-05
I0210 07:52:44.141067  6526 solver.cpp:243] Iteration 9100, loss = 6.21783
I0210 07:52:44.141168  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.01372 (* 1 = 6.01372 loss)
I0210 07:52:48.760346  6526 sgd_solver.cpp:138] Iteration 9100, lr = 2.5e-05
I0210 07:53:53.424031  6526 solver.cpp:243] Iteration 9110, loss = 6.14121
I0210 07:53:53.424206  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.34348 (* 1 = 6.34348 loss)
I0210 07:53:56.363925  6526 sgd_solver.cpp:138] Iteration 9110, lr = 2.5e-05
I0210 07:55:02.378106  6526 solver.cpp:243] Iteration 9120, loss = 6.10518
I0210 07:55:02.378275  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.2972 (* 1 = 6.2972 loss)
I0210 07:55:06.252569  6526 sgd_solver.cpp:138] Iteration 9120, lr = 2.5e-05
I0210 07:56:10.495558  6526 solver.cpp:243] Iteration 9130, loss = 6.03601
I0210 07:56:10.495750  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.94912 (* 1 = 5.94912 loss)
I0210 07:56:16.323587  6526 sgd_solver.cpp:138] Iteration 9130, lr = 2.5e-05
I0210 07:57:19.999435  6526 solver.cpp:243] Iteration 9140, loss = 6.21724
I0210 07:57:19.999549  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.38612 (* 1 = 6.38612 loss)
I0210 07:57:24.334563  6526 sgd_solver.cpp:138] Iteration 9140, lr = 2.5e-05
I0210 07:58:30.740083  6526 solver.cpp:243] Iteration 9150, loss = 6.30523
I0210 07:58:30.745939  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.18002 (* 1 = 6.18002 loss)
I0210 07:58:36.726040  6526 sgd_solver.cpp:138] Iteration 9150, lr = 2.5e-05
I0210 07:59:40.488260  6526 solver.cpp:243] Iteration 9160, loss = 6.19969
I0210 07:59:40.488427  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.05557 (* 1 = 6.05557 loss)
I0210 07:59:45.179009  6526 sgd_solver.cpp:138] Iteration 9160, lr = 2.5e-05
I0210 08:00:52.032274  6526 solver.cpp:243] Iteration 9170, loss = 6.01692
I0210 08:00:52.032447  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.67139 (* 1 = 5.67139 loss)
I0210 08:00:55.269024  6526 sgd_solver.cpp:138] Iteration 9170, lr = 2.5e-05
I0210 08:02:02.536732  6526 solver.cpp:243] Iteration 9180, loss = 6.14314
I0210 08:02:02.536901  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.55518 (* 1 = 5.55518 loss)
I0210 08:02:05.984235  6526 sgd_solver.cpp:138] Iteration 9180, lr = 2.5e-05
I0210 08:03:10.360160  6526 solver.cpp:243] Iteration 9190, loss = 6.05595
I0210 08:03:10.360368  6526 solver.cpp:259]     Train net output #0: mbox_loss = 7.13942 (* 1 = 7.13942 loss)
I0210 08:03:14.187489  6526 sgd_solver.cpp:138] Iteration 9190, lr = 2.5e-05
I0210 08:04:18.563664  6526 solver.cpp:243] Iteration 9200, loss = 6.27184
I0210 08:04:18.564219  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.05592 (* 1 = 6.05592 loss)
I0210 08:04:22.819866  6526 sgd_solver.cpp:138] Iteration 9200, lr = 2.5e-05
I0210 08:05:31.905194  6526 solver.cpp:243] Iteration 9210, loss = 6.21532
I0210 08:05:31.905316  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.2897 (* 1 = 6.2897 loss)
I0210 08:05:36.354841  6526 sgd_solver.cpp:138] Iteration 9210, lr = 2.5e-05
I0210 08:06:39.420840  6526 solver.cpp:243] Iteration 9220, loss = 6.19651
I0210 08:06:39.426295  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.60972 (* 1 = 6.60972 loss)
I0210 08:06:45.082556  6526 sgd_solver.cpp:138] Iteration 9220, lr = 2.5e-05
I0210 08:07:49.192081  6526 solver.cpp:243] Iteration 9230, loss = 6.09789
I0210 08:07:49.192203  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.99341 (* 1 = 5.99341 loss)
I0210 08:07:53.558821  6526 sgd_solver.cpp:138] Iteration 9230, lr = 2.5e-05
I0210 08:08:58.335247  6526 solver.cpp:243] Iteration 9240, loss = 6.14526
I0210 08:08:58.340381  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.1798 (* 1 = 6.1798 loss)
I0210 08:09:02.465687  6526 sgd_solver.cpp:138] Iteration 9240, lr = 2.5e-05
I0210 08:10:07.500849  6526 solver.cpp:243] Iteration 9250, loss = 6.27171
I0210 08:10:07.502138  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.86685 (* 1 = 5.86685 loss)
I0210 08:10:13.554816  6526 sgd_solver.cpp:138] Iteration 9250, lr = 2.5e-05
I0210 08:11:15.336699  6526 solver.cpp:243] Iteration 9260, loss = 6.13081
I0210 08:11:15.339706  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.1612 (* 1 = 6.1612 loss)
I0210 08:11:21.596447  6526 sgd_solver.cpp:138] Iteration 9260, lr = 2.5e-05
I0210 08:12:27.551357  6526 solver.cpp:243] Iteration 9270, loss = 6.08005
I0210 08:12:27.560210  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.20624 (* 1 = 6.20624 loss)
I0210 08:12:33.775090  6526 sgd_solver.cpp:138] Iteration 9270, lr = 2.5e-05
I0210 08:13:37.843405  6526 solver.cpp:243] Iteration 9280, loss = 5.92388
I0210 08:13:37.843583  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.11057 (* 1 = 6.11057 loss)
I0210 08:13:42.455242  6526 sgd_solver.cpp:138] Iteration 9280, lr = 2.5e-05
I0210 08:14:47.043926  6526 solver.cpp:243] Iteration 9290, loss = 5.97391
I0210 08:14:47.045791  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.9723 (* 1 = 5.9723 loss)
I0210 08:14:52.808398  6526 sgd_solver.cpp:138] Iteration 9290, lr = 2.5e-05
I0210 08:15:57.157853  6526 solver.cpp:243] Iteration 9300, loss = 5.98692
I0210 08:15:57.159596  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.99122 (* 1 = 5.99122 loss)
I0210 08:16:03.222426  6526 sgd_solver.cpp:138] Iteration 9300, lr = 2.5e-05
I0210 08:17:06.265523  6526 solver.cpp:243] Iteration 9310, loss = 6.12338
I0210 08:17:06.265697  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.48802 (* 1 = 6.48802 loss)
I0210 08:17:12.265775  6526 sgd_solver.cpp:138] Iteration 9310, lr = 2.5e-05
I0210 08:18:14.081291  6526 solver.cpp:243] Iteration 9320, loss = 6.00431
I0210 08:18:14.094466  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.807 (* 1 = 5.807 loss)
I0210 08:18:19.316557  6526 sgd_solver.cpp:138] Iteration 9320, lr = 2.5e-05
I0210 08:19:23.010192  6526 solver.cpp:243] Iteration 9330, loss = 6.23058
I0210 08:19:23.020931  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.21036 (* 1 = 6.21036 loss)
I0210 08:19:29.455802  6526 sgd_solver.cpp:138] Iteration 9330, lr = 2.5e-05
I0210 08:20:32.158645  6526 solver.cpp:243] Iteration 9340, loss = 6.07578
I0210 08:20:32.158816  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.01369 (* 1 = 6.01369 loss)
I0210 08:20:37.985647  6526 sgd_solver.cpp:138] Iteration 9340, lr = 2.5e-05
I0210 08:21:42.247968  6526 solver.cpp:243] Iteration 9350, loss = 6.25868
I0210 08:21:42.249647  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.50391 (* 1 = 6.50391 loss)
I0210 08:21:48.004314  6526 sgd_solver.cpp:138] Iteration 9350, lr = 2.5e-05
I0210 08:22:49.216830  6526 solver.cpp:243] Iteration 9360, loss = 6.2101
I0210 08:22:49.218026  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.28614 (* 1 = 6.28614 loss)
I0210 08:22:55.513918  6526 sgd_solver.cpp:138] Iteration 9360, lr = 2.5e-05
I0210 08:24:00.405855  6526 solver.cpp:243] Iteration 9370, loss = 6.11402
I0210 08:24:00.406026  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.36144 (* 1 = 6.36144 loss)
I0210 08:24:05.417837  6526 sgd_solver.cpp:138] Iteration 9370, lr = 2.5e-05
I0210 08:25:10.961972  6526 solver.cpp:243] Iteration 9380, loss = 6.17179
I0210 08:25:10.962188  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.14799 (* 1 = 6.14799 loss)
I0210 08:25:16.432109  6526 sgd_solver.cpp:138] Iteration 9380, lr = 2.5e-05
I0210 08:26:17.625458  6526 solver.cpp:243] Iteration 9390, loss = 6.03231
I0210 08:26:17.625591  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.00371 (* 1 = 6.00371 loss)
I0210 08:26:23.327399  6526 sgd_solver.cpp:138] Iteration 9390, lr = 2.5e-05
I0210 08:27:28.796042  6526 solver.cpp:243] Iteration 9400, loss = 6.16671
I0210 08:27:28.810405  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.07368 (* 1 = 6.07368 loss)
I0210 08:27:35.536278  6526 sgd_solver.cpp:138] Iteration 9400, lr = 2.5e-05
I0210 08:28:38.430624  6526 solver.cpp:243] Iteration 9410, loss = 6.18591
I0210 08:28:38.430763  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.25644 (* 1 = 6.25644 loss)
I0210 08:28:44.653342  6526 sgd_solver.cpp:138] Iteration 9410, lr = 2.5e-05
I0210 08:29:50.539142  6526 solver.cpp:243] Iteration 9420, loss = 6.15524
I0210 08:29:50.539253  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.06652 (* 1 = 6.06652 loss)
I0210 08:29:57.166760  6526 sgd_solver.cpp:138] Iteration 9420, lr = 2.5e-05
I0210 08:31:02.970940  6526 solver.cpp:243] Iteration 9430, loss = 6.2872
I0210 08:31:02.971099  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.23323 (* 1 = 6.23323 loss)
I0210 08:31:09.118752  6526 sgd_solver.cpp:138] Iteration 9430, lr = 2.5e-05
I0210 08:32:13.889025  6526 solver.cpp:243] Iteration 9440, loss = 6.0221
I0210 08:32:13.890437  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.73061 (* 1 = 5.73061 loss)
I0210 08:32:19.673748  6526 sgd_solver.cpp:138] Iteration 9440, lr = 2.5e-05
I0210 08:33:19.212872  6526 solver.cpp:243] Iteration 9450, loss = 6.06619
I0210 08:33:19.212999  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.53591 (* 1 = 5.53591 loss)
I0210 08:33:24.580695  6526 sgd_solver.cpp:138] Iteration 9450, lr = 2.5e-05
I0210 08:34:29.505020  6526 solver.cpp:243] Iteration 9460, loss = 6.15987
I0210 08:34:29.508568  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.19431 (* 1 = 6.19431 loss)
I0210 08:34:35.533828  6526 sgd_solver.cpp:138] Iteration 9460, lr = 2.5e-05
I0210 08:35:39.725834  6526 solver.cpp:243] Iteration 9470, loss = 6.25966
I0210 08:35:39.736575  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.83201 (* 1 = 5.83201 loss)
I0210 08:35:45.917512  6526 sgd_solver.cpp:138] Iteration 9470, lr = 2.5e-05
I0210 08:36:48.454198  6526 solver.cpp:243] Iteration 9480, loss = 6.09705
I0210 08:36:48.464890  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.6663 (* 1 = 5.6663 loss)
I0210 08:36:55.613294  6526 sgd_solver.cpp:138] Iteration 9480, lr = 2.5e-05
I0210 08:37:58.752279  6526 solver.cpp:243] Iteration 9490, loss = 6.24376
I0210 08:37:58.752768  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.29161 (* 1 = 6.29161 loss)
I0210 08:38:04.295049  6526 sgd_solver.cpp:138] Iteration 9490, lr = 2.5e-05
I0210 08:39:08.074441  6526 solver.cpp:243] Iteration 9500, loss = 6.21425
I0210 08:39:08.074576  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.47035 (* 1 = 6.47035 loss)
I0210 08:39:13.131273  6526 sgd_solver.cpp:138] Iteration 9500, lr = 2.5e-05
I0210 08:40:18.343194  6526 solver.cpp:243] Iteration 9510, loss = 6.14278
I0210 08:40:18.343363  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.89976 (* 1 = 5.89976 loss)
I0210 08:40:24.587508  6526 sgd_solver.cpp:138] Iteration 9510, lr = 2.5e-05
I0210 08:41:27.301785  6526 solver.cpp:243] Iteration 9520, loss = 6.00104
I0210 08:41:27.301956  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.29216 (* 1 = 6.29216 loss)
I0210 08:41:33.108376  6526 sgd_solver.cpp:138] Iteration 9520, lr = 2.5e-05
I0210 08:42:38.140595  6526 solver.cpp:243] Iteration 9530, loss = 6.07095
I0210 08:42:38.140806  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.99269 (* 1 = 5.99269 loss)
I0210 08:42:43.845098  6526 sgd_solver.cpp:138] Iteration 9530, lr = 2.5e-05
I0210 08:43:47.613327  6526 solver.cpp:243] Iteration 9540, loss = 6.41194
I0210 08:43:47.613483  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.13196 (* 1 = 6.13196 loss)
I0210 08:43:54.224833  6526 sgd_solver.cpp:138] Iteration 9540, lr = 2.5e-05
I0210 08:44:55.549455  6526 solver.cpp:243] Iteration 9550, loss = 6.1278
I0210 08:44:55.549621  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.98711 (* 1 = 5.98711 loss)
I0210 08:45:01.839936  6526 sgd_solver.cpp:138] Iteration 9550, lr = 2.5e-05
I0210 08:46:04.514479  6526 solver.cpp:243] Iteration 9560, loss = 5.98041
I0210 08:46:04.518508  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.25455 (* 1 = 6.25455 loss)
I0210 08:46:11.260617  6526 sgd_solver.cpp:138] Iteration 9560, lr = 2.5e-05
I0210 08:47:13.215525  6526 solver.cpp:243] Iteration 9570, loss = 6.09166
I0210 08:47:13.215651  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.98767 (* 1 = 5.98767 loss)
I0210 08:47:19.638146  6526 sgd_solver.cpp:138] Iteration 9570, lr = 2.5e-05
I0210 08:48:22.629170  6526 solver.cpp:243] Iteration 9580, loss = 6.05934
I0210 08:48:22.629448  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.07247 (* 1 = 6.07247 loss)
I0210 08:48:29.435550  6526 sgd_solver.cpp:138] Iteration 9580, lr = 2.5e-05
I0210 08:49:31.929666  6526 solver.cpp:243] Iteration 9590, loss = 6.11587
I0210 08:49:31.929852  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.49958 (* 1 = 6.49958 loss)
I0210 08:49:38.304558  6526 sgd_solver.cpp:138] Iteration 9590, lr = 2.5e-05
I0210 08:50:43.325700  6526 solver.cpp:243] Iteration 9600, loss = 6.20433
I0210 08:50:43.325930  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.13605 (* 1 = 6.13605 loss)
I0210 08:50:46.945741  6526 sgd_solver.cpp:138] Iteration 9600, lr = 2.5e-05
I0210 08:51:52.320549  6526 solver.cpp:243] Iteration 9610, loss = 6.16332
I0210 08:51:52.320693  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.89258 (* 1 = 6.89258 loss)
I0210 08:51:58.209048  6526 sgd_solver.cpp:138] Iteration 9610, lr = 2.5e-05
I0210 08:53:00.564872  6526 solver.cpp:243] Iteration 9620, loss = 6.10828
I0210 08:53:00.565047  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.49932 (* 1 = 5.49932 loss)
I0210 08:53:07.292497  6526 sgd_solver.cpp:138] Iteration 9620, lr = 2.5e-05
I0210 08:54:10.375875  6526 solver.cpp:243] Iteration 9630, loss = 5.95594
I0210 08:54:10.380347  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.89061 (* 1 = 5.89061 loss)
I0210 08:54:16.639642  6526 sgd_solver.cpp:138] Iteration 9630, lr = 2.5e-05
I0210 08:55:20.794682  6526 solver.cpp:243] Iteration 9640, loss = 6.13612
I0210 08:55:20.794813  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.71379 (* 1 = 5.71379 loss)
I0210 08:55:27.570034  6526 sgd_solver.cpp:138] Iteration 9640, lr = 2.5e-05
I0210 08:56:36.655186  6526 solver.cpp:243] Iteration 9650, loss = 5.9744
I0210 08:56:36.661168  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.42646 (* 1 = 6.42646 loss)
I0210 08:56:42.363344  6526 sgd_solver.cpp:138] Iteration 9650, lr = 2.5e-05
I0210 08:57:44.285975  6526 solver.cpp:243] Iteration 9660, loss = 6.17
I0210 08:57:44.286150  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.64887 (* 1 = 6.64887 loss)
I0210 08:57:49.409126  6526 sgd_solver.cpp:138] Iteration 9660, lr = 2.5e-05
I0210 08:58:52.207291  6526 solver.cpp:243] Iteration 9670, loss = 6.17775
I0210 08:58:52.215914  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.16942 (* 1 = 6.16942 loss)
I0210 08:58:59.132117  6526 sgd_solver.cpp:138] Iteration 9670, lr = 2.5e-05
I0210 09:00:06.078001  6526 solver.cpp:243] Iteration 9680, loss = 6.19115
I0210 09:00:06.078128  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.51179 (* 1 = 6.51179 loss)
I0210 09:00:11.874058  6526 sgd_solver.cpp:138] Iteration 9680, lr = 2.5e-05
I0210 09:01:19.786828  6526 solver.cpp:243] Iteration 9690, loss = 6.1875
I0210 09:01:19.787034  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.98135 (* 1 = 5.98135 loss)
I0210 09:01:25.769098  6526 sgd_solver.cpp:138] Iteration 9690, lr = 2.5e-05
I0210 09:02:36.574421  6526 solver.cpp:243] Iteration 9700, loss = 6.1667
I0210 09:02:36.581354  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.06531 (* 1 = 6.06531 loss)
I0210 09:02:43.048327  6526 sgd_solver.cpp:138] Iteration 9700, lr = 2.5e-05
I0210 09:03:53.372920  6526 solver.cpp:243] Iteration 9710, loss = 6.19293
I0210 09:03:53.383574  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.9559 (* 1 = 5.9559 loss)
I0210 09:03:57.350808  6526 sgd_solver.cpp:138] Iteration 9710, lr = 2.5e-05
I0210 09:05:02.647922  6526 solver.cpp:243] Iteration 9720, loss = 6.09638
I0210 09:05:02.648097  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.60409 (* 1 = 5.60409 loss)
I0210 09:05:07.937388  6526 sgd_solver.cpp:138] Iteration 9720, lr = 2.5e-05
I0210 09:06:22.209118  6526 solver.cpp:243] Iteration 9730, loss = 6.09529
I0210 09:06:22.209297  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.21666 (* 1 = 6.21666 loss)
I0210 09:06:27.436487  6526 sgd_solver.cpp:138] Iteration 9730, lr = 2.5e-05
I0210 09:07:35.044740  6526 solver.cpp:243] Iteration 9740, loss = 5.99645
I0210 09:07:35.044904  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.00591 (* 1 = 6.00591 loss)
I0210 09:07:39.872383  6526 sgd_solver.cpp:138] Iteration 9740, lr = 2.5e-05
I0210 09:08:45.041980  6526 solver.cpp:243] Iteration 9750, loss = 5.95919
I0210 09:08:45.042146  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.96689 (* 1 = 5.96689 loss)
I0210 09:08:50.718511  6526 sgd_solver.cpp:138] Iteration 9750, lr = 2.5e-05
I0210 09:09:58.277436  6526 solver.cpp:243] Iteration 9760, loss = 6.16573
I0210 09:09:58.277554  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.26752 (* 1 = 6.26752 loss)
I0210 09:10:03.069564  6526 sgd_solver.cpp:138] Iteration 9760, lr = 2.5e-05
I0210 09:11:09.188498  6526 solver.cpp:243] Iteration 9770, loss = 6.0879
I0210 09:11:09.188705  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.21166 (* 1 = 6.21166 loss)
I0210 09:11:14.956615  6526 sgd_solver.cpp:138] Iteration 9770, lr = 2.5e-05
I0210 09:12:21.075042  6526 solver.cpp:243] Iteration 9780, loss = 6.0942
I0210 09:12:21.075256  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.90204 (* 1 = 5.90204 loss)
I0210 09:12:26.830790  6526 sgd_solver.cpp:138] Iteration 9780, lr = 2.5e-05
I0210 09:13:30.745856  6526 solver.cpp:243] Iteration 9790, loss = 6.09901
I0210 09:13:30.746037  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.88623 (* 1 = 5.88623 loss)
I0210 09:13:36.625566  6526 sgd_solver.cpp:138] Iteration 9790, lr = 2.5e-05
I0210 09:14:43.756786  6526 solver.cpp:243] Iteration 9800, loss = 6.00022
I0210 09:14:43.770406  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.15145 (* 1 = 6.15145 loss)
I0210 09:14:50.655822  6526 sgd_solver.cpp:138] Iteration 9800, lr = 2.5e-05
I0210 09:15:53.575670  6526 solver.cpp:243] Iteration 9810, loss = 6.00734
I0210 09:15:53.575858  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.00328 (* 1 = 6.00328 loss)
I0210 09:15:59.838299  6526 sgd_solver.cpp:138] Iteration 9810, lr = 2.5e-05
I0210 09:17:04.308280  6526 solver.cpp:243] Iteration 9820, loss = 6.22599
I0210 09:17:04.308496  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.48354 (* 1 = 6.48354 loss)
I0210 09:17:11.374078  6526 sgd_solver.cpp:138] Iteration 9820, lr = 2.5e-05
I0210 09:18:16.050117  6526 solver.cpp:243] Iteration 9830, loss = 6.14419
I0210 09:18:16.050736  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.20238 (* 1 = 6.20238 loss)
I0210 09:18:23.946851  6526 sgd_solver.cpp:138] Iteration 9830, lr = 2.5e-05
I0210 09:19:31.877050  6526 solver.cpp:243] Iteration 9840, loss = 6.11721
I0210 09:19:31.878001  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.17225 (* 1 = 6.17225 loss)
I0210 09:19:38.040410  6526 sgd_solver.cpp:138] Iteration 9840, lr = 2.5e-05
I0210 09:20:47.931298  6526 solver.cpp:243] Iteration 9850, loss = 6.11374
I0210 09:20:47.931511  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.11355 (* 1 = 6.11355 loss)
I0210 09:20:55.879024  6526 sgd_solver.cpp:138] Iteration 9850, lr = 2.5e-05
I0210 09:20:55.912034  6556 blocking_queue.cpp:50] Data layer prefetch queue empty
I0210 09:22:02.692344  6526 solver.cpp:243] Iteration 9860, loss = 6.15673
I0210 09:22:02.698827  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.45879 (* 1 = 6.45879 loss)
I0210 09:22:07.061480  6526 sgd_solver.cpp:138] Iteration 9860, lr = 2.5e-05
I0210 09:23:15.626222  6526 solver.cpp:243] Iteration 9870, loss = 6.22112
I0210 09:23:15.626359  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.46727 (* 1 = 6.46727 loss)
I0210 09:23:21.750275  6526 sgd_solver.cpp:138] Iteration 9870, lr = 2.5e-05
I0210 09:24:27.108772  6526 solver.cpp:243] Iteration 9880, loss = 6.05142
I0210 09:24:27.109966  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.76547 (* 1 = 5.76547 loss)
I0210 09:24:30.357381  6526 sgd_solver.cpp:138] Iteration 9880, lr = 2.5e-05
I0210 09:25:41.811085  6526 solver.cpp:243] Iteration 9890, loss = 6.17369
I0210 09:25:41.811259  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.44863 (* 1 = 6.44863 loss)
I0210 09:25:44.578830  6526 sgd_solver.cpp:138] Iteration 9890, lr = 2.5e-05
I0210 09:26:52.841876  6526 solver.cpp:243] Iteration 9900, loss = 6.01398
I0210 09:26:52.852732  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.16302 (* 1 = 6.16302 loss)
I0210 09:26:58.734416  6526 sgd_solver.cpp:138] Iteration 9900, lr = 2.5e-05
I0210 09:28:06.785337  6526 solver.cpp:243] Iteration 9910, loss = 6.12992
I0210 09:28:06.798447  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.32971 (* 1 = 6.32971 loss)
I0210 09:28:12.132019  6526 sgd_solver.cpp:138] Iteration 9910, lr = 2.5e-05
I0210 09:29:21.259918  6526 solver.cpp:243] Iteration 9920, loss = 5.98057
I0210 09:29:21.260089  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.83909 (* 1 = 5.83909 loss)
I0210 09:29:24.501422  6526 sgd_solver.cpp:138] Iteration 9920, lr = 2.5e-05
I0210 09:30:33.168326  6526 solver.cpp:243] Iteration 9930, loss = 6.07747
I0210 09:30:33.168534  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.16102 (* 1 = 6.16102 loss)
I0210 09:30:35.991075  6526 sgd_solver.cpp:138] Iteration 9930, lr = 2.5e-05
I0210 09:31:46.022428  6526 solver.cpp:243] Iteration 9940, loss = 6.29896
I0210 09:31:46.022524  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.61873 (* 1 = 6.61873 loss)
I0210 09:31:51.299245  6526 sgd_solver.cpp:138] Iteration 9940, lr = 2.5e-05
I0210 09:32:57.138150  6526 solver.cpp:243] Iteration 9950, loss = 6.10825
I0210 09:32:57.145488  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.2817 (* 1 = 6.2817 loss)
I0210 09:33:01.326839  6526 sgd_solver.cpp:138] Iteration 9950, lr = 2.5e-05
I0210 09:34:13.112958  6526 solver.cpp:243] Iteration 9960, loss = 6.04473
I0210 09:34:13.126454  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.77679 (* 1 = 5.77679 loss)
I0210 09:34:14.654857  6526 sgd_solver.cpp:138] Iteration 9960, lr = 2.5e-05
I0210 09:35:26.314304  6526 solver.cpp:243] Iteration 9970, loss = 6.05368
I0210 09:35:26.322533  6526 solver.cpp:259]     Train net output #0: mbox_loss = 6.19236 (* 1 = 6.19236 loss)
I0210 09:35:26.322659  6526 sgd_solver.cpp:138] Iteration 9970, lr = 2.5e-05
I0210 09:36:36.506441  6526 solver.cpp:243] Iteration 9980, loss = 6.10623
I0210 09:36:36.506572  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.97711 (* 1 = 5.97711 loss)
I0210 09:36:42.323626  6526 sgd_solver.cpp:138] Iteration 9980, lr = 2.5e-05
I0210 09:37:50.864879  6526 solver.cpp:243] Iteration 9990, loss = 6.14873
I0210 09:37:50.866307  6526 solver.cpp:259]     Train net output #0: mbox_loss = 5.95457 (* 1 = 5.95457 loss)
I0210 09:37:55.139171  6526 sgd_solver.cpp:138] Iteration 9990, lr = 2.5e-05
I0210 09:38:56.893036  6526 solver.cpp:596] Snapshotting to binary proto file models/VGGNet/VOC0712/SSD_RGBD_test_300x300/VGG_VOC0712_SSD_RGBD_test_300x300_iter_10000.caffemodel
I0210 09:38:57.208901  6526 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/VOC0712/SSD_RGBD_test_300x300/VGG_VOC0712_SSD_RGBD_test_300x300_iter_10000.solverstate
I0210 09:38:57.353157  6526 solver.cpp:433] Iteration 10000, Testing net (#0)
I0210 09:38:57.378981  6526 net.cpp:693] Ignoring source layer mbox_loss
F0210 09:38:57.380692  6526 syncedmem.cpp:56] Check failed: error == cudaSuccess (2 vs. 0)  out of memory
*** Check failure stack trace: ***
    @     0x7fc0c42dbdaa  (unknown)
    @     0x7fc0c42dbce4  (unknown)
    @     0x7fc0c42db6e6  (unknown)
    @     0x7fc0c42de687  (unknown)
    @     0x7fc0c4b35281  caffe::SyncedMemory::to_gpu()
    @     0x7fc0c4b345e9  caffe::SyncedMemory::mutable_gpu_data()
    @     0x7fc0c4b862e2  caffe::Blob<>::mutable_gpu_data()
    @     0x7fc0c4bc286f  caffe::CuDNNConvolutionLayer<>::Forward_gpu()
    @     0x7fc0c4b67815  caffe::Net<>::ForwardFromTo()
    @     0x7fc0c4b67b87  caffe::Net<>::Forward()
    @     0x7fc0c4b7f999  caffe::Solver<>::TestDetection()
    @     0x7fc0c4b80889  caffe::Solver<>::TestAll()
    @     0x7fc0c4b809b0  caffe::Solver<>::Step()
    @     0x7fc0c4b811be  caffe::Solver<>::Solve()
    @     0x7fc0c4977737  caffe::P2PSync<>::Run()
    @           0x40895e  train()
    @           0x40627c  main
    @     0x7fc0c32e7f45  (unknown)
    @           0x406aeb  (unknown)
    @              (nil)  (unknown)
